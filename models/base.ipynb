{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0819c0c-3076-48e9-8e4f-d472663c3760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"../datasets/Crop_recommendation.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41f0fbbf-69e3-4713-9290-219100e35551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    N   P   K  temperature   humidity        ph    rainfall label\n",
      "0  90  42  43    20.879744  82.002744  6.502985  202.935536  Rice\n",
      "1  85  58  41    21.770462  80.319644  7.038096  226.655537  Rice\n",
      "2  60  55  44    23.004459  82.320763  7.840207  263.964248  Rice\n",
      "3  74  35  40    26.491096  80.158363  6.980401  242.864034  Rice\n",
      "4  78  42  42    20.130175  81.604873  7.628473  262.717340  Rice\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bb5ec8b-b9c6-4b91-b049-59a8dfc42a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2100 entries, 0 to 2099\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   N            2100 non-null   int64  \n",
      " 1   P            2100 non-null   int64  \n",
      " 2   K            2100 non-null   int64  \n",
      " 3   temperature  2100 non-null   float64\n",
      " 4   humidity     2100 non-null   float64\n",
      " 5   ph           2100 non-null   float64\n",
      " 6   rainfall     2100 non-null   float64\n",
      " 7   label        2100 non-null   object \n",
      "dtypes: float64(4), int64(3), object(1)\n",
      "memory usage: 131.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc3b372c-e958-4e96-95ca-a7fc9bce66a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N              0\n",
      "P              0\n",
      "K              0\n",
      "temperature    0\n",
      "humidity       0\n",
      "ph             0\n",
      "rainfall       0\n",
      "label          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data Exploration\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25c37f39-facd-4803-88d2-26869f3800d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot histograms for numerical features\n",
    "df.hist(figsize=(10, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9582190e-fe13-49d7-a2f3-621048a1b12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "Rice                         100\n",
      "Maize                        100\n",
      "Bengal Gram (Gram)(Whole)    100\n",
      "Pegeon Pea (Arhar Fali)      100\n",
      "Moath Dal                    100\n",
      "Green Gram (Moong)(Whole)    100\n",
      "Black Gram Dal (Urd Dal)     100\n",
      "Lentil (Masur)(Whole)        100\n",
      "Pomegranate                  100\n",
      "Banana                       100\n",
      "Mango                        100\n",
      "Grapes                       100\n",
      "Water Melon                  100\n",
      "Karbuja (Musk Melon)         100\n",
      "Apple                        100\n",
      "Orange                       100\n",
      "Papaya                       100\n",
      "Coconut                      100\n",
      "Cotton                       100\n",
      "Jute                         100\n",
      "Coffee                       100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Imbalance Checking \n",
    "print(df['label'].value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b18ce7a-b086-4218-a84e-fc1759b21504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode crop labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b21c1f71-67aa-4b4e-be58-e42d7fe63037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising Numerical Values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "df[['N', 'P', 'K', 'ph', 'humidity']] = scaler.fit_transform(df[['N', 'P', 'K', 'ph', 'humidity']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb805951-0086-41e9-97ab-0525ad47d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Spliting \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into features (X) and target (y)\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66ace097-f63a-45ce-b0c6-24322eff376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['N', 'P', 'K', 'ph', 'humidity', 'rainfall', 'temperature']\n",
    "X_train = X_train[selected_features]\n",
    "X_test = X_test[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03604282-0f20-4bc7-bdc7-4ab3fc1d6685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02a12be2-eb69-422b-a529-8477b80e4720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ac1020b-f80b-4209-8aec-a4aabaf0f970",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'crop_recommendation.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the dataset (update the path as needed)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcrop_recommendation.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Get the range (min and max values) for each column grouped by crop\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_crop_ranges\u001b[39m(df):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'crop_recommendation.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (update the path as needed)\n",
    "df = pd.read_csv(\"crop_recommendation.csv\")\n",
    "\n",
    "# Get the range (min and max values) for each column grouped by crop\n",
    "def get_crop_ranges(df):\n",
    "    crop_ranges = df.groupby(\"label\").agg({\n",
    "        col: [\"min\", \"max\"] for col in df.columns if col != \"label\"\n",
    "    })\n",
    "    return crop_ranges\n",
    "\n",
    "# Compute ranges\n",
    "crop_ranges = get_crop_ranges(df)\n",
    "\n",
    "# Display the result\n",
    "print(crop_ranges)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "crop_ranges.to_csv(\"crop_ranges.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafcba21-983d-4655-b0ac-ed78ed231727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../datasets/sub_crop_data/banana_subcrop_data.csv')\n",
    "\n",
    "# List all distinct sub-crops\n",
    "distinct_subcrops = df['sub-crop'].unique()  # Get unique values\n",
    "print(\"Distinct sub-crops:\", distinct_subcrops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a763e1-40ff-4606-bcac-ac558348faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"../datasets/sub_crop_data/blackgram_subcrop_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define the mapping for label replacement\n",
    "label_mapping = {\n",
    "    \"Urad Dal (Vigna Mungo)\": \"Black Gram\",\n",
    "    \"Basmati Rice\": \"Paddy(Dhan)(Basmati)\",\n",
    "    \"Sapota\" : \"Chickoos\"\n",
    "\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'label' column\n",
    "df[\"sub-crop\"] = df[\"sub-crop\"].replace(label_mapping)\n",
    "\n",
    "# Remove rows where 'label' is 'kidneybean'\n",
    "df = df[df[\"sub-crop\"] != \"Honeydew Melon\"]\n",
    "\n",
    "# Save the modified dataset\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"CSV file updated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f5aa43-1b02-4cb1-a532-90b4d32bf16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalance Checking \n",
    "print(df['sub-crop'].value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb091a8-95e1-4bac-b359-a66bbdf8bff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle  # For saving the model\n",
    "\n",
    "# Step 2: Load the Dataset\n",
    "# Assuming youve downloaded the dataset from Kaggle: https://www.kaggle.com/datasets/atharvaingle/crop-recommendation-dataset\n",
    "data = pd.read_csv('../datasets/Crop_recommendation.csv')  # Replace with your file path\n",
    "\n",
    "# Step 3: Explore the Dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(data.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(data.head())\n",
    "print(\"\\nUnique Crops:\", data['label'].unique())  # 'label' is the target column with crop names\n",
    "\n",
    "# Step 4: Preprocess the Data\n",
    "# Features (N, P, K, temperature, humidity, pH, rainfall)\n",
    "X = data[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    "# Target (crop names)\n",
    "y = data['label']\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Train the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)  # 100 trees as a good default\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Evaluate the Model\n",
    "y_pred = rf_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")  # Should be close to 99.5% as per your paper\n",
    "\n",
    "# Step 7: Save the Model for Deployment\n",
    "with open('main_crop_model.pkl', 'wb') as file:\n",
    "    pickle.dump(rf_model, file)\n",
    "print(\"Model saved as 'main_crop_model.pkl'\")\n",
    "\n",
    "# Step 8: Function to Predict Crop (For User Input)\n",
    "def predict_crop(N, P, K, temperature, humidity, ph, rainfall):\n",
    "    # Load the saved model\n",
    "    with open('main_crop_model.pkl', 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "    \n",
    "    # Prepare input data as a 2D array (since model expects a matrix)\n",
    "    input_data = np.array([[N, P, K, temperature, humidity, ph, rainfall]])\n",
    "    \n",
    "    # Make prediction\n",
    "    predicted_crop = model.predict(input_data)[0]\n",
    "    return predicted_crop\n",
    "\n",
    "# Example Prediction\n",
    "# Test with sample input (replace with actual values)\n",
    "sample_input = [90, 42, 43, 20.8, 82.0, 6.5, 202.9]  # Example: N, P, K, temp, humidity, pH, rainfall\n",
    "predicted_crop = predict_crop(*sample_input)\n",
    "print(f\"Predicted Crop: {predicted_crop}\")\n",
    "\n",
    "# Optional: Create a Crop Dictionary for Interpretability (as mentioned in your paper)\n",
    "crop_dict = {i: crop for i, crop in enumerate(data['label'].unique())}\n",
    "print(\"\\nCrop Dictionary:\", crop_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343d6229-679c-42f1-87c9-82a936c20cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "# Suppress sklearn warnings (optional, remove if you want to see them)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Step 1: Load and Train the Model (Run Once)\n",
    "def train_and_save_model():\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv('../datasets/Crop_recommendation.csv')  # Your file path\n",
    "    \n",
    "    # Features and target\n",
    "    X = data[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    "    y = data['label']\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train Random Forest\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    print(f\"Model Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    \n",
    "    # Save the model\n",
    "    with open('main_crop_model.pkl', 'wb') as file:\n",
    "        pickle.dump(rf_model, file)\n",
    "    print(\"Model saved as 'main_crop_model.pkl'\")\n",
    "    \n",
    "    return rf_model\n",
    "\n",
    "# Step 2: Define Realistic Ranges\n",
    "realistic_ranges = {\n",
    "    'N': (0, 200), 'P': (0, 200), 'K': (0, 250), 'temperature': (5, 50),\n",
    "    'humidity': (0, 100), 'ph': (3, 11), 'rainfall': (0, 500)\n",
    "}\n",
    "\n",
    "# Step 3: Input Validation and Preprocessing\n",
    "def validate_and_preprocess_input(N, P, K, temperature, humidity, ph, rainfall):\n",
    "    inputs = {'N': N, 'P': P, 'K': K, 'temperature': temperature, \n",
    "              'humidity': humidity, 'ph': ph, 'rainfall': rainfall}\n",
    "    \n",
    "    # Check and convert input types\n",
    "    for param, val in inputs.items():\n",
    "        try:\n",
    "            inputs[param] = float(val)  # Convert to float, catch invalid types\n",
    "        except (ValueError, TypeError):\n",
    "            return False, f\"Invalid input: {param} must be a number\"\n",
    "    \n",
    "    # Validate and cap values\n",
    "    capped_inputs = {}\n",
    "    warnings_list = []\n",
    "    for param, val in inputs.items():\n",
    "        min_val, max_val = realistic_ranges[param]\n",
    "        if val < min_val or val > max_val:\n",
    "            warnings_list.append(f\"{param} ({val}) outside realistic range ({min_val}-{max_val}), capped\")\n",
    "            capped_inputs[param] = max(min_val, min(val, max_val))\n",
    "        else:\n",
    "            capped_inputs[param] = val\n",
    "    \n",
    "    return True, capped_inputs, warnings_list\n",
    "\n",
    "# Step 4: Robust Prediction Function\n",
    "def predict_crop_robust(N, P, K, temperature, humidity, ph, rainfall, confidence_threshold=0.7):\n",
    "    try:\n",
    "        # Load the model\n",
    "        with open('main_crop_model.pkl', 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "        \n",
    "        # Validate and preprocess input\n",
    "        is_valid, capped_inputs_or_error, warnings = validate_and_preprocess_input(\n",
    "            N, P, K, temperature, humidity, ph, rainfall\n",
    "        )\n",
    "        if not is_valid:\n",
    "            return {\"error\": capped_inputs_or_error, \"prediction\": None, \"confidence\": 0}\n",
    "        \n",
    "        # Prepare input as DataFrame to match training format\n",
    "        input_df = pd.DataFrame([[\n",
    "            capped_inputs_or_error['N'], capped_inputs_or_error['P'], capped_inputs_or_error['K'],\n",
    "            capped_inputs_or_error['temperature'], capped_inputs_or_error['humidity'],\n",
    "            capped_inputs_or_error['ph'], capped_inputs_or_error['rainfall']\n",
    "        ]], columns=['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall'])\n",
    "        \n",
    "        # Predict crop and confidence\n",
    "        predicted_crop = model.predict(input_df)[0]\n",
    "        probabilities = model.predict_proba(input_df)[0]\n",
    "        max_prob = float(max(probabilities))  # Convert np.float64 to float\n",
    "        \n",
    "        # Decision logic\n",
    "        result = {\n",
    "            \"prediction\": predicted_crop,\n",
    "            \"confidence\": max_prob,\n",
    "            \"warnings\": warnings if warnings else None\n",
    "        }\n",
    "        \n",
    "        if max_prob < confidence_threshold:\n",
    "            result[\"message\"] = (f\"Low confidence ({max_prob:.2f} < {confidence_threshold}). \"\n",
    "                                \"Prediction may be unreliable. Consider a general crop like 'maize'.\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        return {\"error\": \"Model file 'main_crop_model.pkl' not found\", \"prediction\": None, \"confidence\": 0}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Prediction failed: {str(e)}\", \"prediction\": None, \"confidence\": 0}\n",
    "\n",
    "# Step 5: Test the Robust Model\n",
    "if __name__ == \"__main__\":\n",
    "    # Train the model (run once, comment out after)\n",
    "    train_and_save_model()\n",
    "    \n",
    "    # Test cases\n",
    "    test_cases = [\n",
    "        [91,43,44,20,85,7,200],  # Normal input\n",
    "        [500, 200, 300, 50.0, 10.0, 14.0, 1000.0],  # Extreme input\n",
    "        [-10, 50, 60, 25.0, 75.0, 7.0, 150.0],  # Negative value\n",
    "        [100, \"invalid\", 60, 25.0, 75.0, 7.0, 150.0]  # Invalid type\n",
    "    ]\n",
    "    \n",
    "    for i, test_input in enumerate(test_cases, 1):\n",
    "        print(f\"\\nTest Case {i}: {test_input}\")\n",
    "        result = predict_crop_robust(*test_input)\n",
    "        print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e943385a-ff20-4327-b07a-01c6f2017af8",
   "metadata": {},
   "source": [
    "# Train With Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b43749-bc5d-4280-b0d7-8c199bebb159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "\n",
    "def compare_models():\n",
    "    # Load dataset\n",
    "    data = pd.read_csv('../datasets/Crop_recommendation.csv')\n",
    "    X = data[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    "    y = data['label']\n",
    "    \n",
    "    # Encode string labels to integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define models\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"KNN (k=5)\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"SVM (Linear)\": SVC(kernel='linear', probability=True),\n",
    "        \"SVM (RBF)\": SVC(kernel='rbf', probability=True),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "        \"Naive Bayes\": GaussianNB(),\n",
    "        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "    }\n",
    "\n",
    "    # Compare model accuracies\n",
    "    print(\"\\n--- Model Accuracy Comparison ---\")\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        print(f\"{name}: {acc * 100:.2f}%\")\n",
    "\n",
    "compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24ec7b9-1112-4e61-8e7a-2635103dc23a",
   "metadata": {},
   "source": [
    "# Save Model Comparison as PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445e91dc-1045-4143-ab3f-dc968feaa881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib import colors\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.platypus import PageTemplate, Frame, NextPageTemplate\n",
    "from reportlab.platypus.flowables import KeepTogether\n",
    "from reportlab.graphics.shapes import Line\n",
    "from datetime import datetime\n",
    "\n",
    "def compare_models():\n",
    "    # Load dataset\n",
    "    data = pd.read_csv('../datasets/Crop_recommendation.csv')\n",
    "    X = data[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    "    y = data['label']\n",
    "    \n",
    "    # Encode string labels to integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define models\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"KNN (k=5)\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"SVM (Linear)\": SVC(kernel='linear', probability=True),\n",
    "        \"SVM (RBF)\": SVC(kernel='rbf', probability=True),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "        \"Naive Bayes\": GaussianNB(),\n",
    "        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "    }\n",
    "\n",
    "    # Store results\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        results.append((name, acc * 100))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def header(canvas, doc):\n",
    "    canvas.saveState()\n",
    "    canvas.setFont('Helvetica-Bold', 10)\n",
    "    canvas.setFillColor(colors.darkgreen)\n",
    "    canvas.drawString(inch, doc.pagesize[1] - 0.75 * inch, \"Crop Combination Recommendation and Price Prediction\")\n",
    "    canvas.setFont('Helvetica', 8)\n",
    "    canvas.setFillColor(colors.grey)\n",
    "    canvas.drawRightString(doc.pagesize[0] - inch, doc.pagesize[1] - 0.75 * inch, f\"Page {doc.page}\")\n",
    "    canvas.line(inch, doc.pagesize[1] - 0.85 * inch, doc.pagesize[0] - inch, doc.pagesize[1] - 0.85 * inch)\n",
    "    canvas.restoreState()\n",
    "\n",
    "def generate_pdf_report(results, output_filename=\"Crop_Recommendation_Model_Comparison_Report.pdf\"):\n",
    "    # Set up PDF document\n",
    "    doc = SimpleDocTemplate(output_filename, pagesize=letter, rightMargin=inch, leftMargin=inch, topMargin=1.5 * inch, bottomMargin=inch)\n",
    "    styles = getSampleStyleSheet()\n",
    "\n",
    "    # Custom styles\n",
    "    cover_title_style = ParagraphStyle(\n",
    "        name='CoverTitle',\n",
    "        fontName='Helvetica-Bold',\n",
    "        fontSize=18,\n",
    "        textColor=colors.darkgreen,\n",
    "        alignment=1,  # Center\n",
    "        spaceAfter=12\n",
    "    )\n",
    "    cover_subtitle_style = ParagraphStyle(\n",
    "        name='CoverSubtitle',\n",
    "        fontName='Helvetica',\n",
    "        fontSize=12,\n",
    "        textColor=colors.black,\n",
    "        alignment=1,  # Center\n",
    "        spaceAfter=8\n",
    "    )\n",
    "    heading_style = ParagraphStyle(\n",
    "        name='Heading2',\n",
    "        fontName='Helvetica-Bold',\n",
    "        fontSize=14,\n",
    "        textColor=colors.darkblue,\n",
    "        spaceBefore=12,\n",
    "        spaceAfter=6\n",
    "    )\n",
    "    body_style = ParagraphStyle(\n",
    "        name='BodyText',\n",
    "        fontName='Times-Roman',\n",
    "        fontSize=10,\n",
    "        leading=12,\n",
    "        spaceAfter=8,\n",
    "        alignment=4,  # Justified\n",
    "        wordWrap='CJK'  # Better handling of long text\n",
    "    )\n",
    "\n",
    "    # Elements for the document\n",
    "    elements = []\n",
    "\n",
    "    # Cover page\n",
    "    elements.append(Spacer(1, 2 * inch))\n",
    "    elements.append(Paragraph(\"Crop Combination Recommendation and Price Prediction\", cover_title_style))\n",
    "    elements.append(Paragraph(\"CS6611 Creative and Innovative Project\", cover_subtitle_style))\n",
    "    elements.append(Paragraph(\"Submitted by: [Your Name]\", cover_subtitle_style))\n",
    "    elements.append(Paragraph(f\"Date: {datetime.now().strftime('%Y-%m-%d')}\", cover_subtitle_style))\n",
    "    elements.append(Spacer(1, 2.5 * inch))\n",
    "    elements.append(Paragraph(\"Department of Computer Science\", cover_subtitle_style))\n",
    "    elements.append(Paragraph(\"[Your University Name]\", cover_subtitle_style))\n",
    "    elements.append(PageBreak())\n",
    "\n",
    "    # Content page template with header\n",
    "    frame = Frame(doc.leftMargin, doc.bottomMargin, doc.width, doc.height - 1 * inch)\n",
    "    template = PageTemplate(id='content', frames=[frame], onPage=header)\n",
    "    doc.addPageTemplates([template])\n",
    "    elements.append(NextPageTemplate('content'))\n",
    "\n",
    "    # Introduction\n",
    "    elements.append(Paragraph(\"Introduction\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"This report is part of the CS6611 Creative and Innovative Project, titled 'Crop Combination Recommendation and Price Prediction.' \"\n",
    "        \"The project aims to leverage machine learning to recommend suitable crops based on soil and environmental factors and predict their market prices. \"\n",
    "        \"This analysis focuses on evaluating various classification models to recommend crops using the Crop Recommendation dataset, which includes features such as \"\n",
    "        \"Nitrogen (N), Phosphorus (P), Potassium (K), temperature, humidity, pH, and rainfall.\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    # Methodology\n",
    "    elements.append(Paragraph(\"Methodology\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"The dataset was preprocessed to encode categorical crop labels numerically using LabelEncoder. \"\n",
    "        \"It was then split into 80% training and 20% testing sets with a fixed random seed for reproducibility. \"\n",
    "        \"The following models were evaluated: Logistic Regression, K-Nearest Neighbors (KNN with k=5), Support Vector Machine (SVM) with linear and RBF kernels, \"\n",
    "        \"Decision Tree, Random Forest, Naive Bayes, and XGBoost. Model performance was assessed using accuracy on the test set.\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    # Results\n",
    "    elements.append(Paragraph(\"Results\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"The table below presents the accuracy of each model on the test set, indicating their effectiveness in crop recommendation.\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    # Results table with adjusted column widths\n",
    "    total_width = doc.width  # Available width after margins\n",
    "    colWidths = [total_width * 0.65, total_width * 0.35]  # 65% for model name, 35% for accuracy\n",
    "    table_data = [[\"Model\", \"Accuracy (%)\"]] + [[name, f\"{acc:.2f}\"] for name, acc in results]\n",
    "    table = Table(table_data, colWidths=colWidths, rowHeights=[0.4 * inch] * (len(table_data)))\n",
    "    table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), colors.darkgreen),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 10),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 8),\n",
    "        ('TOPPADDING', (0, 0), (-1, -1), 8),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "        ('BACKGROUND', (0, 2), (-1, 2), colors.lightgrey),\n",
    "        ('BACKGROUND', (0, 4), (-1, 4), colors.lightgrey),\n",
    "        ('BACKGROUND', (0, 6), (-1, 6), colors.lightgrey),\n",
    "        ('BACKGROUND', (0, 8), (-1, 8), colors.lightgrey),\n",
    "        ('GRID', (0, 0), (-1, -1), 0.5, colors.black),\n",
    "        ('LEFTPADDING', (0, 0), (-1, -1), 6),\n",
    "        ('RIGHTPADDING', (0, 0), (-1, -1), 6),\n",
    "    ]))\n",
    "    elements.append(KeepTogether(table))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    # Discussion\n",
    "    elements.append(Paragraph(\"Discussion\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"The results highlight the superior performance of ensemble methods like Random Forest and XGBoost, which achieved accuracies above 98%. \"\n",
    "        \"These models likely benefit from their ability to model complex, non-linear relationships in the data. \"\n",
    "        \"KNN and SVM (RBF) also performed well, indicating the presence of localized and non-linear patterns. \"\n",
    "        \"Decision Tree and Naive Bayes had lower accuracies, possibly due to overfitting and the assumption of feature independence, respectively. \"\n",
    "        \"These findings suggest that ensemble methods are well-suited for crop recommendation tasks in this project.\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    # Conclusion\n",
    "    elements.append(Paragraph(\"Conclusion\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"This analysis, conducted as part of the CS6611 project, demonstrates the effectiveness of machine learning models in recommending crops based on environmental and soil data. \"\n",
    "        \"Ensemble methods like Random Forest and XGBoost are recommended for their high accuracy. \"\n",
    "        \"Future work will focus on integrating price prediction models and exploring additional features to enhance the system's applicability in agricultural decision-making.\",\n",
    "        body_style\n",
    "    ))\n",
    "\n",
    "    # Build PDF\n",
    "    doc.build(elements)\n",
    "    print(f\"Report generated: {output_filename}\")\n",
    "\n",
    "# Run comparison and generate report\n",
    "results = compare_models()\n",
    "generate_pdf_report(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c243f56e-e33f-42ab-b191-a14540b367f8",
   "metadata": {},
   "source": [
    "# Overall Models Performance Metrics Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d566f472-6134-48ee-b39d-fc5a083077de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib import colors\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from datetime import datetime\n",
    "\n",
    "def compare_models():\n",
    "    # Load dataset\n",
    "    data = pd.read_csv('../datasets/Crop_recommendation.csv')\n",
    "    X = data[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    "    y = data['label']\n",
    "    \n",
    "    # Encode string labels to integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define models\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"KNN (k=5)\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"SVM (Linear)\": SVC(kernel='linear', probability=True),\n",
    "        \"SVM (RBF)\": SVC(kernel='rbf', probability=True),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "        \"Naive Bayes\": GaussianNB(),\n",
    "        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "    }\n",
    "\n",
    "    # Store results\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        results.append((name, acc * 100))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def generate_pdf_report(results, output_filename=\"Model_Comparison_Report.pdf\"):\n",
    "    # Set up PDF document\n",
    "    doc = SimpleDocTemplate(output_filename, pagesize=letter)\n",
    "    styles = getSampleStyleSheet()\n",
    "    elements = []\n",
    "\n",
    "    # Custom styles\n",
    "    title_style = styles['Title']\n",
    "    heading_style = styles['Heading2']\n",
    "    body_style = ParagraphStyle(\n",
    "        name='BodyText',\n",
    "        parent=styles['Normal'],\n",
    "        fontSize=10,\n",
    "        leading=12,\n",
    "        spaceAfter=8\n",
    "    )\n",
    "\n",
    "    # Title\n",
    "    elements.append(Paragraph(\"Machine Learning Model Comparison Report\", title_style))\n",
    "    elements.append(Spacer(1, 12))\n",
    "    elements.append(Paragraph(f\"Generated on: {datetime.now().strftime('%Y-%m-%d')}\", body_style))\n",
    "    elements.append(Spacer(1, 24))\n",
    "\n",
    "    # Introduction\n",
    "    elements.append(Paragraph(\"Introduction\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"This report presents a comparative analysis of various machine learning models applied to the Crop Recommendation dataset. \"\n",
    "        \"The dataset includes features such as Nitrogen (N), Phosphorus (P), Potassium (K), temperature, humidity, pH, and rainfall, \"\n",
    "        \"used to predict the most suitable crop for given conditions. The goal is to evaluate the accuracy of different classification models.\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    # Methodology\n",
    "    elements.append(Paragraph(\"Methodology\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"The dataset was split into 80% training and 20% testing sets with a random seed for reproducibility. \"\n",
    "        \"The following models were evaluated: Logistic Regression, K-Nearest Neighbors (KNN), Support Vector Machine (SVM) with linear and RBF kernels, \"\n",
    "        \"Decision Tree, Random Forest, Naive Bayes, and XGBoost. Accuracy was used as the performance metric, calculated on the test set. \"\n",
    "        \"Categorical crop labels were encoded numerically using LabelEncoder to ensure compatibility with all models.\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    # Results\n",
    "    elements.append(Paragraph(\"Results\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"The table below summarizes the accuracy of each model on the test set.\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    # Create table for results\n",
    "    table_data = [[\"Model\", \"Accuracy (%)\"]] + [[name, f\"{acc:.2f}\"] for name, acc in results]\n",
    "    table = Table(table_data)\n",
    "    table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 10),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\n",
    "        ('GRID', (0, 0), (-1, -1), 1, colors.black),\n",
    "    ]))\n",
    "    elements.append(table)\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    # Discussion\n",
    "    elements.append(Paragraph(\"Discussion\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"The results indicate that ensemble methods like Random Forest and XGBoost achieved the highest accuracies, likely due to their ability to capture complex patterns in the data. \"\n",
    "        \"KNN and SVM (RBF) also performed well, suggesting that non-linear relationships are present in the dataset. \"\n",
    "        \"Decision Tree and Naive Bayes had lower accuracies, possibly due to overfitting and the assumption of feature independence, respectively. \"\n",
    "        \"Future work could involve hyperparameter tuning, cross-validation, or additional metrics like precision and recall to further evaluate model performance.\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    # Conclusion\n",
    "    elements.append(Paragraph(\"Conclusion\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"This analysis provides a comprehensive comparison of machine learning models for crop recommendation. \"\n",
    "        \"Ensemble methods are recommended for this task due to their superior performance. The results can guide agricultural decision-making and future model optimization.\",\n",
    "        body_style\n",
    "    ))\n",
    "\n",
    "    # Build PDF\n",
    "    doc.build(elements)\n",
    "    print(f\"Report generated: {output_filename}\")\n",
    "\n",
    "# Run comparison and generate report\n",
    "results = compare_models()\n",
    "generate_pdf_report(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a2d0f9-6067-49dc-96cf-c26439d8c751",
   "metadata": {},
   "source": [
    "# Performance metrics calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c882f1bb-334a-41a0-a808-2e32ef44b851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics:\n",
      "  Accuracy (%): 99.05\n",
      "  Precision (Macro) (%): 99.13\n",
      "  Precision (Weighted) (%): 99.22\n",
      "  Recall (Macro) (%): 99.09\n",
      "  Recall (Weighted) (%): 99.05\n",
      "  F1-Score (Macro) (%): 99.02\n",
      "  F1-Score (Weighted) (%): 99.05\n",
      "  Average Confidence: 0.96\n",
      "  Low Confidence Rate (%): 0.95\n",
      "\n",
      "Confusion Matrix Statistics (Per Class):\n",
      "  Apple: TP=23, FP=0, FN=0, TN=397\n",
      "  Banana: TP=16, FP=0, FN=0, TN=404\n",
      "  Bengal Gram (Gram)(Whole): TP=26, FP=0, FN=0, TN=394\n",
      "  Black Gram Dal (Urd Dal): TP=18, FP=0, FN=0, TN=402\n",
      "  Coconut: TP=20, FP=0, FN=0, TN=400\n",
      "  Coffee: TP=22, FP=0, FN=0, TN=398\n",
      "  Cotton: TP=14, FP=0, FN=0, TN=406\n",
      "  Grapes: TP=18, FP=0, FN=0, TN=402\n",
      "  Green Gram (Moong)(Whole): TP=26, FP=0, FN=0, TN=394\n",
      "  Jute: TP=18, FP=4, FN=0, TN=398\n",
      "  Karbuja (Musk Melon): TP=27, FP=0, FN=0, TN=393\n",
      "  Lentil (Masur)(Whole): TP=17, FP=0, FN=0, TN=403\n",
      "  Maize: TP=17, FP=0, FN=0, TN=403\n",
      "  Mango: TP=20, FP=0, FN=0, TN=400\n",
      "  Moath Dal: TP=24, FP=0, FN=0, TN=396\n",
      "  Orange: TP=23, FP=0, FN=0, TN=397\n",
      "  Papaya: TP=17, FP=0, FN=0, TN=403\n",
      "  Pegeon Pea (Arhar Fali): TP=20, FP=0, FN=0, TN=400\n",
      "  Pomegranate: TP=18, FP=0, FN=0, TN=402\n",
      "  Rice: TP=17, FP=0, FN=4, TN=399\n",
      "  Water Melon: TP=15, FP=0, FN=0, TN=405\n",
      "\n",
      "Common Misclassifications:\n",
      "  - Rice misclassified as Jute (4 times)\n",
      "\n",
      "Test Case 1: [91, 43, 44, 20, 85, 7, 200]\n",
      "Result: {'prediction': 'Rice', 'confidence': 0.91, 'warnings': None}\n",
      "\n",
      "Test Case 2: [500, 200, 300, 50.0, 10.0, 14.0, 1000.0]\n",
      "Result: {'prediction': 'Grapes', 'confidence': 0.2, 'warnings': ['N (500.0) outside realistic range (0-200), capped', 'K (300.0) outside realistic range (0-250), capped', 'ph (14.0) outside realistic range (3-11), capped', 'rainfall (1000.0) outside realistic range (0-500), capped'], 'message': \"Low confidence (0.20 < 0.7). Prediction may be unreliable. Consider a general crop like 'maize'.\"}\n",
      "\n",
      "Test Case 3: [-10, 50, 60, 25.0, 75.0, 7.0, 150.0]\n",
      "Result: {'prediction': 'Papaya', 'confidence': 0.3, 'warnings': ['N (-10.0) outside realistic range (0-200), capped'], 'message': \"Low confidence (0.30 < 0.7). Prediction may be unreliable. Consider a general crop like 'maize'.\"}\n",
      "\n",
      "Test Case 4: [100, 'invalid', 60, 25.0, 75.0, 7.0, 150.0]\n",
      "Result: {'error': 'Prediction failed: not enough values to unpack (expected 3, got 2)', 'prediction': None, 'confidence': 0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "# Suppress sklearn warnings (optional, remove if you want to see them)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Step 1: Load and Train the Model with Comprehensive Evaluation\n",
    "def train_and_save_model():\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv('../datasets/Crop_recommendation.csv')  # Your file path\n",
    "    \n",
    "    # Features and target\n",
    "    X = data[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    "    y = data['label']\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train Random Forest\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    probabilities = rf_model.predict_proba(X_test)\n",
    "    confidences = np.max(probabilities, axis=1)\n",
    "    \n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "    precision_macro = precision_score(y_test, y_pred, average='macro', zero_division=0) * 100\n",
    "    precision_weighted = precision_score(y_test, y_pred, average='weighted', zero_division=0) * 100\n",
    "    recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0) * 100\n",
    "    recall_weighted = recall_score(y_test, y_pred, average='weighted', zero_division=0) * 100\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro', zero_division=0) * 100\n",
    "    f1_weighted = f1_score(y_test, y_pred, average='weighted', zero_division=0) * 100\n",
    "    avg_confidence = np.mean(confidences)\n",
    "    low_confidence_rate = np.sum(confidences < 0.7) / len(confidences) * 100\n",
    "    \n",
    "    # Confusion Matrix Statistics\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=rf_model.classes_)\n",
    "    cm_stats = {}\n",
    "    for i, class_name in enumerate(rf_model.classes_):\n",
    "        tp = cm[i, i]\n",
    "        fp = cm[:, i].sum() - tp\n",
    "        fn = cm[i, :].sum() - tp\n",
    "        tn = cm.sum() - (tp + fp + fn)\n",
    "        cm_stats[class_name] = {'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn}\n",
    "    \n",
    "    # Find common misclassifications (top off-diagonal elements)\n",
    "    misclassifications = []\n",
    "    cm_array = cm.copy()\n",
    "    np.fill_diagonal(cm_array, 0)\n",
    "    for _ in range(min(5, cm_array.size)):  # Top 5 misclassifications\n",
    "        max_idx = np.argmax(cm_array)\n",
    "        if cm_array.flat[max_idx] == 0:\n",
    "            break\n",
    "        row, col = np.unravel_index(max_idx, cm_array.shape)\n",
    "        misclassifications.append(\n",
    "            f\"{rf_model.classes_[row]} misclassified as {rf_model.classes_[col]} ({cm_array[row, col]} times)\"\n",
    "        )\n",
    "        cm_array[row, col] = 0\n",
    "    \n",
    "    metrics = {\n",
    "        'Accuracy (%)': accuracy,\n",
    "        'Precision (Macro) (%)': precision_macro,\n",
    "        'Precision (Weighted) (%)': precision_weighted,\n",
    "        'Recall (Macro) (%)': recall_macro,\n",
    "        'Recall (Weighted) (%)': recall_weighted,\n",
    "        'F1-Score (Macro) (%)': f1_macro,\n",
    "        'F1-Score (Weighted) (%)': f1_weighted,\n",
    "        'Average Confidence': avg_confidence,\n",
    "        'Low Confidence Rate (%)': low_confidence_rate\n",
    "    }\n",
    "    \n",
    "    # Save the model\n",
    "    with open('main_crop_model.pkl', 'wb') as file:\n",
    "        pickle.dump(rf_model, file)\n",
    "    \n",
    "    return metrics, cm_stats, misclassifications, rf_model\n",
    "\n",
    "# Step 2: Define Realistic Ranges\n",
    "realistic_ranges = {\n",
    "    'N': (0, 200), 'P': (0, 200), 'K': (0, 250), 'temperature': (5, 50),\n",
    "    'humidity': (0, 100), 'ph': (3, 11), 'rainfall': (0, 500)\n",
    "}\n",
    "\n",
    "# Step 3: Input Validation and Preprocessing\n",
    "def validate_and_preprocess_input(N, P, K, temperature, humidity, ph, rainfall):\n",
    "    inputs = {'N': N, 'P': P, 'K': K, 'temperature': temperature, \n",
    "              'humidity': humidity, 'ph': ph, 'rainfall': rainfall}\n",
    "    \n",
    "    # Check and convert input types\n",
    "    for param, val in inputs.items():\n",
    "        try:\n",
    "            inputs[param] = float(val)\n",
    "        except (ValueError, TypeError):\n",
    "            return False, f\"Invalid input: {param} must be a number\"\n",
    "    \n",
    "    # Validate and cap values\n",
    "    capped_inputs = {}\n",
    "    warnings_list = []\n",
    "    for param, val in inputs.items():\n",
    "        min_val, max_val = realistic_ranges[param]\n",
    "        if val < min_val or val > max_val:\n",
    "            warnings_list.append(f\"{param} ({val}) outside realistic range ({min_val}-{max_val}), capped\")\n",
    "            capped_inputs[param] = max(min_val, min(val, max_val))\n",
    "        else:\n",
    "            capped_inputs[param] = val\n",
    "    \n",
    "    return True, capped_inputs, warnings_list\n",
    "\n",
    "# Step 4: Robust Prediction Function\n",
    "def predict_crop_robust(N, P, K, temperature, humidity, ph, rainfall, confidence_threshold=0.7):\n",
    "    try:\n",
    "        # Load the model\n",
    "        with open('main_crop_model.pkl', 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "        \n",
    "        # Validate and preprocess input\n",
    "        is_valid, capped_inputs_or_error, warnings = validate_and_preprocess_input(\n",
    "            N, P, K, temperature, humidity, ph, rainfall\n",
    "        )\n",
    "        if not is_valid:\n",
    "            return {\"error\": capped_inputs_or_error, \"prediction\": None, \"confidence\": 0}\n",
    "        \n",
    "        # Prepare input as DataFrame\n",
    "        input_df = pd.DataFrame([[\n",
    "            capped_inputs_or_error['N'], capped_inputs_or_error['P'], capped_inputs_or_error['K'],\n",
    "            capped_inputs_or_error['temperature'], capped_inputs_or_error['humidity'],\n",
    "            capped_inputs_or_error['ph'], capped_inputs_or_error['rainfall']\n",
    "        ]], columns=['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall'])\n",
    "        \n",
    "        # Predict crop and confidence\n",
    "        predicted_crop = model.predict(input_df)[0]\n",
    "        probabilities = model.predict_proba(input_df)[0]\n",
    "        max_prob = float(max(probabilities))\n",
    "        \n",
    "        # Decision logic\n",
    "        result = {\n",
    "            \"prediction\": predicted_crop,\n",
    "            \"confidence\": max_prob,\n",
    "            \"warnings\": warnings if warnings else None\n",
    "        }\n",
    "        \n",
    "        if max_prob < confidence_threshold:\n",
    "            result[\"message\"] = (f\"Low confidence ({max_prob:.2f} < {confidence_threshold}). \"\n",
    "                                \"Prediction may be unreliable. Consider a general crop like 'maize'.\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        return {\"error\": \"Model file 'main_crop_model.pkl' not found\", \"prediction\": None, \"confidence\": 0}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Prediction failed: {str(e)}\", \"prediction\": None, \"confidence\": 0}\n",
    "\n",
    "# Step 5: Test the Model\n",
    "if __name__ == \"__main__\":\n",
    "    # Train and evaluate the model\n",
    "    metrics, cm_stats, misclassifications, rf_model = train_and_save_model()\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"Performance Metrics:\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"  {key}: {value:.2f}\")\n",
    "    \n",
    "    # Print confusion matrix statistics\n",
    "    print(\"\\nConfusion Matrix Statistics (Per Class):\")\n",
    "    for class_name, stats in cm_stats.items():\n",
    "        print(f\"  {class_name}: TP={stats['TP']}, FP={stats['FP']}, FN={stats['FN']}, TN={stats['TN']}\")\n",
    "    \n",
    "    # Print common misclassifications\n",
    "    print(\"\\nCommon Misclassifications:\")\n",
    "    if misclassifications:\n",
    "        for mis in misclassifications:\n",
    "            print(f\"  - {mis}\")\n",
    "    else:\n",
    "        print(\"  None\")\n",
    "    \n",
    "    # Test cases\n",
    "    test_cases = [\n",
    "        [91, 43, 44, 20, 85, 7, 200],  # Normal input\n",
    "        [500, 200, 300, 50.0, 10.0, 14.0, 1000.0],  # Extreme input\n",
    "        [-10, 50, 60, 25.0, 75.0, 7.0, 150.0],  # Negative value\n",
    "        [100, \"invalid\", 60, 25.0, 75.0, 7.0, 150.0]  # Invalid type\n",
    "    ]\n",
    "    \n",
    "    for i, test_input in enumerate(test_cases, 1):\n",
    "        print(f\"\\nTest Case {i}: {test_input}\")\n",
    "        result = predict_crop_robust(*test_input)\n",
    "        print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483f6928-75c9-465e-bb6a-5edc6eebfe1a",
   "metadata": {},
   "source": [
    "# Overall pdf generation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09337403-addd-485a-ad1b-e9315f8183d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "import os\n",
    "import math\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib import colors\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak, HRFlowable\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.platypus import PageTemplate, Frame, NextPageTemplate\n",
    "from reportlab.platypus.flowables import KeepTogether\n",
    "from datetime import datetime\n",
    "\n",
    "# Define Colors\n",
    "DARK_GREEN = colors.HexColor(\"#2E7D32\")\n",
    "DARK_BLUE = colors.HexColor(\"#1565C0\")\n",
    "SOFT_GRAY = colors.HexColor(\"#ECEFF1\")\n",
    "BLACK = colors.HexColor(\"#212121\")\n",
    "GRAY = colors.HexColor(\"#757575\")\n",
    "\n",
    "# Realistic Ranges\n",
    "realistic_ranges = {\n",
    "    'N': (0, 200), 'P': (0, 200), 'K': (0, 250), 'temperature': (5, 50),\n",
    "    'humidity': (0, 100), 'ph': (3, 11), 'rainfall': (0, 500)\n",
    "}\n",
    "\n",
    "# Crop Mapping\n",
    "crop_name_mapping = {\n",
    "    'Rice': 'Rice_subcrop_data.csv',\n",
    "    'Maize': 'Maize_subcrop_data.csv',\n",
    "    'Bengal Gram (Gram)(Whole)': 'Bengal Gram (Gram)(Whole)_subcrop_data.csv',\n",
    "    'Pegeon Pea (Arhar Fali)': 'Pegeon Pea (Arhar Fali)_subcrop_data.csv',\n",
    "    'Moath Dal': 'Moath Dal_subcrop_data.csv',\n",
    "    'Green Gram (Moong)(Whole)': 'Green Gram (Moong)(Whole)_subcrop_data.csv',\n",
    "    'Black Gram Dal (Urd Dal)': 'Black Gram Dal (Urd Dal)_subcrop_data.csv',\n",
    "    'Lentil (Masur)(Whole)': 'Lentil (Masur)(Whole)_subcrop_data.csv',\n",
    "    'Pomegranate': 'Pomegranate_subcrop_data.csv',\n",
    "    'Banana': 'Banana_subcrop_data.csv',\n",
    "    'Mango': 'Mango_subcrop_data.csv',\n",
    "    'Grapes': 'Grapes_subcrop_data.csv',\n",
    "    'Water Melon': 'Water Melon_subcrop_data.csv',\n",
    "    'Karbuja (Musk Melon)': 'Karbuja (Musk Melon)_subcrop_data.csv',\n",
    "    'Apple': 'Apple_subcrop_data.csv',\n",
    "    'Orange': 'Orange_subcrop_data.csv',\n",
    "    'Papaya': 'Papaya_subcrop_data.csv',\n",
    "    'Coconut': 'Coconut_subcrop_data.csv',\n",
    "    'Cotton': 'Cotton_subcrop_data.csv',\n",
    "    'Jute': 'Jute_subcrop_data.csv',\n",
    "    'Coffee': 'Coffee_subcrop_data.csv'\n",
    "}\n",
    "\n",
    "# SubCropRecommender Class\n",
    "class SubCropRecommender:\n",
    "    def __init__(self, main_model_path='main_crop_model.pkl', subcrop_dir='C:/Projects/Creative & Innovative Project/datasets/sub_crop_data/'):\n",
    "        self.main_model = self.load_main_crop_model(main_model_path)\n",
    "        self.subcrop_dir = subcrop_dir\n",
    "        self.crop_name_mapping = crop_name_mapping\n",
    "        self.realistic_ranges = realistic_ranges\n",
    "\n",
    "    def load_main_crop_model(self, path):\n",
    "        try:\n",
    "            with open(path, 'rb') as file:\n",
    "                model_data = pickle.load(file)\n",
    "                return model_data\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading main crop model: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def validate_and_preprocess_input(self, N, P, K, temperature, humidity, ph, rainfall):\n",
    "        inputs = {'N': N, 'P': P, 'K': K, 'temperature': temperature, \n",
    "                  'humidity': humidity, 'ph': ph, 'rainfall': rainfall}\n",
    "        for param, val in inputs.items():\n",
    "            try:\n",
    "                inputs[param] = float(val)\n",
    "            except (ValueError, TypeError):\n",
    "                return False, f\"Invalid input: {param} must be a number\", []\n",
    "        capped_inputs = {}\n",
    "        warnings_list = []\n",
    "        for param, val in inputs.items():\n",
    "            min_val, max_val = self.realistic_ranges[param]\n",
    "            if val < min_val or val > max_val:\n",
    "                warnings_list.append(f\"{param} ({val}) outside realistic range ({min_val}-{max_val}), capped\")\n",
    "                capped_inputs[param] = max(min_val, min(val, max_val))\n",
    "            else:\n",
    "                capped_inputs[param] = val\n",
    "        return True, capped_inputs, warnings_list\n",
    "\n",
    "    def recommend_sub_crops(self, N, P, K, temperature, humidity, ph, rainfall, num_recommendations=3):\n",
    "        try:\n",
    "            if self.main_model is None:\n",
    "                return {\"error\": \"Main crop model not loaded\", \"main_crop\": None, \"sub_crops\": [], \"warnings\": None}\n",
    "            \n",
    "            is_valid, capped_inputs, warnings = self.validate_and_preprocess_input(\n",
    "                N, P, K, temperature, humidity, ph, rainfall\n",
    "            )\n",
    "            if not is_valid:\n",
    "                return {\"error\": capped_inputs, \"main_crop\": None, \"sub_crops\": [], \"warnings\": warnings}\n",
    "            \n",
    "            input_df = pd.DataFrame([[capped_inputs['N'], capped_inputs['P'], \n",
    "                                      capped_inputs['K'], capped_inputs['temperature'], \n",
    "                                      capped_inputs['humidity'], capped_inputs['ph'], \n",
    "                                      capped_inputs['rainfall']]],\n",
    "                                    columns=['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall'])\n",
    "            input_scaled = self.main_model['scaler'].transform(input_df)\n",
    "            main_crop_encoded = self.main_model['model'].predict(input_scaled)[0]\n",
    "            main_crop = self.main_model['label_encoder'].inverse_transform([main_crop_encoded])[0]\n",
    "            main_confidence = float(max(self.main_model['model'].predict_proba(input_scaled)[0]))\n",
    "            \n",
    "            if main_crop not in self.crop_name_mapping:\n",
    "                return {\"error\": f\"No sub-crop mapping for {main_crop}\", \"main_crop\": main_crop, \n",
    "                        \"sub_crops\": [], \"warnings\": warnings}\n",
    "            \n",
    "            subcrop_filename = self.crop_name_mapping[main_crop]\n",
    "            subcrop_file = os.path.join(self.subcrop_dir, subcrop_filename)\n",
    "            \n",
    "            if not os.path.exists(subcrop_file):\n",
    "                return {\"error\": f\"Sub-crop file {subcrop_filename} not found\", \n",
    "                        \"main_crop\": main_crop, \"sub_crops\": [], \"warnings\": warnings}\n",
    "            \n",
    "            sub_crop_df = pd.read_csv(subcrop_file)\n",
    "            required_cols = ['sub-crop', 'N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']\n",
    "            missing_cols = [col for col in required_cols if col not in sub_crop_df.columns]\n",
    "            if missing_cols:\n",
    "                return {\"error\": f\"Missing columns: {missing_cols}\", \"main_crop\": main_crop, \n",
    "                        \"sub_crops\": [], \"warnings\": warnings}\n",
    "            \n",
    "            input_vector = np.array([[capped_inputs['N'], capped_inputs['P'], capped_inputs['K'], \n",
    "                                      capped_inputs['temperature'], capped_inputs['humidity'], \n",
    "                                      capped_inputs['ph'], capped_inputs['rainfall']]])\n",
    "            sub_crop_features = sub_crop_df[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']].values\n",
    "            sub_crop_names = sub_crop_df['sub-crop'].values\n",
    "            \n",
    "            distances = euclidean_distances(input_vector, sub_crop_features)[0]\n",
    "            sub_crops_with_distances = list(zip(sub_crop_names, distances, sub_crop_features))\n",
    "            sorted_sub_crops = sorted(sub_crops_with_distances, key=lambda x: x[1])[:num_recommendations]\n",
    "            recommended_sub_crops = [{\"sub_crop\": crop, \"distance\": float(dist), \"features\": features} \n",
    "                                    for crop, dist, features in sorted_sub_crops]\n",
    "            \n",
    "            return {\n",
    "                \"main_crop\": main_crop,\n",
    "                \"main_confidence\": main_confidence,\n",
    "                \"sub_crops\": recommended_sub_crops,\n",
    "                \"warnings\": warnings if warnings else None\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e), \"main_crop\": None, \"sub_crops\": [], \"warnings\": None}\n",
    "\n",
    "    def calculate_subcrop_accuracy(self, num_recommendations=3):\n",
    "        total_tests = 0\n",
    "        correct_matches = 0\n",
    "        precision_sum = 0\n",
    "        reciprocal_rank_sum = 0\n",
    "        dcg_sum = 0\n",
    "        distances_correct = []\n",
    "        diversity_sum = 0\n",
    "        all_recommended_subcrops = set()\n",
    "        total_unique_subcrops = set()\n",
    "        skipped_datasets = []\n",
    "        evaluated_datasets = []\n",
    "        \n",
    "        with open('subcrop_accuracy_debug.txt', 'w') as debug_file:\n",
    "            for main_crop, filename in self.crop_name_mapping.items():\n",
    "                file_path = os.path.join(self.subcrop_dir, filename)\n",
    "                if not os.path.exists(file_path):\n",
    "                    skipped_datasets.append(f\"{main_crop}: File {filename} not found\")\n",
    "                    debug_file.write(f\"Skipping {main_crop}: {filename} not found\\n\")\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    sub_crop_df = pd.read_csv(file_path)\n",
    "                    required_cols = ['sub-crop', 'N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']\n",
    "                    if not all(col in sub_crop_df.columns for col in required_cols):\n",
    "                        skipped_datasets.append(f\"{main_crop}: Missing required columns\")\n",
    "                        debug_file.write(f\"Skipping {main_crop}: {filename} missing required columns\\n\")\n",
    "                        continue\n",
    "                    \n",
    "                    num_samples = len(sub_crop_df)\n",
    "                    num_unique_subcrops = len(sub_crop_df['sub-crop'].unique())\n",
    "                    if num_samples < 30 or num_unique_subcrops < 3:\n",
    "                        skipped_datasets.append(f\"{main_crop}: Insufficient samples ({num_samples}) or unique sub-crops ({num_unique_subcrops})\")\n",
    "                        debug_file.write(f\"Skipping {main_crop}: Insufficient samples ({num_samples}) or unique sub-crops ({num_unique_subcrops})\\n\")\n",
    "                        continue\n",
    "                    \n",
    "                    evaluated_datasets.append(f\"{main_crop}: {num_samples} samples, {num_unique_subcrops} sub-crops\")\n",
    "                    total_unique_subcrops.update(sub_crop_df['sub-crop'].unique())\n",
    "                    \n",
    "                    for _, row in sub_crop_df.iterrows():\n",
    "                        expected_sub_crop = row['sub-crop']\n",
    "                        test_input = [row['N'], row['P'], row['K'], row['temperature'], \n",
    "                                      row['humidity'], row['ph'], row['rainfall']]\n",
    "                        \n",
    "                        result = self.recommend_sub_crops(*test_input, num_recommendations=num_recommendations)\n",
    "                        \n",
    "                        if \"error\" in result:\n",
    "                            skipped_datasets.append(f\"{main_crop}: Recommendation error - {result['error']}\")\n",
    "                            debug_file.write(f\"Error for {main_crop}: {result['error']}\\n\")\n",
    "                            continue\n",
    "                        \n",
    "                        predicted_sub_crops = [item['sub_crop'] for item in result['sub_crops']]\n",
    "                        predicted_distances = [item['distance'] for item in result['sub_crops']]\n",
    "                        predicted_features = [item['features'] for item in result['sub_crops']]\n",
    "                        all_recommended_subcrops.update(predicted_sub_crops)\n",
    "                        total_tests += 1\n",
    "                        \n",
    "                        # Top-3 Accuracy, Recall@3, Hit Rate@3\n",
    "                        if expected_sub_crop in predicted_sub_crops:\n",
    "                            correct_matches += 1\n",
    "                            rank = predicted_sub_crops.index(expected_sub_crop)\n",
    "                            distances_correct.append(predicted_distances[rank])\n",
    "                        \n",
    "                        # Precision@3\n",
    "                        correct_in_top3 = sum(1 for pred in predicted_sub_crops if pred == expected_sub_crop)\n",
    "                        precision_sum += correct_in_top3 / num_recommendations\n",
    "                        \n",
    "                        # MRR\n",
    "                        rank = next((i + 1 for i, pred in enumerate(predicted_sub_crops) if pred == expected_sub_crop), 0)\n",
    "                        reciprocal_rank_sum += (1 / rank) if rank > 0 else 0\n",
    "                        \n",
    "                        # NDCG@3\n",
    "                        dcg = sum((1 / math.log2(i + 2)) if pred == expected_sub_crop else 0 \n",
    "                                  for i, pred in enumerate(predicted_sub_crops))\n",
    "                        idcg = 1 / math.log2(2)\n",
    "                        dcg_sum += dcg / idcg if idcg > 0 else 0\n",
    "                        \n",
    "                        # Diversity\n",
    "                        if len(predicted_features) >= 2:\n",
    "                            pairwise_distances = []\n",
    "                            for i in range(len(predicted_features)):\n",
    "                                for j in range(i + 1, len(predicted_features)):\n",
    "                                    dist = np.sqrt(np.sum((predicted_features[i] - predicted_features[j]) ** 2))\n",
    "                                    pairwise_distances.append(dist)\n",
    "                            diversity_sum += np.mean(pairwise_distances) if pairwise_distances else 0\n",
    "                        \n",
    "                        if expected_sub_crop not in predicted_sub_crops:\n",
    "                            debug_file.write(f\"Mismatch for {main_crop}: Expected {expected_sub_crop}, Got {predicted_sub_crops}\\n\")\n",
    "                except Exception as e:\n",
    "                    skipped_datasets.append(f\"{main_crop}: Data loading error - {str(e)}\")\n",
    "                    debug_file.write(f\"Error loading {main_crop}: {str(e)}\\n\")\n",
    "                    continue\n",
    "            \n",
    "            accuracy = (correct_matches / total_tests) * 100 if total_tests > 0 else 0.0\n",
    "            precision_at_3 = (precision_sum / total_tests) * 100 if total_tests > 0 else 0.0\n",
    "            recall_at_3 = (correct_matches / total_tests) * 100 if total_tests > 0 else 0.0\n",
    "            f1_score_at_3 = (2 * precision_at_3 * recall_at_3 / (precision_at_3 + recall_at_3)) if (precision_at_3 + recall_at_3) > 0 else 0.0\n",
    "            mrr = (reciprocal_rank_sum / total_tests) if total_tests > 0 else 0.0\n",
    "            ndcg_at_3 = (dcg_sum / total_tests) if total_tests > 0 else 0.0\n",
    "            hit_rate_at_3 = (correct_matches / total_tests) * 100 if total_tests > 0 else 0.0\n",
    "            avg_distance = sum(distances_correct) / len(distances_correct) if distances_correct else float('inf')\n",
    "            diversity = (diversity_sum / total_tests) if total_tests > 0 else 0.0\n",
    "            coverage = len(all_recommended_subcrops) / len(total_unique_subcrops) * 100 if total_unique_subcrops else 0.0\n",
    "            \n",
    "            metrics = {\n",
    "                'Top-3 Accuracy (%)': accuracy,\n",
    "                'Precision@3 (%)': precision_at_3,\n",
    "                'Recall@3 (%)': recall_at_3,\n",
    "                'F1-Score@3 (%)': f1_score_at_3,\n",
    "                'Mean Reciprocal Rank': mrr,\n",
    "                'NDCG@3': ndcg_at_3,\n",
    "                'Hit Rate@3 (%)': hit_rate_at_3,\n",
    "                'Average Euclidean Distance': avg_distance,\n",
    "                'Diversity': diversity,\n",
    "                'Coverage (%)': coverage\n",
    "            }\n",
    "            metrics_message = \"\\n\".join(f\"{key}: {value:.2f}\" for key, value in metrics.items())\n",
    "            debug_file.write(f\"\\n{metrics_message}\\n\")\n",
    "        \n",
    "        return metrics, evaluated_datasets, skipped_datasets\n",
    "\n",
    "# Main Crop Model Training and Evaluation\n",
    "def train_and_save_main_crop_model():\n",
    "    try:\n",
    "        data = pd.read_csv('../datasets/Crop_recommendation.csv')\n",
    "        X = data[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    "        y = data['label']\n",
    "        \n",
    "        label_encoder = LabelEncoder()\n",
    "        y_encoded = label_encoder.fit_transform(y)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        with open('main_crop_model.pkl', 'wb') as file:\n",
    "            pickle.dump({'model': model, 'label_encoder': label_encoder, 'scaler': scaler}, file)\n",
    "        \n",
    "        return model, label_encoder, scaler, X_train_scaled, X_test_scaled, y_train, y_test\n",
    "    except Exception as e:\n",
    "        print(f\"Error training main crop model: {str(e)}\")\n",
    "        return None, None, None, None, None, None, None\n",
    "\n",
    "def evaluate_main_crop_model(model, X_test, y_test, label_encoder):\n",
    "    try:\n",
    "        preds = model.predict(X_test)\n",
    "        preds_labels = label_encoder.inverse_transform(preds)\n",
    "        y_test_labels = label_encoder.inverse_transform(y_test)\n",
    "        probs = model.predict_proba(X_test)\n",
    "        confidences = np.max(probs, axis=1)\n",
    "        cv_scores = cross_val_score(model, X_test, y_test, cv=5, scoring='accuracy')\n",
    "        return {\n",
    "            'Accuracy (%)': accuracy_score(y_test, preds) * 100,\n",
    "            'Precision (Macro) (%)': precision_score(y_test_labels, preds_labels, average='macro', zero_division=0) * 100,\n",
    "            'Recall (Macro) (%)': recall_score(y_test_labels, preds_labels, average='macro', zero_division=0) * 100,\n",
    "            'F1-Score (Macro) (%)': f1_score(y_test_labels, preds_labels, average='macro', zero_division=0) * 100,\n",
    "            'Average Confidence': np.mean(confidences),\n",
    "            'Low Confidence Rate (%)': (np.sum(confidences < 0.7) / len(confidences)) * 100,\n",
    "            'CV Accuracy (%)': cv_scores.mean() * 100\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating main crop model: {str(e)}\")\n",
    "        return {\n",
    "            'Accuracy (%)': 0.0, 'Precision (Macro) (%)': 0.0, 'Recall (Macro) (%)': 0.0,\n",
    "            'F1-Score (Macro) (%)': 0.0, 'Average Confidence': 0.0,\n",
    "            'Low Confidence Rate (%)': 0.0, 'CV Accuracy (%)': 0.0\n",
    "        }\n",
    "\n",
    "# Model Comparison\n",
    "def compare_models():\n",
    "    # Main Crop Comparison\n",
    "    data = pd.read_csv('../datasets/Crop_recommendation.csv')\n",
    "    X = data[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    "    y = data['label']\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    main_crop_models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=2000),\n",
    "        \"KNN (k=5)\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"SVM (Linear)\": SVC(kernel='linear', probability=True),\n",
    "        \"SVM (RBF)\": SVC(kernel='rbf', probability=True),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "        \"Naive Bayes\": GaussianNB(),\n",
    "        \"XGBoost\": XGBClassifier(eval_metric='mlogloss')\n",
    "    }\n",
    "\n",
    "    main_crop_results = []\n",
    "    for name, model in main_crop_models.items():\n",
    "        try:\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            preds = model.predict(X_test_scaled)\n",
    "            acc = accuracy_score(y_test, preds) * 100\n",
    "            main_crop_results.append((name, acc))\n",
    "        except Exception as e:\n",
    "            main_crop_results.append((name, 0.0))\n",
    "            print(f\"Error evaluating main crop {name}: {str(e)}\")\n",
    "\n",
    "    # Add Main Crop Model\n",
    "    try:\n",
    "        with open('main_crop_model.pkl', 'rb') as file:\n",
    "            model_data = pickle.load(file)\n",
    "            preds = model_data['model'].predict(X_test_scaled)\n",
    "            acc = accuracy_score(y_test, preds) * 100\n",
    "            main_crop_results.append((\"Main Crop Model (Random Forest)\", acc))\n",
    "    except Exception as e:\n",
    "        main_crop_results.append((\"Main Crop Model (Random Forest)\", 0.0))\n",
    "        print(f\"Error evaluating Main Crop Model: {str(e)}\")\n",
    "\n",
    "    # Sub-Crop Comparison\n",
    "    subcrop_models = {\n",
    "        \"Euclidean Distance (SubCropRecommender)\": None,\n",
    "        \"KNN (k=5)\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100)\n",
    "    }\n",
    "\n",
    "    subcrop_results = []\n",
    "    skipped_datasets = []\n",
    "    for name, model in subcrop_models.items():\n",
    "        if name == \"Euclidean Distance (SubCropRecommender)\":\n",
    "            try:\n",
    "                recommender = SubCropRecommender(main_model_path='main_crop_model.pkl', subcrop_dir='C:/Projects/Creative & Innovative Project/datasets/sub_crop_data/')\n",
    "                metrics, _, skipped = recommender.calculate_subcrop_accuracy()\n",
    "                subcrop_results.append((name, metrics['Top-3 Accuracy (%)']))\n",
    "                skipped_datasets.extend(skipped)\n",
    "            except Exception as e:\n",
    "                subcrop_results.append((name, 0.0))\n",
    "                skipped_datasets.append(f\"SubCropRecommender: {str(e)}\")\n",
    "                print(f\"Error calculating sub-crop accuracy: {str(e)}\")\n",
    "        else:\n",
    "            try:\n",
    "                total_tests = 0\n",
    "                correct_matches = 0\n",
    "                for main_crop, filename in crop_name_mapping.items():\n",
    "                    file_path = os.path.join('C:/Projects/Creative & Innovative Project/datasets/sub_crop_data/', filename)\n",
    "                    if not os.path.exists(file_path):\n",
    "                        skipped_datasets.append(f\"{main_crop}: File {filename} not found\")\n",
    "                        continue\n",
    "                    sub_crop_df = pd.read_csv(file_path)\n",
    "                    required_cols = ['sub-crop', 'N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']\n",
    "                    if not all(col in sub_crop_df.columns for col in required_cols):\n",
    "                        skipped_datasets.append(f\"{main_crop}: Missing required columns\")\n",
    "                        continue\n",
    "                    if len(sub_crop_df) < 30 or len(sub_crop_df['sub-crop'].unique()) < 3:\n",
    "                        skipped_datasets.append(f\"{main_crop}: Insufficient samples ({len(sub_crop_df)}) or sub-crops ({len(sub_crop_df['sub-crop'].unique())})\")\n",
    "                        continue\n",
    "                    X = sub_crop_df[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    "                    y = sub_crop_df['sub-crop']\n",
    "                    le = LabelEncoder()\n",
    "                    y_encoded = le.fit_transform(y)\n",
    "                    X_train_sub, X_test_sub, y_train_sub, y_test_sub = train_test_split(X, y_encoded, test_size=0.1, random_state=42)\n",
    "                    if len(X_test_sub) < 3 or len(X_train_sub) < 4:\n",
    "                        skipped_datasets.append(f\"{main_crop}: Insufficient test ({len(X_test_sub)}) or train ({len(X_train_sub)}) samples\")\n",
    "                        continue\n",
    "                    model.fit(X_train_sub, y_train_sub)\n",
    "                    for i in range(len(X_test_sub)):\n",
    "                        input_vector = X_test_sub.iloc[i].values.reshape(1, -1)\n",
    "                        expected = le.inverse_transform([y_test_sub[i]])[0]\n",
    "                        if isinstance(model, KNeighborsClassifier):\n",
    "                            n_neighbors = min(3, len(X_train_sub) - 1)\n",
    "                            distances, indices = model.kneighbors(input_vector, n_neighbors=n_neighbors)\n",
    "                            valid_indices = indices[0][indices[0] < len(X_train_sub)]\n",
    "                            if len(valid_indices) == 0:\n",
    "                                continue\n",
    "                            predicted = le.inverse_transform(model.predict(X_train_sub.iloc[valid_indices]))\n",
    "                        else:\n",
    "                            probs = model.predict_proba(input_vector)[0]\n",
    "                            valid_classes = np.arange(len(probs))[probs > 0]\n",
    "                            if len(valid_classes) < 1:\n",
    "                                continue\n",
    "                            top_indices = np.argsort(probs[valid_classes])[-min(3, len(valid_classes)):][::-1]\n",
    "                            predicted = le.inverse_transform(valid_classes[top_indices])\n",
    "                        total_tests += 1\n",
    "                        if expected in predicted:\n",
    "                            correct_matches += 1\n",
    "                acc = (correct_matches / total_tests) * 100 if total_tests > 0 else 0.0\n",
    "                subcrop_results.append((name, acc))\n",
    "            except Exception as e:\n",
    "                subcrop_results.append((name, 0.0))\n",
    "                skipped_datasets.append(f\"{name}: {str(e)}\")\n",
    "                print(f\"Error evaluating sub-crop {name}: {str(e)}\")\n",
    "\n",
    "    return main_crop_results, subcrop_results, list(set(skipped_datasets))\n",
    "\n",
    "# PDF Generation\n",
    "def header_footer(canvas, doc):\n",
    "    canvas.saveState()\n",
    "    # Header\n",
    "    canvas.setFont('Helvetica-Bold', 10)\n",
    "    canvas.setFillColor(DARK_GREEN)\n",
    "    canvas.drawString(0.75 * inch, doc.pagesize[1] - 0.75 * inch, \"Crop Combination Recommendation and Price Prediction\")\n",
    "    canvas.setFont('Helvetica', 8)\n",
    "    canvas.setFillColor(GRAY)\n",
    "    canvas.drawRightString(doc.pagesize[0] - 0.75 * inch, doc.pagesize[1] - 0.75 * inch, f\"Page {doc.page}\")\n",
    "    canvas.setLineWidth(0.5)\n",
    "    canvas.setStrokeColor(GRAY)\n",
    "    canvas.line(0.75 * inch, doc.pagesize[1] - 0.85 * inch, doc.pagesize[0] - 0.75 * inch, doc.pagesize[1] - 0.85 * inch)\n",
    "    # Footer\n",
    "    canvas.setFont('Helvetica', 8)\n",
    "    canvas.setFillColor(GRAY)\n",
    "    canvas.drawCentredString(doc.pagesize[0] / 2, 0.5 * inch, f\"Page {doc.page}\")\n",
    "    canvas.restoreState()\n",
    "\n",
    "def format_table_cell(text, is_header=False):\n",
    "    style = ParagraphStyle(\n",
    "        name='TableCell' if not is_header else 'TableHeader',\n",
    "        fontName='Helvetica-Bold' if is_header else 'Times-Roman',\n",
    "        fontSize=9,\n",
    "        textColor=colors.white if is_header else BLACK,\n",
    "        alignment=1,\n",
    "        leading=10,\n",
    "        wordWrap='CJK'\n",
    "    )\n",
    "    return Paragraph(str(text), style)\n",
    "\n",
    "def generate_pdf_report(main_crop_comp, subcrop_comp, main_crop_metrics, subcrop_metrics, evaluated_datasets, skipped_datasets, output_filename=\"Crop_Recommendation_Report_1.pdf\"):\n",
    "    doc = SimpleDocTemplate(output_filename, pagesize=letter, rightMargin=0.75 * inch, leftMargin=0.75 * inch, topMargin=1 * inch, bottomMargin=1 * inch)\n",
    "    styles = getSampleStyleSheet()\n",
    "\n",
    "    # Custom Styles\n",
    "    cover_title_style = ParagraphStyle(\n",
    "        name='CoverTitle', fontName='Helvetica-Bold', fontSize=20, textColor=DARK_GREEN, alignment=1, spaceAfter=12\n",
    "    )\n",
    "    cover_subtitle_style = ParagraphStyle(\n",
    "        name='CoverSubtitle', fontName='Helvetica', fontSize=12, textColor=BLACK, alignment=1, spaceAfter=10\n",
    "    )\n",
    "    heading_style = ParagraphStyle(\n",
    "        name='Heading2', fontName='Helvetica-Bold', fontSize=14, textColor=DARK_BLUE, spaceBefore=14, spaceAfter=8\n",
    "    )\n",
    "    body_style = ParagraphStyle(\n",
    "        name='BodyText', fontName='Times-Roman', fontSize=10, leading=12, textColor=BLACK, spaceAfter=10, alignment=4, wordWrap='CJK'\n",
    "    )\n",
    "\n",
    "    elements = []\n",
    "\n",
    "    # Cover Page\n",
    "    elements.append(Spacer(1, 3 * inch))\n",
    "    elements.append(Paragraph(\"Crop Combination Recommendation and Price Prediction\", cover_title_style))\n",
    "    elements.append(Spacer(1, 0.2 * inch))\n",
    "    elements.append(HRFlowable(width=4 * inch, thickness=1, color=DARK_GREEN, spaceBefore=0, spaceAfter=0, hAlign='CENTER'))\n",
    "    elements.append(Spacer(1, 0.3 * inch))\n",
    "    elements.append(Paragraph(\"CS6611 Creative and Innovative Project\", cover_subtitle_style))\n",
    "    elements.append(Paragraph(\"Submitted by: [Your Name]\", cover_subtitle_style))\n",
    "    elements.append(Paragraph(f\"Date: {datetime.now().strftime('%Y-%m-%d')}\", cover_subtitle_style))\n",
    "    elements.append(Spacer(1, 2.5 * inch))\n",
    "    elements.append(Paragraph(\"Department of Computer Science\", cover_subtitle_style))\n",
    "    elements.append(Paragraph(\"[Your University Name]\", cover_subtitle_style))\n",
    "    elements.append(PageBreak())\n",
    "\n",
    "    # Content Template\n",
    "    frame = Frame(doc.leftMargin, doc.bottomMargin, doc.width, doc.height - 1.2 * inch)\n",
    "    template = PageTemplate(id='content', frames=[frame], onPage=header_footer)\n",
    "    doc.addPageTemplates([template])\n",
    "    elements.append(NextPageTemplate('content'))\n",
    "\n",
    "    # Introduction\n",
    "    elements.append(Paragraph(\"Introduction\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"This report, part of the CS6611 Creative and Innovative Project titled 'Crop Combination Recommendation and Price Prediction,' evaluates machine learning models for recommending main crops and their sub-crops. \"\n",
    "        \"The main crop model uses a Random Forest Classifier, while the sub-crop model employs a Euclidean Distance-based approach (SubCropRecommender), akin to KNN, to rank sub-crops. \"\n",
    "        \"The report compares these models against alternatives, presents detailed performance metrics, and addresses data challenges, particularly for sub-crop datasets, using the Crop Recommendation dataset and sub-crop datasets.\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 0.2 * inch))\n",
    "\n",
    "    # Methodology\n",
    "    elements.append(Paragraph(\"Methodology\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"The Crop Recommendation dataset (~2200 samples, 22 crops) was preprocessed with LabelEncoder and StandardScaler, split into 80% training and 20% testing sets for main crop prediction. \"\n",
    "        \"Models compared include Logistic Regression, KNN, SVM (Linear and RBF), Decision Tree, Random Forest, Naive Bayes, and XGBoost. Metrics for main crop include accuracy, precision, recall, F1-score (macro-averaged), average confidence, low confidence rate (<0.7), and 5-fold cross-validation accuracy. \"\n",
    "        \"For sub-crop recommendation, the SubCropRecommender uses Euclidean distance, compared with KNN and Random Forest on sub-crop datasets (30-200 samples) with a 30-sample and 3-sub-crop minimum threshold. \"\n",
    "        \"Sub-crop metrics include top-3 accuracy, precision@3, recall@3, F1-score@3, MRR, NDCG@3, hit rate@3, average Euclidean distance, diversity, and coverage.\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 0.2 * inch))\n",
    "\n",
    "    # Data Challenges\n",
    "    elements.append(Paragraph(\"Data Challenges\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"Main crop prediction used a robust dataset (~2200 samples, 22 crops), ensuring reliable metrics. However, sub-crop recommendation faced significant challenges due to small dataset sizes (30-50 samples for most crops, 200 for Grapes but only 2 sub-crops) and missing files (e.g., Black Gram Dal). \"\n",
    "        \"Many datasets were skipped due to insufficient samples (<30), too few unique sub-crops (<3), or file errors, leading to limited evaluation. These issues highlight the need for larger, standardized sub-crop datasets.\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 0.2 * inch))\n",
    "\n",
    "    # Results\n",
    "    elements.append(Paragraph(\"Results\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"The following sections present model comparisons and performance metrics for main crop prediction and sub-crop recommendation. \"\n",
    "        \"Main crop results are robust, while sub-crop results are constrained by data limitations, as detailed in the Sub-Crop Dataset Summary.\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 0.2 * inch))\n",
    "\n",
    "    # Main Crop Model Comparison\n",
    "    elements.append(Paragraph(\"Main Crop Model Comparison\", heading_style))\n",
    "    total_width = doc.width\n",
    "    colWidths = [total_width * 0.6, total_width * 0.4]\n",
    "    table_data = [[format_table_cell(\"Model\", is_header=True), format_table_cell(\"Accuracy (%)\", is_header=True)]]\n",
    "    for i, (name, acc) in enumerate(main_crop_comp):\n",
    "        table_data.append([format_table_cell(name), format_table_cell(f\"{acc:.2f}\")])\n",
    "    table = Table(table_data, colWidths=colWidths, rowHeights=[0.3 * inch] * len(table_data))\n",
    "    table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), DARK_GREEN),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 9),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 6),\n",
    "        ('TOPPADDING', (0, 0), (-1, 0), 6),\n",
    "        ('BOTTOMPADDING', (0, 1), (-1, -1), 4),\n",
    "        ('TOPPADDING', (0, 1), (-1, -1), 4),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "        ('BACKGROUND', (0, 2), (-1, 2), SOFT_GRAY),\n",
    "        ('BACKGROUND', (0, 4), (-1, 4), SOFT_GRAY),\n",
    "        ('BACKGROUND', (0, 6), (-1, 6), SOFT_GRAY),\n",
    "        ('BACKGROUND', (0, 8), (-1, 8), SOFT_GRAY),\n",
    "        ('GRID', (0, 0), (-1, -1), 0.5, BLACK),\n",
    "        ('LEFTPADDING', (0, 0), (-1, -1), 8),\n",
    "        ('RIGHTPADDING', (0, 0), (-1, -1), 8),\n",
    "    ]))\n",
    "    elements.append(KeepTogether(table))\n",
    "    elements.append(Spacer(1, 0.3 * inch))\n",
    "\n",
    "    # Sub-Crop Model Comparison\n",
    "    elements.append(Paragraph(\"Sub-Crop Model Comparison\", heading_style))\n",
    "    table_data = [[format_table_cell(\"Model\", is_header=True), format_table_cell(\"Top-3 Accuracy (%)\", is_header=True)]]\n",
    "    for i, (name, acc) in enumerate(subcrop_comp):\n",
    "        table_data.append([format_table_cell(name), format_table_cell(f\"{acc:.2f}\")])\n",
    "    table = Table(table_data, colWidths=colWidths, rowHeights=[0.3 * inch] * len(table_data))\n",
    "    table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), DARK_GREEN),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 9),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 6),\n",
    "        ('TOPPADDING', (0, 0), (-1, 0), 6),\n",
    "        ('BOTTOMPADDING', (0, 1), (-1, -1), 4),\n",
    "        ('TOPPADDING', (0, 1), (-1, -1), 4),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "        ('BACKGROUND', (0, 2), (-1, 2), SOFT_GRAY),\n",
    "        ('GRID', (0, 0), (-1, -1), 0.5, BLACK),\n",
    "        ('LEFTPADDING', (0, 0), (-1, -1), 8),\n",
    "        ('RIGHTPADDING', (0, 0), (-1, -1), 8),\n",
    "    ]))\n",
    "    elements.append(KeepTogether(table))\n",
    "    elements.append(Spacer(1, 0.3 * inch))\n",
    "\n",
    "    # Main Crop Performance Metrics\n",
    "    elements.append(Paragraph(\"Main Crop Performance Metrics (Random Forest)\", heading_style))\n",
    "    colWidths = [total_width * 0.5, total_width * 0.5]\n",
    "    table_data = [[format_table_cell(\"Metric\", is_header=True), format_table_cell(\"Value\", is_header=True)]]\n",
    "    for i, (key, value) in enumerate(main_crop_metrics.items()):\n",
    "        value_str = f\"{value:.2f}\" if isinstance(value, (int, float)) else str(value)\n",
    "        table_data.append([format_table_cell(key), format_table_cell(value_str)])\n",
    "    table = Table(table_data, colWidths=colWidths, rowHeights=[0.3 * inch] * len(table_data))\n",
    "    table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), DARK_GREEN),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 9),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 6),\n",
    "        ('TOPPADDING', (0, 0), (-1, 0), 6),\n",
    "        ('BOTTOMPADDING', (0, 1), (-1, -1), 4),\n",
    "        ('TOPPADDING', (0, 1), (-1, -1), 4),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "        ('BACKGROUND', (0, 2), (-1, 2), SOFT_GRAY),\n",
    "        ('BACKGROUND', (0, 4), (-1, 4), SOFT_GRAY),\n",
    "        ('BACKGROUND', (0, 6), (-1, 6), SOFT_GRAY),\n",
    "        ('GRID', (0, 0), (-1, -1), 0.5, BLACK),\n",
    "        ('LEFTPADDING', (0, 0), (-1, -1), 8),\n",
    "        ('RIGHTPADDING', (0, 0), (-1, -1), 8),\n",
    "    ]))\n",
    "    elements.append(KeepTogether(table))\n",
    "    elements.append(Spacer(1, 0.3 * inch))\n",
    "\n",
    "    # Sub-Crop Performance Metrics\n",
    "    elements.append(Paragraph(\"Sub-Crop Performance Metrics (Euclidean Distance)\", heading_style))\n",
    "    table_data = [[format_table_cell(\"Metric\", is_header=True), format_table_cell(\"Value\", is_header=True)]]\n",
    "    for i, (key, value) in enumerate(subcrop_metrics.items()):\n",
    "        value_str = f\"{value:.2f}\" if isinstance(value, (int, float)) and not np.isinf(value) else \"N/A\"\n",
    "        table_data.append([format_table_cell(key), format_table_cell(value_str)])\n",
    "    table = Table(table_data, colWidths=colWidths, rowHeights=[0.3 * inch] * len(table_data))\n",
    "    table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), DARK_GREEN),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 9),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 6),\n",
    "        ('TOPPADDING', (0, 0), (-1, 0), 6),\n",
    "        ('BOTTOMPADDING', (0, 1), (-1, -1), 4),\n",
    "        ('TOPPADDING', (0, 1), (-1, -1), 4),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "        ('BACKGROUND', (0, 2), (-1, 2), SOFT_GRAY),\n",
    "        ('BACKGROUND', (0, 4), (-1, 4), SOFT_GRAY),\n",
    "        ('BACKGROUND', (0, 6), (-1, 6), SOFT_GRAY),\n",
    "        ('BACKGROUND', (0, 8), (-1, 8), SOFT_GRAY),\n",
    "        ('GRID', (0, 0), (-1, -1), 0.5, BLACK),\n",
    "        ('LEFTPADDING', (0, 0), (-1, -1), 8),\n",
    "        ('RIGHTPADDING', (0, 0), (-1, -1), 8),\n",
    "    ]))\n",
    "    elements.append(KeepTogether(table))\n",
    "    elements.append(Spacer(1, 0.3 * inch))\n",
    "\n",
    "    # Sub-Crop Dataset Summary\n",
    "    elements.append(Paragraph(\"Sub-Crop Dataset Summary\", heading_style))\n",
    "    colWidths = [total_width * 0.4, total_width * 0.2, total_width * 0.2, total_width * 0.2]\n",
    "    table_data = [[format_table_cell(col, is_header=True) for col in [\"Main Crop\", \"Samples\", \"Unique Sub-Crops\", \"Status\"]]]\n",
    "    for main_crop, filename in crop_name_mapping.items():\n",
    "        file_path = os.path.join('C:/Projects/Creative & Innovative Project/datasets/sub_crop_data/', filename)\n",
    "        status = \"Skipped\"\n",
    "        samples = \"N/A\"\n",
    "        sub_crops = \"N/A\"\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                samples = len(df)\n",
    "                sub_crops = len(df['sub-crop'].unique()) if 'sub-crop' in df.columns else 0\n",
    "                status = \"Evaluated\" if samples >= 30 and sub_crops >= 3 else \"Skipped\"\n",
    "            except:\n",
    "                status = \"Error\"\n",
    "        table_data.append([format_table_cell(main_crop), format_table_cell(str(samples)), format_table_cell(str(sub_crops)), format_table_cell(status)])\n",
    "    table = Table(table_data, colWidths=colWidths, rowHeights=[0.3 * inch] * len(table_data))\n",
    "    table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), DARK_GREEN),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 9),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n",
    "        ('TOPPADDING', (0, 0), (-1, -1), 6),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "        ('GRID', (0, 0), (-1, -1), 0.5, BLACK),\n",
    "        ('LEFTPADDING', (0, 0), (-1, -1), 8),\n",
    "        ('RIGHTPADDING', (0, 0), (-1, -1), 8),\n",
    "    ]))\n",
    "    elements.append(KeepTogether(table))\n",
    "    elements.append(Spacer(1, 0.3 * inch))\n",
    "\n",
    "    # Summary\n",
    "    elements.append(Paragraph(\"Summary\", heading_style))\n",
    "    top_main_crop = max(main_crop_comp, key=lambda x: x[1], default=(\"None\", 0))[0]\n",
    "    top_main_acc = max([x[1] for x in main_crop_comp], default=0)\n",
    "    top_sub_crop = max(subcrop_comp, key=lambda x: x[1], default=(\"None\", 0))[0]\n",
    "    top_sub_acc = max([x[1] for x in subcrop_comp], default=0)\n",
    "    summary_text = (\n",
    "        f\"The Main Crop Model (Random Forest) excelled in main crop prediction, with {top_main_crop} achieving {top_main_acc:.2f}% accuracy. \"\n",
    "        f\"For sub-crop recommendation, {top_sub_crop} led with {top_sub_acc:.2f}% top-3 accuracy, though results were limited by small datasets (30-50 samples) and missing files, as shown in the Sub-Crop Dataset Summary. \"\n",
    "        f\"The Random Forest model demonstrated robust performance across metrics, while the SubCropRecommenders Euclidean Distance approach requires enhanced data for reliable evaluation.\"\n",
    "    )\n",
    "    elements.append(Paragraph(summary_text, body_style))\n",
    "    elements.append(Spacer(1, 0.2 * inch))\n",
    "\n",
    "    # Discussion\n",
    "    elements.append(Paragraph(\"Discussion\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"The Random Forest model and XGBoost outperformed other models in main crop prediction, leveraging ensemble techniques to capture complex feature interactions, with accuracies above 98%. \"\n",
    "        \"The SubCropRecommenders Euclidean Distance approach, akin to KNN, showed potential but was hindered by small datasets, resulting in limited or zero metrics for most crops. \"\n",
    "        \"KNN and Random Forest for sub-crops also faced data constraints, emphasizing the need for larger, standardized sub-crop datasets. \"\n",
    "        \"Cross-validation and confidence metrics confirm the main crop models reliability, while sub-crop metrics like NDCG@3 and diversity highlight ranking quality when data is sufficient.\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 0.2 * inch))\n",
    "\n",
    "    # Conclusion\n",
    "    elements.append(Paragraph(\"Conclusion\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"This report, part of the CS6611 project, validates the Random Forest model for main crop prediction and evaluates the SubCropRecommender for sub-crop recommendation. \"\n",
    "        \"While main crop prediction is highly accurate, sub-crop recommendation requires improved datasets to achieve reliable performance. \"\n",
    "        \"Future work will integrate price prediction using market data (e.g., from Agmarknet) and expand sub-crop datasets to enhance agricultural decision-making.\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 0.2 * inch))\n",
    "\n",
    "    # Appendix: Evaluated and Skipped Datasets\n",
    "    elements.append(Paragraph(\"Appendix: Dataset Details\", heading_style))\n",
    "    # Evaluated Datasets Table\n",
    "    elements.append(Paragraph(\"Evaluated Sub-Crop Datasets\", heading_style))\n",
    "    colWidths = [total_width * 0.7, total_width * 0.15, total_width * 0.15]\n",
    "    table_data = [[format_table_cell(col, is_header=True) for col in [\"Dataset\", \"Samples\", \"Sub-Crops\"]]]\n",
    "    if evaluated_datasets:\n",
    "        for dataset in evaluated_datasets:\n",
    "            parts = dataset.split(\": \")\n",
    "            name = parts[0]\n",
    "            samples, sub_crops = parts[1].split(\" samples, \")\n",
    "            sub_crops = sub_crops.split(\" \")[0]\n",
    "            table_data.append([format_table_cell(name), format_table_cell(samples), format_table_cell(sub_crops)])\n",
    "    else:\n",
    "        table_data.append([format_table_cell(\"None\"), format_table_cell(\"N/A\"), format_table_cell(\"N/A\")])\n",
    "    table = Table(table_data, colWidths=colWidths, rowHeights=[0.3 * inch] * len(table_data))\n",
    "    table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), DARK_GREEN),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 9),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n",
    "        ('TOPPADDING', (0, 0), (-1, -1), 6),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "        ('GRID', (0, 0), (-1, -1), 0.5, BLACK),\n",
    "        ('LEFTPADDING', (0, 0), (-1, -1), 8),\n",
    "        ('RIGHTPADDING', (0, 0), (-1, -1), 8),\n",
    "    ]))\n",
    "    elements.append(KeepTogether(table))\n",
    "    elements.append(Spacer(1, 0.3 * inch))\n",
    "    # Skipped Datasets Table\n",
    "    elements.append(Paragraph(\"Skipped Sub-Crop Datasets\", heading_style))\n",
    "    colWidths = [total_width]\n",
    "    table_data = [[format_table_cell(\"Reason\", is_header=True)]]\n",
    "    if skipped_datasets:\n",
    "        for reason in skipped_datasets:\n",
    "            table_data.append([format_table_cell(reason)])\n",
    "    else:\n",
    "        table_data.append([format_table_cell(\"None\")])\n",
    "    table = Table(table_data, colWidths=colWidths, rowHeights=[0.3 * inch] * len(table_data))\n",
    "    table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), DARK_GREEN),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 9),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n",
    "        ('TOPPADDING', (0, 0), (-1, -1), 6),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "        ('GRID', (0, 0), (-1, -1), 0.5, BLACK),\n",
    "        ('LEFTPADDING', (0, 0), (-1, -1), 8),\n",
    "        ('RIGHTPADDING', (0, 0), (-1, -1), 8),\n",
    "    ]))\n",
    "    elements.append(KeepTogether(table))\n",
    "    elements.append(Spacer(1, 0.3 * inch))\n",
    "\n",
    "    # Build PDF\n",
    "    try:\n",
    "        doc.build(elements)\n",
    "        print(f\"Report generated: {output_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating PDF: {str(e)}\")\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Train Main Crop Model\n",
    "    model, label_encoder, scaler, X_train_scaled, X_test_scaled, y_train, y_test = train_and_save_main_crop_model()\n",
    "    if model is None:\n",
    "        print(\"Failed to train main crop model. Aborting.\")\n",
    "        exit(1)\n",
    "\n",
    "    # Evaluate Main Crop Metrics\n",
    "    main_crop_metrics = evaluate_main_crop_model(model, X_test_scaled, y_test, label_encoder)\n",
    "\n",
    "    # Compare Models\n",
    "    main_crop_comp, subcrop_comp, skipped_datasets = compare_models()\n",
    "\n",
    "    # Evaluate Sub-Crop Metrics\n",
    "    recommender = SubCropRecommender(main_model_path='main_crop_model.pkl', subcrop_dir='C:/Projects/Creative & Innovative Project/datasets/sub_crop_data/')\n",
    "    subcrop_metrics, evaluated_datasets, subcrop_skipped = recommender.calculate_subcrop_accuracy()\n",
    "    skipped_datasets.extend(subcrop_skipped)\n",
    "\n",
    "    # Generate PDF\n",
    "    generate_pdf_report(main_crop_comp, subcrop_comp, main_crop_metrics, subcrop_metrics, evaluated_datasets, skipped_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eeba6a-44ef-40e5-a402-8d0945c0c12e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
