{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8428b8-4844-47f0-895b-2d3691f1c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "import os\n",
    "import math\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib import colors\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak, HRFlowable\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.platypus import PageTemplate, Frame, NextPageTemplate\n",
    "from reportlab.platypus.flowables import KeepTogether\n",
    "from datetime import datetime\n",
    "\n",
    "# Define Colors\n",
    "DARK_GREEN = colors.HexColor(\"#2E7D32\")\n",
    "DARK_BLUE = colors.HexColor(\"#1565C0\")\n",
    "SOFT_GRAY = colors.HexColor(\"#ECEFF1\")\n",
    "BLACK = colors.HexColor(\"#212121\")\n",
    "GRAY = colors.HexColor(\"#757575\")\n",
    "\n",
    "# Realistic Ranges\n",
    "realistic_ranges = {\n",
    "    'N': (0, 200), 'P': (0, 200), 'K': (0, 250), 'temperature': (5, 50),\n",
    "    'humidity': (0, 100), 'ph': (3, 11), 'rainfall': (0, 500)\n",
    "}\n",
    "\n",
    "# Crop Mapping\n",
    "crop_name_mapping = {\n",
    "    'Rice': 'Rice_subcrop_data.csv',\n",
    "    'Maize': 'Maize_subcrop_data.csv',\n",
    "    'Bengal Gram (Gram)(Whole)': 'Bengal Gram (Gram)(Whole)_subcrop_data.csv',\n",
    "    'Pegeon Pea (Arhar Fali)': 'Pegeon Pea (Arhar Fali)_subcrop_data.csv',\n",
    "    'Moath Dal': 'Moath Dal_subcrop_data.csv',\n",
    "    'Green Gram (Moong)(Whole)': 'Green Gram (Moong)(Whole)_subcrop_data.csv',\n",
    "    'Black Gram Dal (Urd Dal)': 'Black Gram Dal (Urd Dal)_subcrop_data.csv',\n",
    "    'Lentil (Masur)(Whole)': 'Lentil (Masur)(Whole)_subcrop_data.csv',\n",
    "    'Pomegranate': 'Pomegranate_subcrop_data.csv',\n",
    "    'Banana': 'Banana_subcrop_data.csv',\n",
    "    'Mango': 'Mango_subcrop_data.csv',\n",
    "    'Grapes': 'Grapes_subcrop_data.csv',\n",
    "    'Water Melon': 'Water Melon_subcrop_data.csv',\n",
    "    'Karbuja (Musk Melon)': 'Karbuja (Musk Melon)_subcrop_data.csv',\n",
    "    'Apple': 'Apple_subcrop_data.csv',\n",
    "    'Orange': 'Orange_subcrop_data.csv',\n",
    "    'Papaya': 'Papaya_subcrop_data.csv',\n",
    "    'Coconut': 'Coconut_subcrop_data.csv',\n",
    "    'Cotton': 'Cotton_subcrop_data.csv',\n",
    "    'Jute': 'Jute_subcrop_data.csv',\n",
    "    'Coffee': 'Coffee_subcrop_data.csv'\n",
    "}\n",
    "\n",
    "# SubCropRecommender Class\n",
    "class SubCropRecommender:\n",
    "    def __init__(self, main_model_path='main_crop_model.pkl', subcrop_dir='C:/Projects/Creative & Innovative Project/datasets/sub_crop_data/'):\n",
    "        self.main_model = self.load_main_crop_model(main_model_path)\n",
    "        self.subcrop_dir = subcrop_dir\n",
    "        self.crop_name_mapping = crop_name_mapping\n",
    "        self.realistic_ranges = realistic_ranges\n",
    "\n",
    "    def load_main_crop_model(self, path):\n",
    "        try:\n",
    "            with open(path, 'rb') as file:\n",
    "                model_data = pickle.load(file)\n",
    "                return model_data\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading main crop model: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def validate_and_preprocess_input(self, N, P, K, temperature, humidity, ph, rainfall):\n",
    "        inputs = {'N': N, 'P': P, 'K': K, 'temperature': temperature, \n",
    "                  'humidity': humidity, 'ph': ph, 'rainfall': rainfall}\n",
    "        for param, val in inputs.items():\n",
    "            try:\n",
    "                inputs[param] = float(val)\n",
    "            except (ValueError, TypeError):\n",
    "                return False, f\"Invalid input: {param} must be a number\", []\n",
    "        capped_inputs = {}\n",
    "        warnings_list = []\n",
    "        for param, val in inputs.items():\n",
    "            min_val, max_val = self.realistic_ranges[param]\n",
    "            if val < min_val or val > max_val:\n",
    "                warnings_list.append(f\"{param} ({val}) outside realistic range ({min_val}-{max_val}), capped\")\n",
    "                capped_inputs[param] = max(min_val, min(val, max_val))\n",
    "            else:\n",
    "                capped_inputs[param] = val\n",
    "        return True, capped_inputs, warnings_list\n",
    "\n",
    "    def recommend_sub_crops(self, N, P, K, temperature, humidity, ph, rainfall, num_recommendations=3):\n",
    "        try:\n",
    "            if self.main_model is None:\n",
    "                return {\"error\": \"Main crop model not loaded\", \"main_crop\": None, \"sub_crops\": [], \"warnings\": None}\n",
    "            \n",
    "            is_valid, capped_inputs, warnings = self.validate_and_preprocess_input(\n",
    "                N, P, K, temperature, humidity, ph, rainfall\n",
    "            )\n",
    "            if not is_valid:\n",
    "                return {\"error\": capped_inputs, \"main_crop\": None, \"sub_crops\": [], \"warnings\": warnings}\n",
    "            \n",
    "            input_df = pd.DataFrame([[capped_inputs['N'], capped_inputs['P'], \n",
    "                                      capped_inputs['K'], capped_inputs['temperature'], \n",
    "                                      capped_inputs['humidity'], capped_inputs['ph'], \n",
    "                                      capped_inputs['rainfall']]],\n",
    "                                    columns=['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall'])\n",
    "            input_scaled = self.main_model['scaler'].transform(input_df)\n",
    "            main_crop_encoded = self.main_model['model'].predict(input_scaled)[0]\n",
    "            main_crop = self.main_model['label_encoder'].inverse_transform([main_crop_encoded])[0]\n",
    "            main_confidence = float(max(self.main_model['model'].predict_proba(input_scaled)[0]))\n",
    "            \n",
    "            if main_crop not in self.crop_name_mapping:\n",
    "                return {\"error\": f\"No sub-crop mapping for {main_crop}\", \"main_crop\": main_crop, \n",
    "                        \"sub_crops\": [], \"warnings\": warnings}\n",
    "            \n",
    "            subcrop_filename = self.crop_name_mapping[main_crop]\n",
    "            subcrop_file = os.path.join(self.subcrop_dir, subcrop_filename)\n",
    "            \n",
    "            if not os.path.exists(subcrop_file):\n",
    "                return {\"error\": f\"Sub-crop file {subcrop_filename} not found\", \n",
    "                        \"main_crop\": main_crop, \"sub_crops\": [], \"warnings\": warnings}\n",
    "            \n",
    "            sub_crop_df = pd.read_csv(subcrop_file)\n",
    "            required_cols = ['sub-crop', 'N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']\n",
    "            missing_cols = [col for col in required_cols if col not in sub_crop_df.columns]\n",
    "            if missing_cols:\n",
    "                return {\"error\": f\"Missing columns: {missing_cols}\", \"main_crop\": main_crop, \n",
    "                        \"sub_crops\": [], \"warnings\": warnings}\n",
    "            \n",
    "            input_vector = np.array([[capped_inputs['N'], capped_inputs['P'], capped_inputs['K'], \n",
    "                                      capped_inputs['temperature'], capped_inputs['humidity'], \n",
    "                                      capped_inputs['ph'], capped_inputs['rainfall']]])\n",
    "            sub_crop_features = sub_crop_df[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']].values\n",
    "            sub_crop_names = sub_crop_df['sub-crop'].values\n",
    "            \n",
    "            distances = euclidean_distances(input_vector, sub_crop_features)[0]\n",
    "            sub_crops_with_distances = list(zip(sub_crop_names, distances, sub_crop_features))\n",
    "            sorted_sub_crops = sorted(sub_crops_with_distances, key=lambda x: x[1])[:num_recommendations]\n",
    "            recommended_sub_crops = [{\"sub_crop\": crop, \"distance\": float(dist), \"features\": features} \n",
    "                                    for crop, dist, features in sorted_sub_crops]\n",
    "            \n",
    "            return {\n",
    "                \"main_crop\": main_crop,\n",
    "                \"main_confidence\": main_confidence,\n",
    "                \"sub_crops\": recommended_sub_crops,\n",
    "                \"warnings\": warnings if warnings else None\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e), \"main_crop\": None, \"sub_crops\": [], \"warnings\": None}\n",
    "\n",
    "    def calculate_subcrop_accuracy(self, num_recommendations=3):\n",
    "        total_tests = 0\n",
    "        correct_matches = 0\n",
    "        precision_sum = 0\n",
    "        reciprocal_rank_sum = 0\n",
    "        dcg_sum = 0\n",
    "        distances_correct = []\n",
    "        diversity_sum = 0\n",
    "        all_recommended_subcrops = set()\n",
    "        total_unique_subcrops = set()\n",
    "        skipped_datasets = []\n",
    "        evaluated_datasets = []\n",
    "        \n",
    "        with open('subcrop_accuracy_debug.txt', 'w') as debug_file:\n",
    "            for main_crop, filename in self.crop_name_mapping.items():\n",
    "                file_path = os.path.join(self.subcrop_dir, filename)\n",
    "                if not os.path.exists(file_path):\n",
    "                    skipped_datasets.append(f\"{main_crop}: File {filename} not found\")\n",
    "                    debug_file.write(f\"Skipping {main_crop}: {filename} not found\\n\")\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    sub_crop_df = pd.read_csv(file_path)\n",
    "                    required_cols = ['sub-crop', 'N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']\n",
    "                    if not all(col in sub_crop_df.columns for col in required_cols):\n",
    "                        skipped_datasets.append(f\"{main_crop}: Missing required columns\")\n",
    "                        debug_file.write(f\"Skipping {main_crop}: {filename} missing required columns\\n\")\n",
    "                        continue\n",
    "                    \n",
    "                    num_samples = len(sub_crop_df)\n",
    "                    num_unique_subcrops = len(sub_crop_df['sub-crop'].unique())\n",
    "                    if num_samples < 30 or num_unique_subcrops < 3:\n",
    "                        skipped_datasets.append(f\"{main_crop}: Insufficient samples ({num_samples}) or unique sub-crops ({num_unique_subcrops})\")\n",
    "                        debug_file.write(f\"Skipping {main_crop}: Insufficient samples ({num_samples}) or unique sub-crops ({num_unique_subcrops})\\n\")\n",
    "                        continue\n",
    "                    \n",
    "                    evaluated_datasets.append(f\"{main_crop}: {num_samples} samples, {num_unique_subcrops} sub-crops\")\n",
    "                    total_unique_subcrops.update(sub_crop_df['sub-crop'].unique())\n",
    "                    \n",
    "                    for _, row in sub_crop_df.iterrows():\n",
    "                        expected_sub_crop = row['sub-crop']\n",
    "                        test_input = [row['N'], row['P'], row['K'], row['temperature'], \n",
    "                                      row['humidity'], row['ph'], row['rainfall']]\n",
    "                        \n",
    "                        result = self.recommend_sub_crops(*test_input, num_recommendations=num_recommendations)\n",
    "                        \n",
    "                        if \"error\" in result:\n",
    "                            skipped_datasets.append(f\"{main_crop}: Recommendation error - {result['error']}\")\n",
    "                            debug_file.write(f\"Error for {main_crop}: {result['error']}\\n\")\n",
    "                            continue\n",
    "                        \n",
    "                        predicted_sub_crops = [item['sub_crop'] for item in result['sub_crops']]\n",
    "                        predicted_distances = [item['distance'] for item in result['sub_crops']]\n",
    "                        predicted_features = [item['features'] for item in result['sub_crops']]\n",
    "                        all_recommended_subcrops.update(predicted_sub_crops)\n",
    "                        total_tests += 1\n",
    "                        \n",
    "                        # Top-3 Accuracy, Recall@3, Hit Rate@3\n",
    "                        if expected_sub_crop in predicted_sub_crops:\n",
    "                            correct_matches += 1\n",
    "                            rank = predicted_sub_crops.index(expected_sub_crop)\n",
    "                            distances_correct.append(predicted_distances[rank])\n",
    "                        \n",
    "                        # Precision@3\n",
    "                        correct_in_top3 = sum(1 for pred in predicted_sub_crops if pred == expected_sub_crop)\n",
    "                        precision_sum += correct_in_top3 / num_recommendations\n",
    "                        \n",
    "                        # MRR\n",
    "                        rank = next((i + 1 for i, pred in enumerate(predicted_sub_crops) if pred == expected_sub_crop), 0)\n",
    "                        reciprocal_rank_sum += (1 / rank) if rank > 0 else 0\n",
    "                        \n",
    "                        # NDCG@3\n",
    "                        dcg = sum((1 / math.log2(i + 2)) if pred == expected_sub_crop else 0 \n",
    "                                  for i, pred in enumerate(predicted_sub_crops))\n",
    "                        idcg = 1 / math.log2(2)\n",
    "                        dcg_sum += dcg / idcg if idcg > 0 else 0\n",
    "                        \n",
    "                        # Diversity\n",
    "                        if len(predicted_features) >= 2:\n",
    "                            pairwise_distances = []\n",
    "                            for i in range(len(predicted_features)):\n",
    "                                for j in range(i + 1, len(predicted_features)):\n",
    "                                    dist = np.sqrt(np.sum((predicted_features[i] - predicted_features[j]) ** 2))\n",
    "                                    pairwise_distances.append(dist)\n",
    "                            diversity_sum += np.mean(pairwise_distances) if pairwise_distances else 0\n",
    "                        \n",
    "                        if expected_sub_crop not in predicted_sub_crops:\n",
    "                            debug_file.write(f\"Mismatch for {main_crop}: Expected {expected_sub_crop}, Got {predicted_sub_crops}\\n\")\n",
    "                except Exception as e:\n",
    "                    skipped_datasets.append(f\"{main_crop}: Data loading error - {str(e)}\")\n",
    "                    debug_file.write(f\"Error loading {main_crop}: {str(e)}\\n\")\n",
    "                    continue\n",
    "            \n",
    "            accuracy = (correct_matches / total_tests) * 100 if total_tests > 0 else 0.0\n",
    "            precision_at_3 = (precision_sum / total_tests) * 100 if total_tests > 0 else 0.0\n",
    "            recall_at_3 = (correct_matches / total_tests) * 100 if total_tests > 0 else 0.0\n",
    "            f1_score_at_3 = (2 * precision_at_3 * recall_at_3 / (precision_at_3 + recall_at_3)) if (precision_at_3 + recall_at_3) > 0 else 0.0\n",
    "            mrr = (reciprocal_rank_sum / total_tests) if total_tests > 0 else 0.0\n",
    "            ndcg_at_3 = (dcg_sum / total_tests) if total_tests > 0 else 0.0\n",
    "            hit_rate_at_3 = (correct_matches / total_tests) * 100 if total_tests > 0 else 0.0\n",
    "            avg_distance = sum(distances_correct) / len(distances_correct) if distances_correct else float('inf')\n",
    "            diversity = (diversity_sum / total_tests) if total_tests > 0 else 0.0\n",
    "            coverage = len(all_recommended_subcrops) / len(total_unique_subcrops) * 100 if total_unique_subcrops else 0.0\n",
    "            \n",
    "            metrics = {\n",
    "                'Top-3 Accuracy (%)': accuracy,\n",
    "                'Precision@3 (%)': precision_at_3,\n",
    "                'Recall@3 (%)': recall_at_3,\n",
    "                'F1-Score@3 (%)': f1_score_at_3,\n",
    "                'Mean Reciprocal Rank': mrr,\n",
    "                'NDCG@3': ndcg_at_3,\n",
    "                'Hit Rate@3 (%)': hit_rate_at_3,\n",
    "                'Average Euclidean Distance': avg_distance,\n",
    "                'Diversity': diversity,\n",
    "                'Coverage (%)': coverage\n",
    "            }\n",
    "            metrics_message = \"\\n\".join(f\"{key}: {value:.2f}\" for key, value in metrics.items())\n",
    "            debug_file.write(f\"\\n{metrics_message}\\n\")\n",
    "        \n",
    "        return metrics, evaluated_datasets, skipped_datasets\n",
    "\n",
    "# Main Crop Model Training and Evaluation\n",
    "def train_and_save_main_crop_model():\n",
    "    try:\n",
    "        data = pd.read_csv('../datasets/Crop_recommendation.csv')\n",
    "        X = data[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    "        y = data['label']\n",
    "        \n",
    "        label_encoder = LabelEncoder()\n",
    "        y_encoded = label_encoder.fit_transform(y)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        with open('main_crop_model.pkl', 'wb') as file:\n",
    "            pickle.dump({'model': model, 'label_encoder': label_encoder, 'scaler': scaler}, file)\n",
    "        \n",
    "        return model, label_encoder, scaler, X_train_scaled, X_test_scaled, y_train, y_test\n",
    "    except Exception as e:\n",
    "        print(f\"Error training main crop model: {str(e)}\")\n",
    "        return None, None, None, None, None, None, None\n",
    "\n",
    "def evaluate_main_crop_model(model, X_test, y_test, label_encoder):\n",
    "    try:\n",
    "        preds = model.predict(X_test)\n",
    "        preds_labels = label_encoder.inverse_transform(preds)\n",
    "        y_test_labels = label_encoder.inverse_transform(y_test)\n",
    "        probs = model.predict_proba(X_test)\n",
    "        confidences = np.max(probs, axis=1)\n",
    "        cv_scores = cross_val_score(model, X_test, y_test, cv=5, scoring='accuracy')\n",
    "        return {\n",
    "            'Accuracy (%)': accuracy_score(y_test, preds) * 100,\n",
    "            'Precision (Macro) (%)': precision_score(y_test_labels, preds_labels, average='macro', zero_division=0) * 100,\n",
    "            'Recall (Macro) (%)': recall_score(y_test_labels, preds_labels, average='macro', zero_division=0) * 100,\n",
    "            'F1-Score (Macro) (%)': f1_score(y_test_labels, preds_labels, average='macro', zero_division=0) * 100,\n",
    "            'Average Confidence': np.mean(confidences),\n",
    "            'Low Confidence Rate (%)': (np.sum(confidences < 0.7) / len(confidences)) * 100,\n",
    "            'CV Accuracy (%)': cv_scores.mean() * 100\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating main crop model: {str(e)}\")\n",
    "        return {\n",
    "            'Accuracy (%)': 0.0, 'Precision (Macro) (%)': 0.0, 'Recall (Macro) (%)': 0.0,\n",
    "            'F1-Score (Macro) (%)': 0.0, 'Average Confidence': 0.0,\n",
    "            'Low Confidence Rate (%)': 0.0, 'CV Accuracy (%)': 0.0\n",
    "        }\n",
    "\n",
    "# Model Comparison\n",
    "def compare_models():\n",
    "    # Main Crop Comparison\n",
    "    data = pd.read_csv('../datasets/Crop_recommendation.csv')\n",
    "    X = data[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    "    y = data['label']\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    main_crop_models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=2000),\n",
    "        \"KNN (k=5)\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"SVM (Linear)\": SVC(kernel='linear', probability=True),\n",
    "        \"SVM (RBF)\": SVC(kernel='rbf', probability=True),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "        \"Naive Bayes\": GaussianNB(),\n",
    "        \"XGBoost\": XGBClassifier(eval_metric='mlogloss')\n",
    "    }\n",
    "\n",
    "    main_crop_results = []\n",
    "    for name, model in main_crop_models.items():\n",
    "        try:\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            preds = model.predict(X_test_scaled)\n",
    "            acc = accuracy_score(y_test, preds) * 100\n",
    "            main_crop_results.append((name, acc))\n",
    "        except Exception as e:\n",
    "            main_crop_results.append((name, 0.0))\n",
    "            print(f\"Error evaluating main crop {name}: {str(e)}\")\n",
    "\n",
    "    # Add Main Crop Model\n",
    "    try:\n",
    "        with open('main_crop_model.pkl', 'rb') as file:\n",
    "            model_data = pickle.load(file)\n",
    "            preds = model_data['model'].predict(X_test_scaled)\n",
    "            acc = accuracy_score(y_test, preds) * 100\n",
    "            main_crop_results.append((\"Main Crop Model (Random Forest)\", acc))\n",
    "    except Exception as e:\n",
    "        main_crop_results.append((\"Main Crop Model (Random Forest)\", 0.0))\n",
    "        print(f\"Error evaluating Main Crop Model: {str(e)}\")\n",
    "\n",
    "    # Sub-Crop Comparison\n",
    "    subcrop_models = {\n",
    "        \"Euclidean Distance (SubCropRecommender)\": None,\n",
    "        \"KNN (k=5)\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100)\n",
    "    }\n",
    "\n",
    "    subcrop_results = []\n",
    "    skipped_datasets = []\n",
    "    for name, model in subcrop_models.items():\n",
    "        if name == \"Euclidean Distance (SubCropRecommender)\":\n",
    "            try:\n",
    "                recommender = SubCropRecommender(main_model_path='main_crop_model.pkl', subcrop_dir='C:/Projects/Creative & Innovative Project/datasets/sub_crop_data/')\n",
    "                metrics, _, skipped = recommender.calculate_subcrop_accuracy()\n",
    "                subcrop_results.append((name, metrics['Top-3 Accuracy (%)']))\n",
    "                skipped_datasets.extend(skipped)\n",
    "            except Exception as e:\n",
    "                subcrop_results.append((name, 0.0))\n",
    "                skipped_datasets.append(f\"SubCropRecommender: {str(e)}\")\n",
    "                print(f\"Error calculating sub-crop accuracy: {str(e)}\")\n",
    "        else:\n",
    "            try:\n",
    "                total_tests = 0\n",
    "                correct_matches = 0\n",
    "                for main_crop, filename in crop_name_mapping.items():\n",
    "                    file_path = os.path.join('C:/Projects/Creative & Innovative Project/datasets/sub_crop_data/', filename)\n",
    "                    if not os.path.exists(file_path):\n",
    "                        skipped_datasets.append(f\"{main_crop}: File {filename} not found\")\n",
    "                        continue\n",
    "                    sub_crop_df = pd.read_csv(file_path)\n",
    "                    required_cols = ['sub-crop', 'N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']\n",
    "                    if not all(col in sub_crop_df.columns for col in required_cols):\n",
    "                        skipped_datasets.append(f\"{main_crop}: Missing required columns\")\n",
    "                        continue\n",
    "                    if len(sub_crop_df) < 30 or len(sub_crop_df['sub-crop'].unique()) < 3:\n",
    "                        skipped_datasets.append(f\"{main_crop}: Insufficient samples ({len(sub_crop_df)}) or sub-crops ({len(sub_crop_df['sub-crop'].unique())})\")\n",
    "                        continue\n",
    "                    X = sub_crop_df[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    "                    y = sub_crop_df['sub-crop']\n",
    "                    le = LabelEncoder()\n",
    "                    y_encoded = le.fit_transform(y)\n",
    "                    X_train_sub, X_test_sub, y_train_sub, y_test_sub = train_test_split(X, y_encoded, test_size=0.1, random_state=42)\n",
    "                    if len(X_test_sub) < 3 or len(X_train_sub) < 4:\n",
    "                        skipped_datasets.append(f\"{main_crop}: Insufficient test ({len(X_test_sub)}) or train ({len(X_train_sub)}) samples\")\n",
    "                        continue\n",
    "                    model.fit(X_train_sub, y_train_sub)\n",
    "                    for i in range(len(X_test_sub)):\n",
    "                        input_vector = X_test_sub.iloc[i].values.reshape(1, -1)\n",
    "                        expected = le.inverse_transform([y_test_sub[i]])[0]\n",
    "                        if isinstance(model, KNeighborsClassifier):\n",
    "                            n_neighbors = min(3, len(X_train_sub) - 1)\n",
    "                            distances, indices = model.kneighbors(input_vector, n_neighbors=n_neighbors)\n",
    "                            valid_indices = indices[0][indices[0] < len(X_train_sub)]\n",
    "                            if len(valid_indices) == 0:\n",
    "                                continue\n",
    "                            predicted = le.inverse_transform(model.predict(X_train_sub.iloc[valid_indices]))\n",
    "                        else:\n",
    "                            probs = model.predict_proba(input_vector)[0]\n",
    "                            valid_classes = np.arange(len(probs))[probs > 0]\n",
    "                            if len(valid_classes) < 1:\n",
    "                                continue\n",
    "                            top_indices = np.argsort(probs[valid_classes])[-min(3, len(valid_classes)):][::-1]\n",
    "                            predicted = le.inverse_transform(valid_classes[top_indices])\n",
    "                        total_tests += 1\n",
    "                        if expected in predicted:\n",
    "                            correct_matches += 1\n",
    "                acc = (correct_matches / total_tests) * 100 if total_tests > 0 else 0.0\n",
    "                subcrop_results.append((name, acc))\n",
    "            except Exception as e:\n",
    "                subcrop_results.append((name, 0.0))\n",
    "                skipped_datasets.append(f\"{name}: {str(e)}\")\n",
    "                print(f\"Error evaluating sub-crop {name}: {str(e)}\")\n",
    "\n",
    "    return main_crop_results, subcrop_results, list(set(skipped_datasets))\n",
    "\n",
    "# PDF Generation\n",
    "def header_footer(canvas, doc):\n",
    "    canvas.saveState()\n",
    "    # Header\n",
    "    canvas.setFont('Helvetica-Bold', 10)\n",
    "    canvas.setFillColor(DARK_GREEN)\n",
    "    canvas.drawString(0.75 * inch, doc.pagesize[1] - 0.75 * inch, \"Crop Combination Recommendation and Price Prediction\")\n",
    "    canvas.setFont('Helvetica', 8)\n",
    "    canvas.setFillColor(GRAY)\n",
    "    canvas.drawRightString(doc.pagesize[0] - 0.75 * inch, doc.pagesize[1] - 0.75 * inch, f\"Page {doc.page}\")\n",
    "    canvas.setLineWidth(0.5)\n",
    "    canvas.setStrokeColor(GRAY)\n",
    "    canvas.line(0.75 * inch, doc.pagesize[1] - 0.85 * inch, doc.pagesize[0] - 0.75 * inch, doc.pagesize[1] - 0.85 * inch)\n",
    "    # Footer\n",
    "    canvas.setFont('Helvetica', 8)\n",
    "    canvas.setFillColor(GRAY)\n",
    "    canvas.drawCentredString(doc.pagesize[0] / 2, 0.5 * inch, f\"Page {doc.page}\")\n",
    "    canvas.restoreState()\n",
    "\n",
    "def format_table_cell(text, is_header=False):\n",
    "    style = ParagraphStyle(\n",
    "        name='TableCell' if not is_header else 'TableHeader',\n",
    "        fontName='Helvetica-Bold' if is_header else 'Times-Roman',\n",
    "        fontSize=9,\n",
    "        textColor=colors.white if is_header else BLACK,\n",
    "        alignment=1,\n",
    "        leading=10,\n",
    "        wordWrap='CJK'\n",
    "    )\n",
    "    return Paragraph(str(text), style)\n",
    "\n",
    "def generate_pdf_report(main_crop_comp, subcrop_comp, main_crop_metrics, subcrop_metrics, evaluated_datasets, skipped_datasets, output_filename=\"Crop_Recommendation_Report.pdf\"):\n",
    "    doc = SimpleDocTemplate(output_filename, pagesize=letter, rightMargin=0.75 * inch, leftMargin=0.75 * inch, topMargin=1 * inch, bottomMargin=1 * inch)\n",
    "    styles = getSampleStyleSheet()\n",
    "\n",
    "    # Custom Styles\n",
    "    cover_title_style = ParagraphStyle(\n",
    "        name='CoverTitle', fontName='Helvetica-Bold', fontSize=20, textColor=DARK_GREEN, alignment=1, spaceAfter=12\n",
    "    )\n",
    "    cover_subtitle_style = ParagraphStyle(\n",
    "        name='CoverSubtitle', fontName='Helvetica', fontSize=12, textColor=BLACK, alignment=1, spaceAfter=10\n",
    "    )\n",
    "    heading_style = ParagraphStyle(\n",
    "        name='Heading2', fontName='Helvetica-Bold', fontSize=14, textColor=DARK_BLUE, spaceBefore=14, spaceAfter=8\n",
    "    )\n",
    "    body_style = ParagraphStyle(\n",
    "        name='BodyText', fontName='Times-Roman', fontSize=10, leading=12, textColor=BLACK, spaceAfter=10, alignment=4, wordWrap='CJK'\n",
    "    )\n",
    "\n",
    "    elements = []\n",
    "\n",
    "    # Cover Page\n",
    "    elements.append(Spacer(1, 3 * inch))\n",
    "    elements.append(Paragraph(\"Crop Combination Recommendation and Price Prediction\", cover_title_style))\n",
    "    elements.append(Spacer(1, 0.2 * inch))\n",
    "    elements.append(HRFlowable(width=4 * inch, thickness=1, color=DARK_GREEN, spaceBefore=0, spaceAfter=0, hAlign='CENTER'))\n",
    "    elements.append(Spacer(1, 0.3 * inch))\n",
    "    elements.append(Paragraph(\"CS6611 Creative and Innovative Project\", cover_subtitle_style))\n",
    "    elements.append(Paragraph(\"Submitted by: [Your Name]\", cover_subtitle_style))\n",
    "    elements.append(Paragraph(f\"Date: {datetime.now().strftime('%Y-%m-%d')}\", cover_subtitle_style))\n",
    "    elements.append(Spacer(1, 2.5 * inch))\n",
    "    elements.append(Paragraph(\"Department of Computer Science\", cover_subtitle_style))\n",
    "    elements.append(Paragraph(\"[Your University Name]\", cover_subtitle_style))\n",
    "    elements.append(PageBreak())\n",
    "\n",
    "    # Content Template\n",
    "    frame = Frame(doc.leftMargin, doc.bottomMargin, doc.width, doc.height - 1.2 * inch)\n",
    "    template = PageTemplate(id='content', frames=[frame], onPage=header_footer)\n",
    "    doc.addPageTemplates([template])\n",
    "    elements.append(NextPageTemplate('content'))\n",
    "\n",
    "    # Introduction\n",
    "    elements.append(Paragraph(\"Introduction\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"This report, part of the CS6611 Creative and Innovative Project titled 'Crop Combination Recommendation and Price Prediction,' evaluates machine learning models for recommending main crops and their sub-crops. \"\n",
    "        \"The main crop model uses a Random Forest Classifier, while the sub-crop model employs a Euclidean Distance-based approach (SubCropRecommender), akin to KNN, to rank sub-crops. \"\n",
    "        \"The report compares these models against alternatives, presents detailed performance metrics, and addresses data challenges, particularly for sub-crop datasets, using the Crop Recommendation dataset and sub-crop datasets.\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 0.2 * inch))\n",
    "\n",
    "    # Methodology\n",
    "    elements.append(Paragraph(\"Methodology\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"The Crop Recommendation dataset (~2200 samples, 22 crops) was preprocessed with LabelEncoder and StandardScaler, split into 80% training and 20% testing sets for main crop prediction. \"\n",
    "        \"Models compared include Logistic Regression, KNN, SVM (Linear and RBF), Decision Tree, Random Forest, Naive Bayes, and XGBoost. Metrics for main crop include accuracy, precision, recall, F1-score (macro-averaged), average confidence, low confidence rate (<0.7), and 5-fold cross-validation accuracy. \"\n",
    "        \"For sub-crop recommendation, the SubCropRecommender uses Euclidean distance, compared with KNN and Random Forest on sub-crop datasets (30-200 samples) with a 30-sample and 3-sub-crop minimum threshold. \"\n",
    "        \"Sub-crop metrics include top-3 accuracy, precision@3, recall@3, F1-score@3, MRR, NDCG@3, hit rate@3, average Euclidean distance, diversity, and coverage.\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 0.2 * inch))\n",
    "\n",
    "    # Data Challenges\n",
    "    elements.append(Paragraph(\"Data Challenges\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"Main crop prediction used a robust dataset (~2200 samples, 22 crops), ensuring reliable metrics. However, sub-crop recommendation faced significant challenges due to small dataset sizes (30-50 samples for most crops, 200 for Grapes but only 2 sub-crops) and missing files (e.g., Black Gram Dal). \"\n",
    "        \"Many datasets were skipped due to insufficient samples (<30), too few unique sub-crops (<3), or file errors, leading to limited evaluation. These issues highlight the need for larger, standardized sub-crop datasets.\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 0.2 * inch))\n",
    "\n",
    "    # Results\n",
    "    elements.append(Paragraph(\"Results\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"The following sections present model comparisons and performance metrics for main crop prediction and sub-crop recommendation. \"\n",
    "        \"Main crop results are robust, while sub-crop results are constrained by data limitations, as detailed in the Sub-Crop Dataset Summary.\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 0.2 * inch))\n",
    "\n",
    "    # Main Crop Model Comparison\n",
    "    elements.append(Paragraph(\"Main Crop Model Comparison\", heading_style))\n",
    "    total_width = doc.width\n",
    "    colWidths = [total_width * 0.6, total_width * 0.4]\n",
    "    table_data = [[format_table_cell(\"Model\", is_header=True), format_table_cell(\"Accuracy (%)\", is_header=True)]]\n",
    "    for i, (name, acc) in enumerate(main_crop_comp):\n",
    "        table_data.append([format_table_cell(name), format_table_cell(f\"{acc:.2f}\")])\n",
    "    table = Table(table_data, colWidths=colWidths, rowHeights=[0.3 * inch] * len(table_data))\n",
    "    table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), DARK_GREEN),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 9),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 6),\n",
    "        ('TOPPADDING', (0, 0), (-1, 0), 6),\n",
    "        ('BOTTOMPADDING', (0, 1), (-1, -1), 4),\n",
    "        ('TOPPADDING', (0, 1), (-1, -1), 4),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "        ('BACKGROUND', (0, 2), (-1, 2), SOFT_GRAY),\n",
    "        ('BACKGROUND', (0, 4), (-1, 4), SOFT_GRAY),\n",
    "        ('BACKGROUND', (0, 6), (-1, 6), SOFT_GRAY),\n",
    "        ('BACKGROUND', (0, 8), (-1, 8), SOFT_GRAY),\n",
    "        ('GRID', (0, 0), (-1, -1), 0.5, BLACK),\n",
    "        ('LEFTPADDING', (0, 0), (-1, -1), 8),\n",
    "        ('RIGHTPADDING', (0, 0), (-1, -1), 8),\n",
    "    ]))\n",
    "    elements.append(KeepTogether(table))\n",
    "    elements.append(Spacer(1, 0.3 * inch))\n",
    "\n",
    "    # Sub-Crop Model Comparison\n",
    "    elements.append(Paragraph(\"Sub-Crop Model Comparison\", heading_style))\n",
    "    table_data = [[format_table_cell(\"Model\", is_header=True), format_table_cell(\"Top-3 Accuracy (%)\", is_header=True)]]\n",
    "    for i, (name, acc) in enumerate(subcrop_comp):\n",
    "        table_data.append([format_table_cell(name), format_table_cell(f\"{acc:.2f}\")])\n",
    "    table = Table(table_data, colWidths=colWidths, rowHeights=[0.3 * inch] * len(table_data))\n",
    "    table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), DARK_GREEN),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 9),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 6),\n",
    "        ('TOPPADDING', (0, 0), (-1, 0), 6),\n",
    "        ('BOTTOMPADDING', (0, 1), (-1, -1), 4),\n",
    "        ('TOPPADDING', (0, 1), (-1, -1), 4),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "        ('BACKGROUND', (0, 2), (-1, 2), SOFT_GRAY),\n",
    "        ('GRID', (0, 0), (-1, -1), 0.5, BLACK),\n",
    "        ('LEFTPADDING', (0, 0), (-1, -1), 8),\n",
    "        ('RIGHTPADDING', (0, 0), (-1, -1), 8),\n",
    "    ]))\n",
    "    elements.append(KeepTogether(table))\n",
    "    elements.append(Spacer(1, 0.3 * inch))\n",
    "\n",
    "    # Main Crop Performance Metrics\n",
    "    elements.append(Paragraph(\"Main Crop Performance Metrics (Random Forest)\", heading_style))\n",
    "    colWidths = [total_width * 0.5, total_width * 0.5]\n",
    "    table_data = [[format_table_cell(\"Metric\", is_header=True), format_table_cell(\"Value\", is_header=True)]]\n",
    "    for i, (key, value) in enumerate(main_crop_metrics.items()):\n",
    "        value_str = f\"{value:.2f}\" if isinstance(value, (int, float)) else str(value)\n",
    "        table_data.append([format_table_cell(key), format_table_cell(value_str)])\n",
    "    table = Table(table_data, colWidths=colWidths, rowHeights=[0.3 * inch] * len(table_data))\n",
    "    table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), DARK_GREEN),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 9),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 6),\n",
    "        ('TOPPADDING', (0, 0), (-1, 0), 6),\n",
    "        ('BOTTOMPADDING', (0, 1), (-1, -1), 4),\n",
    "        ('TOPPADDING', (0, 1), (-1, -1), 4),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "        ('BACKGROUND', (0, 2), (-1, 2), SOFT_GRAY),\n",
    "        ('BACKGROUND', (0, 4), (-1, 4), SOFT_GRAY),\n",
    "        ('BACKGROUND', (0, 6), (-1, 6), SOFT_GRAY),\n",
    "        ('GRID', (0, 0), (-1, -1), 0.5, BLACK),\n",
    "        ('LEFTPADDING', (0, 0), (-1, -1), 8),\n",
    "        ('RIGHTPADDING', (0, 0), (-1, -1), 8),\n",
    "    ]))\n",
    "    elements.append(KeepTogether(table))\n",
    "    elements.append(Spacer(1, 0.3 * inch))\n",
    "\n",
    "    # Sub-Crop Performance Metrics\n",
    "    elements.append(Paragraph(\"Sub-Crop Performance Metrics (Euclidean Distance)\", heading_style))\n",
    "    table_data = [[format_table_cell(\"Metric\", is_header=True), format_table_cell(\"Value\", is_header=True)]]\n",
    "    for i, (key, value) in enumerate(subcrop_metrics.items()):\n",
    "        value_str = f\"{value:.2f}\" if isinstance(value, (int, float)) and not np.isinf(value) else \"N/A\"\n",
    "        table_data.append([format_table_cell(key), format_table_cell(value_str)])\n",
    "    table = Table(table_data, colWidths=colWidths, rowHeights=[0.3 * inch] * len(table_data))\n",
    "    table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), DARK_GREEN),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 9),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 6),\n",
    "        ('TOPPADDING', (0, 0), (-1, 0), 6),\n",
    "        ('BOTTOMPADDING', (0, 1), (-1, -1), 4),\n",
    "        ('TOPPADDING', (0, 1), (-1, -1), 4),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "        ('BACKGROUND', (0, 2), (-1, 2), SOFT_GRAY),\n",
    "        ('BACKGROUND', (0, 4), (-1, 4), SOFT_GRAY),\n",
    "        ('BACKGROUND', (0, 6), (-1, 6), SOFT_GRAY),\n",
    "        ('BACKGROUND', (0, 8), (-1, 8), SOFT_GRAY),\n",
    "        ('GRID', (0, 0), (-1, -1), 0.5, BLACK),\n",
    "        ('LEFTPADDING', (0, 0), (-1, -1), 8),\n",
    "        ('RIGHTPADDING', (0, 0), (-1, -1), 8),\n",
    "    ]))\n",
    "    elements.append(KeepTogether(table))\n",
    "    elements.append(Spacer(1, 0.3 * inch))\n",
    "\n",
    "    # Sub-Crop Dataset Summary\n",
    "    elements.append(Paragraph(\"Sub-Crop Dataset Summary\", heading_style))\n",
    "    colWidths = [total_width * 0.4, total_width * 0.2, total_width * 0.2, total_width * 0.2]\n",
    "    table_data = [[format_table_cell(col, is_header=True) for col in [\"Main Crop\", \"Samples\", \"Unique Sub-Crops\", \"Status\"]]]\n",
    "    for main_crop, filename in crop_name_mapping.items():\n",
    "        file_path = os.path.join('C:/Projects/Creative & Innovative Project/datasets/sub_crop_data/', filename)\n",
    "        status = \"Skipped\"\n",
    "        samples = \"N/A\"\n",
    "        sub_crops = \"N/A\"\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                samples = len(df)\n",
    "                sub_crops = len(df['sub-crop'].unique()) if 'sub-crop' in df.columns else 0\n",
    "                status = \"Evaluated\" if samples >= 30 and sub_crops >= 3 else \"Skipped\"\n",
    "            except:\n",
    "                status = \"Error\"\n",
    "        table_data.append([format_table_cell(main_crop), format_table_cell(str(samples)), format_table_cell(str(sub_crops)), format_table_cell(status)])\n",
    "    table = Table(table_data, colWidths=colWidths, rowHeights=[0.3 * inch] * len(table_data))\n",
    "    table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), DARK_GREEN),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 9),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n",
    "        ('TOPPADDING', (0, 0), (-1, -1), 6),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "        ('GRID', (0, 0), (-1, -1), 0.5, BLACK),\n",
    "        ('LEFTPADDING', (0, 0), (-1, -1), 8),\n",
    "        ('RIGHTPADDING', (0, 0), (-1, -1), 8),\n",
    "    ]))\n",
    "    elements.append(KeepTogether(table))\n",
    "    elements.append(Spacer(1, 0.3 * inch))\n",
    "\n",
    "    # Summary\n",
    "    elements.append(Paragraph(\"Summary\", heading_style))\n",
    "    top_main_crop = max(main_crop_comp, key=lambda x: x[1], default=(\"None\", 0))[0]\n",
    "    top_main_acc = max([x[1] for x in main_crop_comp], default=0)\n",
    "    top_sub_crop = max(subcrop_comp, key=lambda x: x[1], default=(\"None\", 0))[0]\n",
    "    top_sub_acc = max([x[1] for x in subcrop_comp], default=0)\n",
    "    summary_text = (\n",
    "        f\"The Main Crop Model (Random Forest) excelled in main crop prediction, with {top_main_crop} achieving {top_main_acc:.2f}% accuracy. \"\n",
    "        f\"For sub-crop recommendation, {top_sub_crop} led with {top_sub_acc:.2f}% top-3 accuracy, though results were limited by small datasets (30-50 samples) and missing files, as shown in the Sub-Crop Dataset Summary. \"\n",
    "        f\"The Random Forest model demonstrated robust performance across metrics, while the SubCropRecommender’s Euclidean Distance approach requires enhanced data for reliable evaluation.\"\n",
    "    )\n",
    "    elements.append(Paragraph(summary_text, body_style))\n",
    "    elements.append(Spacer(1, 0.2 * inch))\n",
    "\n",
    "    # Discussion\n",
    "    elements.append(Paragraph(\"Discussion\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"The Random Forest model and XGBoost outperformed other models in main crop prediction, leveraging ensemble techniques to capture complex feature interactions, with accuracies above 98%. \"\n",
    "        \"The SubCropRecommender’s Euclidean Distance approach, akin to KNN, showed potential but was hindered by small datasets, resulting in limited or zero metrics for most crops. \"\n",
    "        \"KNN and Random Forest for sub-crops also faced data constraints, emphasizing the need for larger, standardized sub-crop datasets. \"\n",
    "        \"Cross-validation and confidence metrics confirm the main crop model’s reliability, while sub-crop metrics like NDCG@3 and diversity highlight ranking quality when data is sufficient.\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 0.2 * inch))\n",
    "\n",
    "    # Conclusion\n",
    "    elements.append(Paragraph(\"Conclusion\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"This report, part of the CS6611 project, validates the Random Forest model for main crop prediction and evaluates the SubCropRecommender for sub-crop recommendation. \"\n",
    "        \"While main crop prediction is highly accurate, sub-crop recommendation requires improved datasets to achieve reliable performance. \"\n",
    "        \"Future work will integrate price prediction using market data (e.g., from Agmarknet) and expand sub-crop datasets to enhance agricultural decision-making.\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 0.2 * inch))\n",
    "\n",
    "    # Appendix: Evaluated and Skipped Datasets\n",
    "    elements.append(Paragraph(\"Appendix: Dataset Details\", heading_style))\n",
    "    # Evaluated Datasets Table\n",
    "    elements.append(Paragraph(\"Evaluated Sub-Crop Datasets\", heading_style))\n",
    "    colWidths = [total_width * 0.7, total_width * 0.15, total_width * 0.15]\n",
    "    table_data = [[format_table_cell(col, is_header=True) for col in [\"Dataset\", \"Samples\", \"Sub-Crops\"]]]\n",
    "    if evaluated_datasets:\n",
    "        for dataset in evaluated_datasets:\n",
    "            parts = dataset.split(\": \")\n",
    "            name = parts[0]\n",
    "            samples, sub_crops = parts[1].split(\" samples, \")\n",
    "            sub_crops = sub_crops.split(\" \")[0]\n",
    "            table_data.append([format_table_cell(name), format_table_cell(samples), format_table_cell(sub_crops)])\n",
    "    else:\n",
    "        table_data.append([format_table_cell(\"None\"), format_table_cell(\"N/A\"), format_table_cell(\"N/A\")])\n",
    "    table = Table(table_data, colWidths=colWidths, rowHeights=[0.3 * inch] * len(table_data))\n",
    "    table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), DARK_GREEN),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 9),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n",
    "        ('TOPPADDING', (0, 0), (-1, -1), 6),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "        ('GRID', (0, 0), (-1, -1), 0.5, BLACK),\n",
    "        ('LEFTPADDING', (0, 0), (-1, -1), 8),\n",
    "        ('RIGHTPADDING', (0, 0), (-1, -1), 8),\n",
    "    ]))\n",
    "    elements.append(KeepTogether(table))\n",
    "    elements.append(Spacer(1, 0.3 * inch))\n",
    "    # Skipped Datasets Table\n",
    "    elements.append(Paragraph(\"Skipped Sub-Crop Datasets\", heading_style))\n",
    "    colWidths = [total_width]\n",
    "    table_data = [[format_table_cell(\"Reason\", is_header=True)]]\n",
    "    if skipped_datasets:\n",
    "        for reason in skipped_datasets:\n",
    "            table_data.append([format_table_cell(reason)])\n",
    "    else:\n",
    "        table_data.append([format_table_cell(\"None\")])\n",
    "    table = Table(table_data, colWidths=colWidths, rowHeights=[0.3 * inch] * len(table_data))\n",
    "    table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), DARK_GREEN),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 9),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n",
    "        ('TOPPADDING', (0, 0), (-1, -1), 6),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "        ('GRID', (0, 0), (-1, -1), 0.5, BLACK),\n",
    "        ('LEFTPADDING', (0, 0), (-1, -1), 8),\n",
    "        ('RIGHTPADDING', (0, 0), (-1, -1), 8),\n",
    "    ]))\n",
    "    elements.append(KeepTogether(table))\n",
    "    elements.append(Spacer(1, 0.3 * inch))\n",
    "\n",
    "    # Build PDF\n",
    "    try:\n",
    "        doc.build(elements)\n",
    "        print(f\"Report generated: {output_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating PDF: {str(e)}\")\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Train Main Crop Model\n",
    "    model, label_encoder, scaler, X_train_scaled, X_test_scaled, y_train, y_test = train_and_save_main_crop_model()\n",
    "    if model is None:\n",
    "        print(\"Failed to train main crop model. Aborting.\")\n",
    "        exit(1)\n",
    "\n",
    "    # Evaluate Main Crop Metrics\n",
    "    main_crop_metrics = evaluate_main_crop_model(model, X_test_scaled, y_test, label_encoder)\n",
    "\n",
    "    # Compare Models\n",
    "    main_crop_comp, subcrop_comp, skipped_datasets = compare_models()\n",
    "\n",
    "    # Evaluate Sub-Crop Metrics\n",
    "    recommender = SubCropRecommender(main_model_path='main_crop_model.pkl', subcrop_dir='C:/Projects/Creative & Innovative Project/datasets/sub_crop_data/')\n",
    "    subcrop_metrics, evaluated_datasets, subcrop_skipped = recommender.calculate_subcrop_accuracy()\n",
    "    skipped_datasets.extend(subcrop_skipped)\n",
    "\n",
    "    # Generate PDF\n",
    "    generate_pdf_report(main_crop_comp, subcrop_comp, main_crop_metrics, subcrop_metrics, evaluated_datasets, skipped_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9a55eb-cd89-4d05-8f04-e69dcff99864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
