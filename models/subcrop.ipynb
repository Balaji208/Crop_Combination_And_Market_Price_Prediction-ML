{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc1d9781-551c-4707-8af6-3d2cecfb42ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost --no-cache-dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d43e4374-5241-48a2-9b51-25045a942d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset saved as 'merged_subcrop_data.csv'.\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aarth\\AppData\\Local\\Temp\\ipykernel_4024\\41141993.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['main-crop'] = label_encoder.fit_transform(X['main-crop'])\n",
      "C:\\Users\\aarth\\AppData\\Local\\Temp\\ipykernel_4024\\41141993.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']] = scaler.fit_transform(X[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']])\n",
      "C:\\Users\\aarth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Parameters: {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 30, 'bootstrap': False}\n",
      "Accuracy: 0.864406779661017\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "        Apricot       0.94      0.93      0.93       120\n",
      "          Bajra       0.94      0.94      0.94       120\n",
      "         Banana       0.89      0.72      0.79       120\n",
      "   Basmati Rice       0.88      0.94      0.91       120\n",
      "    Bengal Gram       0.88      0.92      0.90       120\n",
      "            Ber       0.85      0.97      0.90       120\n",
      " Black Chickpea       0.93      0.88      0.91       120\n",
      "     Black Gram       0.52      0.33      0.40       120\n",
      "   Black Pepper       0.89      0.93      0.91       120\n",
      "     Black Rice       0.93      0.93      0.93       120\n",
      "   Bottle Gourd       0.93      0.94      0.93       120\n",
      "     Brown Rice       0.88      0.88      0.88       120\n",
      "      Cardamoms       0.94      0.94      0.94       120\n",
      "       Chakotha       0.92      0.91      0.92       120\n",
      "Charleston Gray       0.93      0.92      0.92       120\n",
      "         Cherry       0.92      0.92      0.92       120\n",
      "       Chickoos       0.83      0.92      0.87       120\n",
      "       Chickpea       0.51      0.34      0.41       120\n",
      "          Cocoa       0.89      0.88      0.88       120\n",
      "         Cowpea       0.61      0.75      0.67       120\n",
      "  Crimson Sweet       0.96      0.84      0.90       120\n",
      "  Custard Apple       0.78      0.61      0.68       120\n",
      "  Desi Chickpea       0.94      0.90      0.92       120\n",
      "            Fig       0.85      0.82      0.84       120\n",
      " Foxtail Millet       0.92      0.95      0.93       120\n",
      "         Ginger       0.92      0.98      0.95       120\n",
      " Green Chickpea       0.91      0.97      0.94       120\n",
      "     Green Gram       0.43      0.15      0.22       120\n",
      "      Groundnut       0.80      0.86      0.83       120\n",
      "          Guava       0.72      0.68      0.70       120\n",
      "    Indica Rice       0.96      0.91      0.93       120\n",
      "     Jack Fruit       0.78      0.96      0.86       120\n",
      "  Japonica Rice       0.95      0.93      0.94       120\n",
      "          Jowar       0.97      0.93      0.95       120\n",
      "        Jubilee       0.92      0.93      0.93       120\n",
      "Kabuli Chickpea       0.91      0.89      0.90       120\n",
      "         Kinnow       0.92      0.93      0.92       120\n",
      "          Lemon       0.91      0.92      0.91       120\n",
      "         Lentil       0.76      0.99      0.86       120\n",
      "          Maize       0.91      0.93      0.92       120\n",
      "          Mango       0.89      0.99      0.94       120\n",
      "         Papaya       0.85      0.77      0.81       120\n",
      "           Pear       0.96      0.99      0.98       120\n",
      "     Pegeon Pea       0.67      0.73      0.70       120\n",
      "      Persimmon       0.91      0.92      0.91       120\n",
      "     Pigeon Pea       0.75      0.91      0.82       120\n",
      "      Pineapple       0.76      0.71      0.73       120\n",
      "           Plum       0.96      0.94      0.95       120\n",
      "    Pomegranate       0.88      0.86      0.87       120\n",
      "        Pumpkin       0.93      0.95      0.94       120\n",
      "           Rice       0.84      0.95      0.89       120\n",
      "         Sesame       0.83      1.00      0.91       120\n",
      "        Sesamum       0.83      0.78      0.81       120\n",
      "       Soyabean       0.86      0.95      0.90       120\n",
      "     Sugar Baby       0.85      0.97      0.91       120\n",
      "      Sugarcane       0.93      0.96      0.94       120\n",
      "       Turmeric       0.86      0.88      0.87       120\n",
      "     Watermelon       0.92      0.89      0.91       120\n",
      "    Yellow Doll       0.92      0.91      0.91       120\n",
      "\n",
      "       accuracy                           0.86      7080\n",
      "      macro avg       0.86      0.86      0.86      7080\n",
      "   weighted avg       0.86      0.86      0.86      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load main crop recommendation data\n",
    "main_df = pd.read_csv(\"../datasets/Crop_recommendation.csv\")\n",
    "\n",
    "# List to store all subcrop data\n",
    "all_subcrop_data = []\n",
    "for crop in main_df[\"label\"].unique():\n",
    "    file_path = f\"../datasets/sub_crop_data/{crop}_subcrop_data.csv\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df[\"main-crop\"] = crop  # Add main crop column\n",
    "        all_subcrop_data.append(df)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: File {file_path} not found. Skipping.\")\n",
    "\n",
    "# Merge all subcrop data\n",
    "df = pd.concat(all_subcrop_data, ignore_index=True)\n",
    "\n",
    "# Save merged dataset\n",
    "df.to_csv(\"../datasets/merged_subcrop_data.csv\", index=False)\n",
    "print(\"Merged dataset saved as 'merged_subcrop_data.csv'.\")\n",
    "\n",
    "# Ensure 'sub-crop' column exists\n",
    "if 'sub-crop' not in df.columns:\n",
    "    raise ValueError(\"Missing 'sub-crop' column in sub_crop_data.csv files!\")\n",
    "\n",
    "# Feature Selection\n",
    "X = df[['main-crop', 'N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    "y = df['sub-crop']\n",
    "\n",
    "# Encode categorical variable 'main-crop'\n",
    "label_encoder = LabelEncoder()\n",
    "X['main-crop'] = label_encoder.fit_transform(X['main-crop'])\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']] = scaler.fit_transform(X[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']])\n",
    "\n",
    "# Handle class imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X, y = smote.fit_resample(X, y)\n",
    "\n",
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees\n",
    "    'max_depth': [10, 20, 30, None],  # Depth of trees\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum samples to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum samples per leaf\n",
    "    'bootstrap': [True, False]  # Whether to use bootstrap sampling\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=42), \n",
    "    param_grid, n_iter=20, cv=5, verbose=1, n_jobs=-1, scoring='accuracy'\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Best model from hyperparameter tuning\n",
    "best_model = clf.best_estimator_\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Best Model Parameters:\", clf.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f32e98c-bea0-4e53-9033-a87fbf80d0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Boosted Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4706bab-0a34-4708-97c0-564fb2c0bc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aarth\\AppData\\Local\\Temp\\ipykernel_25896\\1133621281.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['main-crop'] = label_encoder_X.fit_transform(X['main-crop'])\n",
      "C:\\Users\\aarth\\AppData\\Local\\Temp\\ipykernel_25896\\1133621281.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']] = scaler.fit_transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load main crop recommendation data\n",
    "main_df = pd.read_csv(\"../datasets/Crop_recommendation.csv\")\n",
    "\n",
    "# List to store all subcrop data\n",
    "all_subcrop_data = []\n",
    "for crop in main_df[\"label\"].unique():\n",
    "    file_path = f\"../datasets/sub_crop_data/{crop}_subcrop_data.csv\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df[\"main-crop\"] = crop  # Add main crop column\n",
    "        all_subcrop_data.append(df)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: File {file_path} not found. Skipping.\")\n",
    "\n",
    "# Merge all subcrop data\n",
    "df = pd.concat(all_subcrop_data, ignore_index=True)\n",
    "\n",
    "# Save merged dataset\n",
    "df.to_csv(\"../datasets/merged_subcrop_data.csv\", index=False)\n",
    "\n",
    "# Ensure 'sub-crop' column exists\n",
    "if 'sub-crop' not in df.columns:\n",
    "    raise ValueError(\"Missing 'sub-crop' column in sub_crop_data.csv files!\")\n",
    "\n",
    "# Feature Selection\n",
    "X = df[['main-crop', 'N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    "y = df['sub-crop']\n",
    "\n",
    "# Encode categorical variable 'main-crop'\n",
    "label_encoder_X = LabelEncoder()\n",
    "X['main-crop'] = label_encoder_X.fit_transform(X['main-crop'])\n",
    "\n",
    "# Encode target variable 'sub-crop'\n",
    "label_encoder_y = LabelEncoder()\n",
    "y_encoded = label_encoder_y.fit_transform(y)\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']] = scaler.fit_transform(\n",
    "    X[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    ")\n",
    "\n",
    "# Handle class imbalance using SMOTE\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X, y_encoded = smote.fit_resample(X, y_encoded)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# Hyperparameter tuning for XGBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [6, 10, 15],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(objective='multi:softmax', num_class=len(label_encoder_y.classes_), random_state=42)\n",
    "clf = GridSearchCV(xgb, param_grid, cv=5, verbose=1, n_jobs=-1, scoring='accuracy')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Best model from hyperparameter tuning\n",
    "best_model = clf.best_estimator_\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Convert predictions back to original labels\n",
    "y_pred_labels = label_encoder_y.inverse_transform(y_pred)\n",
    "y_test_labels = label_encoder_y.inverse_transform(y_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Best Model Parameters:\", clf.best_params_)\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test_labels, y_pred_labels))\n",
    "print(classification_report(y_test_labels, y_pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10eadcdf-e1f5-465a-8d6d-79d915b15f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset saved as 'merged_subcrop_data.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aarth\\AppData\\Local\\Temp\\ipykernel_10764\\3295950877.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['main-crop'] = label_encoder.fit_transform(X['main-crop'])\n",
      "C:\\Users\\aarth\\AppData\\Local\\Temp\\ipykernel_10764\\3295950877.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']] = scaler.fit_transform(X[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3161290322580645\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "        Apricot       0.45      0.65      0.53        20\n",
      "          Bajra       0.42      0.40      0.41        20\n",
      "         Banana       0.48      0.50      0.49        60\n",
      "   Basmati Rice       0.22      0.25      0.23        20\n",
      "    Bengal Gram       0.13      0.10      0.11        20\n",
      "            Ber       0.00      0.00      0.00        20\n",
      " Black Chickpea       0.22      0.30      0.26        20\n",
      "     Black Gram       0.23      0.23      0.23       100\n",
      "   Black Pepper       0.52      0.62      0.57        40\n",
      "     Black Rice       0.33      0.20      0.25        20\n",
      "   Bottle Gourd       0.24      0.20      0.22        20\n",
      "     Brown Rice       0.22      0.30      0.26        20\n",
      "      Cardamoms       0.85      0.55      0.67        20\n",
      "       Chakotha       0.23      0.25      0.24        20\n",
      "Charleston Gray       0.35      0.35      0.35        20\n",
      "         Cherry       0.58      0.55      0.56        20\n",
      "       Chickoos       0.09      0.10      0.10        20\n",
      "       Chickpea       0.26      0.32      0.29       100\n",
      "          Cocoa       0.38      0.42      0.40        40\n",
      "         Cowpea       0.11      0.12      0.11        60\n",
      "  Crimson Sweet       0.19      0.15      0.17        20\n",
      "  Custard Apple       0.28      0.25      0.26        60\n",
      "  Desi Chickpea       0.22      0.20      0.21        20\n",
      "            Fig       0.47      0.42      0.45        40\n",
      " Foxtail Millet       0.29      0.35      0.32        20\n",
      "         Ginger       0.65      0.75      0.70        20\n",
      " Green Chickpea       0.48      0.50      0.49        20\n",
      "     Green Gram       0.28      0.25      0.27       120\n",
      "      Groundnut       0.43      0.38      0.40        40\n",
      "          Guava       0.18      0.20      0.19        60\n",
      "    Indica Rice       0.26      0.25      0.26        20\n",
      "     Jack Fruit       0.32      0.30      0.31        20\n",
      "  Japonica Rice       0.21      0.20      0.21        20\n",
      "          Jowar       0.24      0.20      0.22        20\n",
      "        Jubilee       0.24      0.30      0.27        20\n",
      "Kabuli Chickpea       0.11      0.10      0.10        20\n",
      "         Kinnow       0.30      0.30      0.30        20\n",
      "          Lemon       0.33      0.30      0.32        20\n",
      "         Lentil       0.32      0.30      0.31        20\n",
      "          Maize       0.33      0.30      0.32        20\n",
      "          Mango       0.50      0.70      0.58        20\n",
      "         Papaya       0.22      0.28      0.24        40\n",
      "           Pear       0.88      0.70      0.78        20\n",
      "     Pegeon Pea       0.19      0.18      0.18        60\n",
      "      Persimmon       0.39      0.35      0.37        20\n",
      "     Pigeon Pea       0.33      0.35      0.34        40\n",
      "      Pineapple       0.42      0.42      0.42        60\n",
      "           Plum       0.50      0.45      0.47        20\n",
      "    Pomegranate       0.45      0.33      0.38        40\n",
      "        Pumpkin       0.42      0.40      0.41        20\n",
      "           Rice       0.26      0.25      0.26        20\n",
      "         Sesame       0.63      0.60      0.62        20\n",
      "        Sesamum       0.30      0.28      0.29        40\n",
      "       Soyabean       0.30      0.35      0.33        20\n",
      "     Sugar Baby       0.19      0.20      0.20        20\n",
      "      Sugarcane       0.29      0.20      0.24        20\n",
      "       Turmeric       0.36      0.25      0.29        40\n",
      "     Watermelon       0.38      0.45      0.41        20\n",
      "    Yellow Doll       0.17      0.15      0.16        20\n",
      "\n",
      "       accuracy                           0.32      1860\n",
      "      macro avg       0.33      0.33      0.33      1860\n",
      "   weighted avg       0.32      0.32      0.32      1860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load main crop recommendation data\n",
    "main_df = pd.read_csv(\"../datasets/Crop_recommendation.csv\")\n",
    "\n",
    "# List to store all subcrop data\n",
    "all_subcrop_data = []\n",
    "for crop in main_df[\"label\"].unique():  # Ensure \"label\" is the correct column name in Crop_recommendation.csv\n",
    "    file_path = f\"../datasets/sub_crop_data/{crop}_subcrop_data.csv\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df[\"main-crop\"] = crop  # Add main crop column\n",
    "        all_subcrop_data.append(df)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: File {file_path} not found. Skipping.\")\n",
    "\n",
    "# Merge all subcrop data\n",
    "df = pd.concat(all_subcrop_data, ignore_index=True)\n",
    "\n",
    "# Save merged dataset\n",
    "df.to_csv(\"../datasets/merged_subcrop_data.csv\", index=False)\n",
    "print(\"Merged dataset saved as 'merged_subcrop_data.csv'.\")\n",
    "\n",
    "# Ensure 'sub_crop' column exists\n",
    "if 'sub-crop' not in df.columns:\n",
    "    raise ValueError(\"Missing 'sub_crop' column in sub_crop_data.csv files!\")\n",
    "\n",
    "# Feature Selection\n",
    "X = df[['main-crop', 'N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    "y = df['sub-crop']\n",
    "\n",
    "# Encode categorical variable 'main_crop'\n",
    "label_encoder = LabelEncoder()\n",
    "X['main-crop'] = label_encoder.fit_transform(X['main-crop'])\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']] = scaler.fit_transform(X[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train Random Forest Model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3006b2e8-a5d5-4f33-9d40-0c885be1cbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset saved as 'merged_subcrop_data.csv'.\n",
      "KNN Accuracy (k=5): 0.2543010752688172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aarth\\AppData\\Local\\Temp\\ipykernel_10764\\765560364.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['main-crop'] = label_encoder.fit_transform(X['main-crop'])\n",
      "C:\\Users\\aarth\\AppData\\Local\\Temp\\ipykernel_10764\\765560364.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']] = scaler.fit_transform(X[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "        Apricot       0.38      0.50      0.43        20\n",
      "          Bajra       0.41      0.55      0.47        20\n",
      "         Banana       0.38      0.45      0.41        60\n",
      "   Basmati Rice       0.31      0.45      0.37        20\n",
      "    Bengal Gram       0.04      0.05      0.04        20\n",
      "            Ber       0.04      0.05      0.04        20\n",
      " Black Chickpea       0.15      0.20      0.17        20\n",
      "     Black Gram       0.18      0.24      0.20       100\n",
      "   Black Pepper       0.33      0.50      0.40        40\n",
      "     Black Rice       0.47      0.35      0.40        20\n",
      "   Bottle Gourd       0.32      0.45      0.38        20\n",
      "     Brown Rice       0.21      0.35      0.26        20\n",
      "      Cardamoms       0.64      0.70      0.67        20\n",
      "       Chakotha       0.33      0.45      0.38        20\n",
      "Charleston Gray       0.21      0.30      0.24        20\n",
      "         Cherry       0.28      0.40      0.33        20\n",
      "       Chickoos       0.12      0.15      0.13        20\n",
      "       Chickpea       0.21      0.26      0.24       100\n",
      "          Cocoa       0.28      0.25      0.26        40\n",
      "         Cowpea       0.18      0.20      0.19        60\n",
      "  Crimson Sweet       0.11      0.05      0.07        20\n",
      "  Custard Apple       0.18      0.18      0.18        60\n",
      "  Desi Chickpea       0.26      0.25      0.26        20\n",
      "            Fig       0.36      0.30      0.33        40\n",
      " Foxtail Millet       0.20      0.20      0.20        20\n",
      "         Ginger       0.37      0.55      0.44        20\n",
      " Green Chickpea       0.14      0.10      0.12        20\n",
      "     Green Gram       0.23      0.26      0.25       120\n",
      "      Groundnut       0.36      0.33      0.34        40\n",
      "          Guava       0.24      0.18      0.21        60\n",
      "    Indica Rice       0.23      0.15      0.18        20\n",
      "     Jack Fruit       0.21      0.20      0.21        20\n",
      "  Japonica Rice       0.33      0.15      0.21        20\n",
      "          Jowar       0.46      0.30      0.36        20\n",
      "        Jubilee       0.08      0.10      0.09        20\n",
      "Kabuli Chickpea       0.19      0.15      0.17        20\n",
      "         Kinnow       0.30      0.30      0.30        20\n",
      "          Lemon       0.46      0.30      0.36        20\n",
      "         Lentil       0.28      0.25      0.26        20\n",
      "          Maize       0.19      0.20      0.20        20\n",
      "          Mango       0.32      0.55      0.41        20\n",
      "         Papaya       0.24      0.25      0.24        40\n",
      "           Pear       0.56      0.25      0.34        20\n",
      "     Pegeon Pea       0.20      0.15      0.17        60\n",
      "      Persimmon       0.31      0.40      0.35        20\n",
      "     Pigeon Pea       0.25      0.12      0.17        40\n",
      "      Pineapple       0.30      0.23      0.26        60\n",
      "           Plum       0.20      0.10      0.13        20\n",
      "    Pomegranate       0.39      0.33      0.36        40\n",
      "        Pumpkin       0.23      0.25      0.24        20\n",
      "           Rice       0.33      0.30      0.32        20\n",
      "         Sesame       0.27      0.20      0.23        20\n",
      "        Sesamum       0.09      0.07      0.08        40\n",
      "       Soyabean       0.36      0.20      0.26        20\n",
      "     Sugar Baby       0.16      0.15      0.15        20\n",
      "      Sugarcane       0.10      0.05      0.07        20\n",
      "       Turmeric       0.27      0.10      0.15        40\n",
      "     Watermelon       0.20      0.10      0.13        20\n",
      "    Yellow Doll       0.18      0.15      0.16        20\n",
      "\n",
      "       accuracy                           0.25      1860\n",
      "      macro avg       0.26      0.26      0.25      1860\n",
      "   weighted avg       0.26      0.25      0.25      1860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load main crop recommendation data\n",
    "main_df = pd.read_csv(\"../datasets/Crop_recommendation.csv\")\n",
    "\n",
    "# List to store all subcrop data\n",
    "all_subcrop_data = []\n",
    "for crop in main_df[\"label\"].unique():  # Ensure \"label\" is the correct column name in Crop_recommendation.csv\n",
    "    file_path = f\"../datasets/sub_crop_data/{crop}_subcrop_data.csv\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df[\"main-crop\"] = crop  # Add main crop column\n",
    "        all_subcrop_data.append(df)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: File {file_path} not found. Skipping.\")\n",
    "\n",
    "# Merge all subcrop data\n",
    "df = pd.concat(all_subcrop_data, ignore_index=True)\n",
    "\n",
    "# Save merged dataset\n",
    "df.to_csv(\"../datasets/merged_subcrop_data.csv\", index=False)\n",
    "print(\"Merged dataset saved as 'merged_subcrop_data.csv'.\")\n",
    "\n",
    "# Ensure 'sub_crop' column exists\n",
    "if 'sub-crop' not in df.columns:\n",
    "    raise ValueError(\"Missing 'sub_crop' column in sub_crop_data.csv files!\")\n",
    "\n",
    "# Feature Selection\n",
    "X = df[['main-crop', 'N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    "y = df['sub-crop']\n",
    "\n",
    "# Encode categorical variable 'main_crop'\n",
    "label_encoder = LabelEncoder()\n",
    "X['main-crop'] = label_encoder.fit_transform(X['main-crop'])\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']] = scaler.fit_transform(X[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train KNN Model\n",
    "k = 5  # You can try different values of K (3, 5, 7, etc.)\n",
    "knn = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"KNN Accuracy (k={k}):\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fc32f29-12ac-4889-8d16-2ba9c43cfa16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Case 1: [90, 42, 43, 20.8, 82.0, 6.5, 202.9]\n",
      "Result: {'main_crop': 'rice', 'main_confidence': 0.99, 'sub_crops': [{'sub_crop': 'Japonica Rice', 'distance': 4.65287621842113}, {'sub_crop': 'Indica Rice', 'distance': 4.95321969937769}, {'sub_crop': 'Japonica Rice', 'distance': 5.513283880116667}], 'warnings': None}\n",
      "\n",
      "Test Case 2: [500, 200, 300, 50.0, 10.0, 14.0, 1000.0]\n",
      "Result: {'main_crop': 'grapes', 'main_confidence': 0.2, 'sub_crops': [{'sub_crop': 'Pomegranate', 'distance': 467.32482973213354}, {'sub_crop': 'Pomegranate', 'distance': 470.19616179038746}, {'sub_crop': 'Pomegranate', 'distance': 470.3618455320737}], 'warnings': ['N (500.0) outside realistic range (0-200), capped', 'K (300.0) outside realistic range (0-250), capped', 'ph (14.0) outside realistic range (3-11), capped', 'rainfall (1000.0) outside realistic range (0-500), capped']}\n",
      "\n",
      "Test Case 3: [-10, 50, 60, 25.0, 75.0, 7.0, 150.0]\n",
      "Result: {'main_crop': 'papaya', 'main_confidence': 0.3, 'sub_crops': [{'sub_crop': 'Guava', 'distance': 38.05431213067573}, {'sub_crop': 'Pineapple', 'distance': 38.43404738752344}, {'sub_crop': 'Banana', 'distance': 40.27656839629202}], 'warnings': ['N (-10.0) outside realistic range (0-200), capped']}\n",
      "\n",
      "Test Case 4: [100, 'invalid', 60, 25.0, 75.0, 7.0, 150.0]\n",
      "Result: {'error': 'Invalid input: P must be a number', 'main_crop': None, 'sub_crops': [], 'warnings': []}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Step 1: Load Main Crop Model\n",
    "def load_main_crop_model():\n",
    "    with open('main_crop_model.pkl', 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "# Step 2: Define Realistic Ranges\n",
    "realistic_ranges = {\n",
    "    'N': (0, 200), 'P': (0, 200), 'K': (0, 250), 'temperature': (5, 50),\n",
    "    'humidity': (0, 100), 'ph': (3, 11), 'rainfall': (0, 500)\n",
    "}\n",
    "\n",
    "# Step 3: Input Validation and Preprocessing\n",
    "def validate_and_preprocess_input(N, P, K, temperature, humidity, ph, rainfall):\n",
    "    inputs = {'N': N, 'P': P, 'K': K, 'temperature': temperature, \n",
    "              'humidity': humidity, 'ph': ph, 'rainfall': rainfall}\n",
    "    \n",
    "    for param, val in inputs.items():\n",
    "        try:\n",
    "            inputs[param] = float(val)\n",
    "        except (ValueError, TypeError):\n",
    "            return False, f\"Invalid input: {param} must be a number\", []\n",
    "    \n",
    "    capped_inputs = {}\n",
    "    warnings_list = []\n",
    "    for param, val in inputs.items():\n",
    "        min_val, max_val = realistic_ranges[param]\n",
    "        if val < min_val or val > max_val:\n",
    "            warnings_list.append(f\"{param} ({val}) outside realistic range ({min_val}-{max_val}), capped\")\n",
    "            capped_inputs[param] = max(min_val, min(val, max_val))\n",
    "        else:\n",
    "            capped_inputs[param] = val\n",
    "    \n",
    "    return True, capped_inputs, warnings_list\n",
    "\n",
    "# Step 4: Main Crop to Sub-Crop File Mapping\n",
    "crop_name_mapping = {\n",
    "    'rice': 'rice_subcrop_data.csv',\n",
    "    'wheat': 'wheat_subcrop_data.csv',  # Missing, add if needed\n",
    "    'maize': 'maize_subcrop_data.csv',\n",
    "    'chickpea': 'Bengal Gram_subcrop_data.csv',\n",
    "    'kidneybeans': 'kidneybeans_subcrop_data.csv',\n",
    "    'pigeonpeas': 'Pegeon Pea_subcrop_data.csv',\n",
    "    'mothbeans': 'Moath Dal_subcrop_data.csv',\n",
    "    'mungbean': 'Green Gram_subcrop_data.csv',\n",
    "    'blackgram': 'Black Gram_subcrop_data.csv',\n",
    "    'lentil': 'lentil_subcrop_data.csv',\n",
    "    'pomegranate': 'pomegranate_subcrop_data.csv',\n",
    "    'banana': 'banana_subcrop_data.csv',\n",
    "    'mango': 'mango_subcrop_data.csv',\n",
    "    'grapes': 'grapes_subcrop_data.csv',\n",
    "    'watermelon': 'Water Melon_subcrop_data.csv',\n",
    "    'muskmelon': 'Karbuja_subcrop_data.csv',\n",
    "    'apple': 'apple_subcrop_data.csv',\n",
    "    'orange': 'orange_subcrop_data.csv',\n",
    "    'papaya': 'papaya_subcrop_data.csv',\n",
    "    'coconut': 'coconut_subcrop_data.csv',\n",
    "    'cotton': 'cotton_subcrop_data.csv',\n",
    "    'jute': 'jute_subcrop_data.csv'\n",
    "}\n",
    "\n",
    "# Step 5: Sub-Crop Recommendation Function\n",
    "def recommend_sub_crops(N, P, K, temperature, humidity, ph, rainfall, \n",
    "                        subcrop_dir='../datasets/sub_crop_data/', num_recommendations=3):\n",
    "    try:\n",
    "        # Load main crop model\n",
    "        main_model = load_main_crop_model()\n",
    "        \n",
    "        # Validate and preprocess input\n",
    "        is_valid, capped_inputs_or_error, warnings = validate_and_preprocess_input(\n",
    "            N, P, K, temperature, humidity, ph, rainfall\n",
    "        )\n",
    "        if not is_valid:\n",
    "            return {\"error\": capped_inputs_or_error, \"main_crop\": None, \"sub_crops\": [], \"warnings\": warnings}\n",
    "        \n",
    "        # Predict main crop\n",
    "        input_df = pd.DataFrame([[capped_inputs_or_error['N'], capped_inputs_or_error['P'], \n",
    "                                  capped_inputs_or_error['K'], capped_inputs_or_error['temperature'], \n",
    "                                  capped_inputs_or_error['humidity'], capped_inputs_or_error['ph'], \n",
    "                                  capped_inputs_or_error['rainfall']]],\n",
    "                                columns=['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall'])\n",
    "        main_crop = main_model.predict(input_df)[0]\n",
    "        main_confidence = float(max(main_model.predict_proba(input_df)[0]))\n",
    "        \n",
    "        # Get sub-crop file name from mapping\n",
    "        if main_crop not in crop_name_mapping:\n",
    "            return {\"error\": f\"No sub-crop mapping for {main_crop}\", \"main_crop\": main_crop, \n",
    "                    \"sub_crops\": [], \"warnings\": warnings}\n",
    "        \n",
    "        subcrop_filename = crop_name_mapping[main_crop]\n",
    "        subcrop_file = os.path.join(subcrop_dir, subcrop_filename)\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not os.path.exists(subcrop_file):\n",
    "            return {\"error\": f\"Sub-crop file {subcrop_filename} not found at {subcrop_file}\", \n",
    "                    \"main_crop\": main_crop, \"sub_crops\": [], \"warnings\": warnings}\n",
    "        \n",
    "        # Load sub-crop data\n",
    "        sub_crop_df = pd.read_csv(subcrop_file)\n",
    "        \n",
    "        # Define expected columns (adjusted to your data)\n",
    "        required_cols = ['sub-crop', 'N', 'P', 'K', 'rainfall', 'ph', 'humidity']\n",
    "        \n",
    "        # Check columns\n",
    "        missing_cols = [col for col in required_cols if col not in sub_crop_df.columns]\n",
    "        if missing_cols:\n",
    "            print(f\"Debug: Columns in {subcrop_filename}: {sub_crop_df.columns.tolist()}\")\n",
    "            print(f\"Debug: Missing columns: {missing_cols}\")\n",
    "            return {\"error\": f\"Sub-crop file {subcrop_filename} missing required columns: {missing_cols}\", \n",
    "                    \"main_crop\": main_crop, \"sub_crops\": [], \"warnings\": warnings}\n",
    "        \n",
    "        # Input features for distance calculation\n",
    "        input_vector = np.array([[capped_inputs_or_error['N'], capped_inputs_or_error['P'], \n",
    "                                  capped_inputs_or_error['K'], capped_inputs_or_error['rainfall'], \n",
    "                                  capped_inputs_or_error['ph'], capped_inputs_or_error['humidity']]])\n",
    "        sub_crop_features = sub_crop_df[['N', 'P', 'K', 'rainfall', 'ph', 'humidity']].values\n",
    "        \n",
    "        # Calculate Euclidean distances\n",
    "        distances = euclidean_distances(input_vector, sub_crop_features)[0]\n",
    "        \n",
    "        # Sort sub-crops by distance and select top N\n",
    "        sub_crops_with_distances = list(zip(sub_crop_df['sub-crop'], distances))\n",
    "        sorted_sub_crops = sorted(sub_crops_with_distances, key=lambda x: x[1])[:num_recommendations]\n",
    "        recommended_sub_crops = [{\"sub_crop\": crop, \"distance\": float(dist)} for crop, dist in sorted_sub_crops]\n",
    "        \n",
    "        # Result\n",
    "        result = {\n",
    "            \"main_crop\": main_crop,\n",
    "            \"main_confidence\": main_confidence,\n",
    "            \"sub_crops\": recommended_sub_crops,\n",
    "            \"warnings\": warnings if warnings else None\n",
    "        }\n",
    "        return result\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        return {\"error\": f\"File error: {str(e)}\", \"main_crop\": None, \"sub_crops\": [], \"warnings\": None}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Sub-crop recommendation failed: {str(e)}\", \"main_crop\": None, \n",
    "                \"sub_crops\": [], \"warnings\": None}\n",
    "\n",
    "# Step 6: Test the Sub-Crop Model\n",
    "if __name__ == \"__main__\":\n",
    "    # Test cases\n",
    "    test_cases = [\n",
    "        [90, 42, 43, 20.8, 82.0, 6.5, 202.9],  # Normal input\n",
    "        [500, 200, 300, 50.0, 10.0, 14.0, 1000.0],  # Extreme input\n",
    "        [-10, 50, 60, 25.0, 75.0, 7.0, 150.0],  # Negative value\n",
    "        [100, \"invalid\", 60, 25.0, 75.0, 7.0, 150.0]  # Invalid type\n",
    "    ]\n",
    "    \n",
    "    for i, test_input in enumerate(test_cases, 1):\n",
    "        print(f\"\\nTest Case {i}: {test_input}\")\n",
    "        result = recommend_sub_crops(*test_input, subcrop_dir='../datasets/sub_crop_data/')\n",
    "        print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5be2a268-4370-4a9d-993b-4b758988026d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.52% (Correct: 8470/8597)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Load Main Crop Model\n",
    "def load_main_crop_model():\n",
    "    with open('main_crop_model.pkl', 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "# Realistic Ranges\n",
    "realistic_ranges = {\n",
    "    'N': (0, 200), 'P': (0, 200), 'K': (0, 250), 'temperature': (5, 50),\n",
    "    'humidity': (0, 100), 'ph': (3, 11), 'rainfall': (0, 500)\n",
    "}\n",
    "\n",
    "# Input Validation\n",
    "def validate_and_preprocess_input(N, P, K, temperature, humidity, ph, rainfall):\n",
    "    inputs = {'N': N, 'P': P, 'K': K, 'temperature': temperature, \n",
    "              'humidity': humidity, 'ph': ph, 'rainfall': rainfall}\n",
    "    for param, val in inputs.items():\n",
    "        try:\n",
    "            inputs[param] = float(val)\n",
    "        except (ValueError, TypeError):\n",
    "            return False, f\"Invalid input: {param} must be a number\", []\n",
    "    capped_inputs = {}\n",
    "    warnings_list = []\n",
    "    for param, val in inputs.items():\n",
    "        min_val, max_val = realistic_ranges[param]\n",
    "        if val < min_val or val > max_val:\n",
    "            warnings_list.append(f\"{param} ({val}) outside realistic range ({min_val}-{max_val}), capped\")\n",
    "            capped_inputs[param] = max(min_val, min(val, max_val))\n",
    "        else:\n",
    "            capped_inputs[param] = val\n",
    "    return True, capped_inputs, warnings_list\n",
    "\n",
    "# Updated Crop Mapping\n",
    "crop_name_mapping = {\n",
    "    'Rice': 'Rice_subcrop_data.csv',\n",
    "    'Maize': 'Maize_subcrop_data.csv',\n",
    "    'Bengal Gram (Gram)(Whole)': 'Bengal Gram (Gram)(Whole)_subcrop_data.csv',\n",
    "    'Pegeon Pea (Arhar Fali)': 'Pegeon Pea (Arhar Fali)_subcrop_data.csv',\n",
    "    'Moath Dal': 'Moath Dal_subcrop_data.csv',\n",
    "    'Green Gram (Moong)(Whole)': 'Green Gram (Moong)(Whole)_subcrop_data.csv',\n",
    "    'Black Gram (Urd Beans)(Whole)': 'Black Gram (Urd Beans)(Whole)_subcrop_data.csv',\n",
    "    'Lentil (Masur)(Whole)': 'Lentil (Masur)(Whole)_subcrop_data.csv',\n",
    "    'Pomegranate': 'Pomegranate_subcrop_data.csv',\n",
    "    'Banana': 'Banana_subcrop_data.csv',\n",
    "    'Mango': 'Mango_subcrop_data.csv',\n",
    "    'Grapes': 'Grapes_subcrop_data.csv',\n",
    "    'Water Melon': 'Water Melon_subcrop_data.csv',\n",
    "    'Karbuja (Musk Melon)': 'Karbuja (Musk Melon)_subcrop_data.csv',\n",
    "    'Apple': 'Apple_subcrop_data.csv',\n",
    "    'Orange': 'Orange_subcrop_data.csv',\n",
    "    'Papaya': 'Papaya_subcrop_data.csv',\n",
    "    'Coconut': 'Coconut_subcrop_data.csv',\n",
    "    'Cotton': 'Cotton_subcrop_data.csv',\n",
    "    'Jute': 'Jute_subcrop_data.csv',\n",
    "    'Coffee': 'Coffee_subcrop_data.csv'\n",
    "}\n",
    "\n",
    "# Sub-Crop Recommendation\n",
    "def recommend_sub_crops(N, P, K, temperature, humidity, ph, rainfall, \n",
    "                        subcrop_dir='../datasets/sub_crop_data/', num_recommendations=3):\n",
    "    try:\n",
    "        main_model = load_main_crop_model()\n",
    "        is_valid, capped_inputs, warnings = validate_and_preprocess_input(\n",
    "            N, P, K, temperature, humidity, ph, rainfall\n",
    "        )\n",
    "        if not is_valid:\n",
    "            return {\"error\": capped_inputs, \"main_crop\": None, \"sub_crops\": [], \"warnings\": warnings}\n",
    "        \n",
    "        input_df = pd.DataFrame([[capped_inputs['N'], capped_inputs['P'], \n",
    "                                  capped_inputs['K'], capped_inputs['temperature'], \n",
    "                                  capped_inputs['humidity'], capped_inputs['ph'], \n",
    "                                  capped_inputs['rainfall']]],\n",
    "                                columns=['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall'])\n",
    "        main_crop = main_model.predict(input_df)[0]\n",
    "        main_confidence = float(max(main_model.predict_proba(input_df)[0]))\n",
    "        \n",
    "        if main_crop not in crop_name_mapping:\n",
    "            return {\"error\": f\"No sub-crop mapping for {main_crop}\", \"main_crop\": main_crop, \n",
    "                    \"sub_crops\": [], \"warnings\": warnings}\n",
    "        \n",
    "        subcrop_filename = crop_name_mapping[main_crop]\n",
    "        subcrop_file = os.path.join(subcrop_dir, subcrop_filename)\n",
    "        \n",
    "        if not os.path.exists(subcrop_file):\n",
    "            return {\"error\": f\"Sub-crop file {subcrop_filename} not found\", \n",
    "                    \"main_crop\": main_crop, \"sub_crops\": [], \"warnings\": warnings}\n",
    "        \n",
    "        sub_crop_df = pd.read_csv(subcrop_file)\n",
    "        required_cols = ['sub-crop', 'N', 'P', 'K', 'temperature', 'rainfall', 'ph', 'humidity']\n",
    "        missing_cols = [col for col in required_cols if col not in sub_crop_df.columns]\n",
    "        if missing_cols:\n",
    "            return {\"error\": f\"Missing columns: {missing_cols}\", \"main_crop\": main_crop, \n",
    "                    \"sub_crops\": [], \"warnings\": warnings}\n",
    "        \n",
    "        # Include temperature in distance calculation\n",
    "        input_vector = np.array([[capped_inputs['N'], capped_inputs['P'], capped_inputs['K'], \n",
    "                                  capped_inputs['temperature'], capped_inputs['rainfall'], \n",
    "                                  capped_inputs['ph'], capped_inputs['humidity']]])\n",
    "        sub_crop_features = sub_crop_df[['N', 'P', 'K', 'temperature', 'rainfall', 'ph', 'humidity']].values\n",
    "        \n",
    "        distances = euclidean_distances(input_vector, sub_crop_features)[0]\n",
    "        sub_crops_with_distances = list(zip(sub_crop_df['sub-crop'], distances))\n",
    "        sorted_sub_crops = sorted(sub_crops_with_distances, key=lambda x: x[1])[:num_recommendations]\n",
    "        recommended_sub_crops = [{\"sub_crop\": crop, \"distance\": float(dist)} for crop, dist in sorted_sub_crops]\n",
    "        \n",
    "        return {\n",
    "            \"main_crop\": main_crop,\n",
    "            \"main_confidence\": main_confidence,\n",
    "            \"sub_crops\": recommended_sub_crops,\n",
    "            \"warnings\": warnings if warnings else None\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"main_crop\": None, \"sub_crops\": [], \"warnings\": None}\n",
    "\n",
    "# Accuracy Calculation with File Output\n",
    "def calculate_subcrop_accuracy(subcrop_dir='../datasets/sub_crop_data/', num_recommendations=3):\n",
    "    total_tests = 0\n",
    "    correct_matches = 0\n",
    "    \n",
    "    # Open debug file for writing\n",
    "    with open('subcrop_accuracy_debug.txt', 'w') as debug_file:\n",
    "        for main_crop, filename in crop_name_mapping.items():\n",
    "            file_path = os.path.join(subcrop_dir, filename)\n",
    "            if not os.path.exists(file_path):\n",
    "                debug_file.write(f\"Skipping {main_crop}: {filename} not found\\n\")\n",
    "                continue\n",
    "            \n",
    "            sub_crop_df = pd.read_csv(file_path)\n",
    "            required_cols = ['sub-crop', 'N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']\n",
    "            if not all(col in sub_crop_df.columns for col in required_cols):\n",
    "                debug_file.write(f\"Skipping {main_crop}: {filename} missing required columns\\n\")\n",
    "                continue\n",
    "            \n",
    "            for _, row in sub_crop_df.iterrows():\n",
    "                expected_sub_crop = row['sub-crop']\n",
    "                test_input = [row['N'], row['P'], row['K'], row['temperature'], \n",
    "                              row['humidity'], row['ph'], row['rainfall']]\n",
    "                \n",
    "                result = recommend_sub_crops(*test_input, subcrop_dir=subcrop_dir, \n",
    "                                            num_recommendations=num_recommendations)\n",
    "                \n",
    "                if \"error\" in result:\n",
    "                    debug_file.write(f\"Error for {main_crop}: {result['error']}\\n\")\n",
    "                    continue\n",
    "                \n",
    "                predicted_sub_crops = [item['sub_crop'] for item in result['sub_crops']]\n",
    "                total_tests += 1\n",
    "                \n",
    "                if expected_sub_crop in predicted_sub_crops:\n",
    "                    correct_matches += 1\n",
    "                else:\n",
    "                    debug_file.write(f\"Mismatch for {main_crop}: Expected {expected_sub_crop}, Got {predicted_sub_crops}\\n\")\n",
    "        \n",
    "        accuracy = (correct_matches / total_tests) * 100 if total_tests > 0 else 0.0\n",
    "        accuracy_message = f\"Accuracy: {accuracy:.2f}% (Correct: {correct_matches}/{total_tests})\"\n",
    "        debug_file.write(f\"\\n{accuracy_message}\\n\")\n",
    "    \n",
    "    return accuracy, accuracy_message\n",
    "\n",
    "# Run Test\n",
    "if __name__ == \"__main__\":\n",
    "    accuracy, message = calculate_subcrop_accuracy(subcrop_dir='../datasets/sub_crop_data/')\n",
    "    print(message)  # Print only the final accuracy to console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14b1368c-2901-4134-98ef-fb979023d5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-crop recommender model saved as 'subcrop_recommender.pkl'\n",
      "Prediction Result: {'main_crop': 'Coconut', 'main_confidence': 0.47, 'sub_crops': [{'sub_crop': 'Cocoa', 'distance': 15.111247247683465}, {'sub_crop': 'Cocoa', 'distance': 15.724221952580418}, {'sub_crop': 'Banana', 'distance': 16.027305422593663}], 'warnings': None}\n",
      "Accuracy: 98.52% (Correct: 8470/8597)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Realistic Ranges\n",
    "realistic_ranges = {\n",
    "    'N': (0, 200), 'P': (0, 200), 'K': (0, 250), 'temperature': (5, 50),\n",
    "    'humidity': (0, 100), 'ph': (3, 11), 'rainfall': (0, 500)\n",
    "}\n",
    "\n",
    "# Updated Crop Mapping\n",
    "crop_name_mapping = {\n",
    "    'Rice': 'Rice_subcrop_data.csv',\n",
    "    'Maize': 'Maize_subcrop_data.csv',\n",
    "    'Bengal Gram (Gram)(Whole)': 'Bengal Gram (Gram)(Whole)_subcrop_data.csv',\n",
    "    'Pegeon Pea (Arhar Fali)': 'Pegeon Pea (Arhar Fali)_subcrop_data.csv',\n",
    "    'Moath Dal': 'Moath Dal_subcrop_data.csv',\n",
    "    'Green Gram (Moong)(Whole)': 'Green Gram (Moong)(Whole)_subcrop_data.csv',\n",
    "    'Black Gram (Urd Beans)(Whole)': 'Black Gram (Urd Beans)(Whole)_subcrop_data.csv',\n",
    "    'Lentil (Masur)(Whole)': 'Lentil (Masur)(Whole)_subcrop_data.csv',\n",
    "    'Pomegranate': 'Pomegranate_subcrop_data.csv',\n",
    "    'Banana': 'Banana_subcrop_data.csv',\n",
    "    'Mango': 'Mango_subcrop_data.csv',\n",
    "    'Grapes': 'Grapes_subcrop_data.csv',\n",
    "    'Water Melon': 'Water Melon_subcrop_data.csv',\n",
    "    'Karbuja (Musk Melon)': 'Karbuja (Musk Melon)_subcrop_data.csv',\n",
    "    'Apple': 'Apple_subcrop_data.csv',\n",
    "    'Orange': 'Orange_subcrop_data.csv',\n",
    "    'Papaya': 'Papaya_subcrop_data.csv',\n",
    "    'Coconut': 'Coconut_subcrop_data.csv',\n",
    "    'Cotton': 'Cotton_subcrop_data.csv',\n",
    "    'Jute': 'Jute_subcrop_data.csv',\n",
    "    'Coffee': 'Coffee_subcrop_data.csv'\n",
    "}\n",
    "\n",
    "# SubCropRecommender Class\n",
    "class SubCropRecommender:\n",
    "    def __init__(self, main_model_path='main_crop_model.pkl', subcrop_dir='../datasets/sub_crop_data/'):\n",
    "        self.main_model = self.load_main_crop_model(main_model_path)\n",
    "        self.subcrop_dir = subcrop_dir\n",
    "        self.crop_name_mapping = crop_name_mapping\n",
    "        self.realistic_ranges = realistic_ranges\n",
    "\n",
    "    def load_main_crop_model(self, path):\n",
    "        with open(path, 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "\n",
    "    def validate_and_preprocess_input(self, N, P, K, temperature, humidity, ph, rainfall):\n",
    "        inputs = {'N': N, 'P': P, 'K': K, 'temperature': temperature, \n",
    "                  'humidity': humidity, 'ph': ph, 'rainfall': rainfall}\n",
    "        for param, val in inputs.items():\n",
    "            try:\n",
    "                inputs[param] = float(val)\n",
    "            except (ValueError, TypeError):\n",
    "                return False, f\"Invalid input: {param} must be a number\", []\n",
    "        capped_inputs = {}\n",
    "        warnings_list = []\n",
    "        for param, val in inputs.items():\n",
    "            min_val, max_val = self.realistic_ranges[param]\n",
    "            if val < min_val or val > max_val:\n",
    "                warnings_list.append(f\"{param} ({val}) outside realistic range ({min_val}-{max_val}), capped\")\n",
    "                capped_inputs[param] = max(min_val, min(val, max_val))\n",
    "            else:\n",
    "                capped_inputs[param] = val\n",
    "        return True, capped_inputs, warnings_list\n",
    "\n",
    "    def recommend_sub_crops(self, N, P, K, temperature, humidity, ph, rainfall, num_recommendations=3):\n",
    "        try:\n",
    "            is_valid, capped_inputs, warnings = self.validate_and_preprocess_input(\n",
    "                N, P, K, temperature, humidity, ph, rainfall\n",
    "            )\n",
    "            if not is_valid:\n",
    "                return {\"error\": capped_inputs, \"main_crop\": None, \"sub_crops\": [], \"warnings\": warnings}\n",
    "            \n",
    "            input_df = pd.DataFrame([[capped_inputs['N'], capped_inputs['P'], \n",
    "                                      capped_inputs['K'], capped_inputs['temperature'], \n",
    "                                      capped_inputs['humidity'], capped_inputs['ph'], \n",
    "                                      capped_inputs['rainfall']]],\n",
    "                                    columns=['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall'])\n",
    "            main_crop = self.main_model.predict(input_df)[0]\n",
    "            main_confidence = float(max(self.main_model.predict_proba(input_df)[0]))\n",
    "            \n",
    "            if main_crop not in self.crop_name_mapping:\n",
    "                return {\"error\": f\"No sub-crop mapping for {main_crop}\", \"main_crop\": main_crop, \n",
    "                        \"sub_crops\": [], \"warnings\": warnings}\n",
    "            \n",
    "            subcrop_filename = self.crop_name_mapping[main_crop]\n",
    "            subcrop_file = os.path.join(self.subcrop_dir, subcrop_filename)\n",
    "            \n",
    "            if not os.path.exists(subcrop_file):\n",
    "                return {\"error\": f\"Sub-crop file {subcrop_filename} not found\", \n",
    "                        \"main_crop\": main_crop, \"sub_crops\": [], \"warnings\": warnings}\n",
    "            \n",
    "            sub_crop_df = pd.read_csv(subcrop_file)\n",
    "            required_cols = ['sub-crop', 'N', 'P', 'K', 'temperature', 'rainfall', 'ph', 'humidity']\n",
    "            missing_cols = [col for col in required_cols if col not in sub_crop_df.columns]\n",
    "            if missing_cols:\n",
    "                return {\"error\": f\"Missing columns: {missing_cols}\", \"main_crop\": main_crop, \n",
    "                        \"sub_crops\": [], \"warnings\": warnings}\n",
    "            \n",
    "            input_vector = np.array([[capped_inputs['N'], capped_inputs['P'], capped_inputs['K'], \n",
    "                                      capped_inputs['temperature'], capped_inputs['rainfall'], \n",
    "                                      capped_inputs['ph'], capped_inputs['humidity']]])\n",
    "            sub_crop_features = sub_crop_df[['N', 'P', 'K', 'temperature', 'rainfall', 'ph', 'humidity']].values\n",
    "            \n",
    "            distances = euclidean_distances(input_vector, sub_crop_features)[0]\n",
    "            sub_crops_with_distances = list(zip(sub_crop_df['sub-crop'], distances))\n",
    "            sorted_sub_crops = sorted(sub_crops_with_distances, key=lambda x: x[1])[:num_recommendations]\n",
    "            recommended_sub_crops = [{\"sub_crop\": crop, \"distance\": float(dist)} for crop, dist in sorted_sub_crops]\n",
    "            \n",
    "            return {\n",
    "                \"main_crop\": main_crop,\n",
    "                \"main_confidence\": main_confidence,\n",
    "                \"sub_crops\": recommended_sub_crops,\n",
    "                \"warnings\": warnings if warnings else None\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e), \"main_crop\": None, \"sub_crops\": [], \"warnings\": None}\n",
    "\n",
    "    def calculate_subcrop_accuracy(self, num_recommendations=3):\n",
    "        total_tests = 0\n",
    "        correct_matches = 0\n",
    "        \n",
    "        with open('subcrop_accuracy_debug.txt', 'w') as debug_file:\n",
    "            for main_crop, filename in self.crop_name_mapping.items():\n",
    "                file_path = os.path.join(self.subcrop_dir, filename)\n",
    "                if not os.path.exists(file_path):\n",
    "                    debug_file.write(f\"Skipping {main_crop}: {filename} not found\\n\")\n",
    "                    continue\n",
    "                \n",
    "                sub_crop_df = pd.read_csv(file_path)\n",
    "                required_cols = ['sub-crop', 'N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']\n",
    "                if not all(col in sub_crop_df.columns for col in required_cols):\n",
    "                    debug_file.write(f\"Skipping {main_crop}: {filename} missing required columns\\n\")\n",
    "                    continue\n",
    "                \n",
    "                for _, row in sub_crop_df.iterrows():\n",
    "                    expected_sub_crop = row['sub-crop']\n",
    "                    test_input = [row['N'], row['P'], row['K'], row['temperature'], \n",
    "                                  row['humidity'], row['ph'], row['rainfall']]\n",
    "                    \n",
    "                    result = self.recommend_sub_crops(*test_input, num_recommendations=num_recommendations)\n",
    "                    \n",
    "                    if \"error\" in result:\n",
    "                        debug_file.write(f\"Error for {main_crop}: {result['error']}\\n\")\n",
    "                        continue\n",
    "                    \n",
    "                    predicted_sub_crops = [item['sub_crop'] for item in result['sub_crops']]\n",
    "                    total_tests += 1\n",
    "                    \n",
    "                    if expected_sub_crop in predicted_sub_crops:\n",
    "                        correct_matches += 1\n",
    "                    else:\n",
    "                        debug_file.write(f\"Mismatch for {main_crop}: Expected {expected_sub_crop}, Got {predicted_sub_crops}\\n\")\n",
    "            \n",
    "            accuracy = (correct_matches / total_tests) * 100 if total_tests > 0 else 0.0\n",
    "            accuracy_message = f\"Accuracy: {accuracy:.2f}% (Correct: {correct_matches}/{total_tests})\"\n",
    "            debug_file.write(f\"\\n{accuracy_message}\\n\")\n",
    "        \n",
    "        return accuracy, accuracy_message\n",
    "\n",
    "# Save the Model as a .pkl File\n",
    "def save_subcrop_model(filename='subcrop_recommender.pkl'):\n",
    "    recommender = SubCropRecommender(main_model_path='main_crop_model.pkl', \n",
    "                                     subcrop_dir='../datasets/sub_crop_data/')\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(recommender, file)\n",
    "    print(f\"Sub-crop recommender model saved as '{filename}'\")\n",
    "\n",
    "# Load and Use the Saved Model\n",
    "def load_subcrop_model(filename='subcrop_recommender.pkl'):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "# Test the Model\n",
    "if __name__ == \"__main__\":\n",
    "    # Save the model\n",
    "    save_subcrop_model('subcrop_recommender.pkl')\n",
    "    \n",
    "    # Load and test the saved model\n",
    "    recommender = load_subcrop_model('subcrop_recommender.pkl')\n",
    "    \n",
    "    # Example prediction\n",
    "    result = recommender.recommend_sub_crops(20, 30, 40, 25, 80, 6.0, 150)\n",
    "    print(\"Prediction Result:\", result)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy, message = recommender.calculate_subcrop_accuracy()\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23e86a23-deb0-4d52-84cb-14a7e87f86f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test API Response:\n",
      "{'main_crop': 'Karbuja (Musk Melon)', 'main_confidence': 1.0, 'sub_crops': [{'sub_crop': 'Pumpkin', 'distance': 4.352191270348047}, {'sub_crop': 'Water Melon', 'distance': 4.512648190896566}, {'sub_crop': 'Water Melon', 'distance': 4.708077704809503}], 'warnings': None}\n"
     ]
    }
   ],
   "source": [
    "# Load the trained SubCropRecommender model\n",
    "recommender = load_subcrop_model('subcrop_recommender.pkl')\n",
    "\n",
    "# Define the test input values\n",
    "N = 107\n",
    "P = 11\n",
    "K = 54\n",
    "temperature = 28.59052369\n",
    "humidity = 91.33617236\n",
    "ph = 6.094016338\n",
    "rainfall = 29.44008034\n",
    "\n",
    "# Get recommendations\n",
    "result = recommender.recommend_sub_crops(N, P, K, temperature, humidity, ph, rainfall)\n",
    "\n",
    "# Print results\n",
    "print(\"Test API Response:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766d10a2-b947-4ca7-8ebb-c41125dcab60",
   "metadata": {},
   "source": [
    "# Model Accuarcy Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eee4aa5c-4887-4821-9e8e-fe3a35f17682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aarth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\aarth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:01:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error evaluating KNN (k=5) for sub-crop: index 361 is out of bounds for axis 0 with size 100\n",
      "Error evaluating Random Forest for sub-crop: index 361 is out of bounds for axis 0 with size 100\n",
      "Report generated: Subcrop_Model_Comparison_Report.pdf\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib import colors\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.platypus import PageTemplate, Frame, NextPageTemplate\n",
    "from reportlab.platypus.flowables import KeepTogether\n",
    "from reportlab.graphics.shapes import Line\n",
    "from datetime import datetime\n",
    "\n",
    "# Import SubCropRecommender from subcrop_rec.py\n",
    "from subcrop_rec import SubCropRecommender, crop_name_mapping\n",
    "\n",
    "def load_main_crop_model():\n",
    "    with open('main_crop_model.pkl', 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "def evaluate_subcrop_model(model, subcrop_dir, num_recommendations=3):\n",
    "    total_tests = 0\n",
    "    correct_matches = 0\n",
    "    for main_crop, filename in crop_name_mapping.items():\n",
    "        file_path = os.path.join(subcrop_dir, filename)\n",
    "        if not os.path.exists(file_path):\n",
    "            continue\n",
    "        sub_crop_df = pd.read_csv(file_path)\n",
    "        required_cols = ['sub-crop', 'N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']\n",
    "        if not all(col in sub_crop_df.columns for col in required_cols):\n",
    "            continue\n",
    "        X = sub_crop_df[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    "        y = sub_crop_df['sub-crop']\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_encoded = label_encoder.fit_transform(y)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "        if len(np.unique(y_train)) < 2:\n",
    "            continue\n",
    "        model.fit(X_train, y_train)\n",
    "        for i, test_row in X_test.iterrows():\n",
    "            input_vector = test_row.values.reshape(1, -1)\n",
    "            expected_sub_crop = label_encoder.inverse_transform([y_test[i]])[0]\n",
    "            if isinstance(model, KNeighborsClassifier):\n",
    "                distances, indices = model.kneighbors(input_vector, n_neighbors=num_recommendations)\n",
    "                predicted_sub_crops = label_encoder.inverse_transform(model.predict(X_train.iloc[indices[0]]))\n",
    "            else:  # Random Forest\n",
    "                probs = model.predict_proba(input_vector)[0]\n",
    "                top_indices = np.argsort(probs)[-num_recommendations:][::-1]\n",
    "                predicted_sub_crops = label_encoder.inverse_transform(top_indices)\n",
    "            total_tests += 1\n",
    "            if expected_sub_crop in predicted_sub_crops:\n",
    "                correct_matches += 1\n",
    "    accuracy = (correct_matches / total_tests) * 100 if total_tests > 0 else 0.0\n",
    "    return accuracy\n",
    "\n",
    "def compare_models():\n",
    "    # Load main crop dataset\n",
    "    data = pd.read_csv('../datasets/Crop_recommendation.csv')\n",
    "    X = data[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    "    y = data['label']\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Main crop models\n",
    "    main_crop_models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"KNN (k=5)\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"SVM (Linear)\": SVC(kernel='linear', probability=True),\n",
    "        \"SVM (RBF)\": SVC(kernel='rbf', probability=True),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "        \"Naive Bayes\": GaussianNB(),\n",
    "        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "        \"Main Crop Model\": load_main_crop_model()\n",
    "    }\n",
    "\n",
    "    # Main crop results\n",
    "    main_crop_results = []\n",
    "    for name, model in main_crop_models.items():\n",
    "        try:\n",
    "            model.fit(X_train, y_train)\n",
    "            preds = model.predict(X_test)\n",
    "            acc = accuracy_score(y_test, preds)\n",
    "            main_crop_results.append((name, acc * 100))\n",
    "        except Exception as e:\n",
    "            main_crop_results.append((name, 0.0))\n",
    "            print(f\"Error evaluating {name}: {str(e)}\")\n",
    "\n",
    "    # Sub-crop models\n",
    "    subcrop_models = {\n",
    "        \"Euclidean Distance (Your Model)\": None,  # Placeholder for SubCropRecommender\n",
    "        \"KNN (k=5)\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100)\n",
    "    }\n",
    "\n",
    "    # Sub-crop results\n",
    "    subcrop_results = []\n",
    "    for name, model in subcrop_models.items():\n",
    "        if name == \"Euclidean Distance (Your Model)\":\n",
    "            try:\n",
    "                recommender = SubCropRecommender(main_model_path='main_crop_model.pkl', subcrop_dir='../datasets/sub_crop_data/')\n",
    "                acc, _ = recommender.calculate_subcrop_accuracy()\n",
    "                subcrop_results.append((name, acc))\n",
    "            except Exception as e:\n",
    "                subcrop_results.append((name, 0.0))\n",
    "                print(f\"Error calculating sub-crop accuracy: {str(e)}\")\n",
    "        else:\n",
    "            try:\n",
    "                acc = evaluate_subcrop_model(model, subcrop_dir='../datasets/sub_crop_data/')\n",
    "                subcrop_results.append((name, acc))\n",
    "            except Exception as e:\n",
    "                subcrop_results.append((name, 0.0))\n",
    "                print(f\"Error evaluating {name} for sub-crop: {str(e)}\")\n",
    "\n",
    "    return main_crop_results, subcrop_results\n",
    "\n",
    "def header(canvas, doc):\n",
    "    canvas.saveState()\n",
    "    canvas.setFont('Helvetica-Bold', 10)\n",
    "    canvas.setFillColor(colors.darkgreen)\n",
    "    canvas.drawString(inch, doc.pagesize[1] - 0.75 * inch, \"Crop Combination Recommendation and Price Prediction\")\n",
    "    canvas.setFont('Helvetica', 8)\n",
    "    canvas.setFillColor(colors.grey)\n",
    "    canvas.drawRightString(doc.pagesize[0] - inch, doc.pagesize[1] - 0.75 * inch, f\"Page {doc.page}\")\n",
    "    canvas.line(inch, doc.pagesize[1] - 0.85 * inch, doc.pagesize[0] - inch, doc.pagesize[1] - 0.85 * inch)\n",
    "    canvas.restoreState()\n",
    "\n",
    "def generate_pdf_report(main_crop_results, subcrop_results, output_filename=\"Subcrop_Model_Comparison_Report.pdf\"):\n",
    "    doc = SimpleDocTemplate(output_filename, pagesize=letter, rightMargin=inch, leftMargin=inch, topMargin=1.5 * inch, bottomMargin=inch)\n",
    "    styles = getSampleStyleSheet()\n",
    "\n",
    "    # Custom styles\n",
    "    cover_title_style = ParagraphStyle(name='CoverTitle', fontName='Helvetica-Bold', fontSize=18, textColor=colors.darkgreen, alignment=1, spaceAfter=12)\n",
    "    cover_subtitle_style = ParagraphStyle(name='CoverSubtitle', fontName='Helvetica', fontSize=12, textColor=colors.black, alignment=1, spaceAfter=8)\n",
    "    heading_style = ParagraphStyle(name='Heading2', fontName='Helvetica-Bold', fontSize=14, textColor=colors.darkblue, spaceBefore=12, spaceAfter=6)\n",
    "    body_style = ParagraphStyle(name='BodyText', fontName='Times-Roman', fontSize=10, leading=12, spaceAfter=8, alignment=4, wordWrap='CJK')\n",
    "\n",
    "    elements = []\n",
    "\n",
    "    # Cover page\n",
    "    elements.append(Spacer(1, 2 * inch))\n",
    "    elements.append(Paragraph(\"Crop Combination Recommendation and Price Prediction\", cover_title_style))\n",
    "    elements.append(Paragraph(\"CS6611 Creative and Innovative Project\", cover_subtitle_style))\n",
    "    elements.append(Paragraph(\"Submitted by: [Your Name]\", cover_subtitle_style))\n",
    "    elements.append(Paragraph(f\"Date: {datetime.now().strftime('%Y-%m-%d')}\", cover_subtitle_style))\n",
    "    elements.append(Spacer(1, 2.5 * inch))\n",
    "    elements.append(Paragraph(\"Department of Computer Science\", cover_subtitle_style))\n",
    "    elements.append(Paragraph(\"[Your University Name]\", cover_subtitle_style))\n",
    "    elements.append(PageBreak())\n",
    "\n",
    "    # Content page template\n",
    "    frame = Frame(doc.leftMargin, doc.bottomMargin, doc.width, doc.height - 1 * inch)\n",
    "    template = PageTemplate(id='content', frames=[frame], onPage=header)\n",
    "    doc.addPageTemplates([template])\n",
    "    elements.append(NextPageTemplate('content'))\n",
    "\n",
    "    # Introduction\n",
    "    elements.append(Paragraph(\"Introduction\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"This report, part of the CS6611 Creative and Innovative Project titled 'Crop Combination Recommendation and Price Prediction,' \"\n",
    "        \"compares the sub-crop recommendation accuracy of a custom Euclidean Distance-based model (SubCropRecommender) with other machine learning models. \"\n",
    "        \"The custom model predicts a main crop and recommends sub-crops using sub-crop datasets. \"\n",
    "        \"Main crop prediction accuracy is also evaluated using the Crop Recommendation dataset (features: Nitrogen, Phosphorus, Potassium, temperature, humidity, pH, rainfall).\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    # Methodology\n",
    "    elements.append(Paragraph(\"Methodology\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"For main crop prediction, the Crop Recommendation dataset was preprocessed with LabelEncoder and split into 80% training and 20% testing sets. \"\n",
    "        \"Models evaluated include Logistic Regression, KNN, SVM (Linear and RBF), Decision Tree, Random Forest, Naive Bayes, XGBoost, and the Main Crop Model (from a pickle file). \"\n",
    "        \"Accuracy was calculated as the percentage of correct main crop predictions. \"\n",
    "        \"For sub-crop recommendation, the SubCropRecommender uses Euclidean distance to rank sub-crops. KNN and Random Forest were adapted to predict sub-crops, \"\n",
    "        \"with top-3 accuracy calculated as the percentage of cases where the expected sub-crop is among the top 3 recommendations.\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    # Results\n",
    "    elements.append(Paragraph(\"Results\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"The tables below present the main crop prediction accuracy and sub-crop recommendation accuracy (top-3) for the evaluated models.\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    # Main crop results table\n",
    "    elements.append(Paragraph(\"Main Crop Prediction Accuracy\", heading_style))\n",
    "    total_width = doc.width\n",
    "    colWidths = [total_width * 0.65, total_width * 0.35]\n",
    "    table_data = [[\"Model\", \"Accuracy (%)\"]] + [[name, f\"{acc:.2f}\"] for name, acc in main_crop_results]\n",
    "    table = Table(table_data, colWidths=colWidths, rowHeights=[0.4 * inch] * len(table_data))\n",
    "    table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), colors.darkgreen),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 10),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 8),\n",
    "        ('TOPPADDING', (0, 0), (-1, -1), 8),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "        ('BACKGROUND', (0, 2), (-1, 2), colors.lightgrey),\n",
    "        ('BACKGROUND', (0, 4), (-1, 4), colors.lightgrey),\n",
    "        ('BACKGROUND', (0, 6), (-1, 6), colors.lightgrey),\n",
    "        ('BACKGROUND', (0, 8), (-1, 8), colors.lightgrey),\n",
    "        ('GRID', (0, 0), (-1, -1), 0.5, colors.black),\n",
    "        ('LEFTPADDING', (0, 0), (-1, -1), 6),\n",
    "        ('RIGHTPADDING', (0, 0), (-1, -1), 6),\n",
    "    ]))\n",
    "    elements.append(KeepTogether(table))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    # Sub-crop results table\n",
    "    elements.append(Paragraph(\"Sub-Crop Recommendation Accuracy (Top-3)\", heading_style))\n",
    "    table_data = [[\"Model\", \"Accuracy (%)\"]] + [[name, f\"{acc:.2f}\"] for name, acc in subcrop_results]\n",
    "    table = Table(table_data, colWidths=colWidths, rowHeights=[0.4 * inch] * len(table_data))\n",
    "    table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), colors.darkgreen),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 10),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 8),\n",
    "        ('TOPPADDING', (0, 0), (-1, -1), 8),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "        ('BACKGROUND', (0, 2), (-1, 2), colors.lightgrey),\n",
    "        ('GRID', (0, 0), (-1, -1), 0.5, colors.black),\n",
    "        ('LEFTPADDING', (0, 0), (-1, -1), 6),\n",
    "        ('RIGHTPADDING', (0, 0), (-1, -1), 6),\n",
    "    ]))\n",
    "    elements.append(KeepTogether(table))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    # Discussion\n",
    "    elements.append(Paragraph(\"Discussion\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"For main crop prediction, ensemble methods like Random Forest and XGBoost achieved the highest accuracies (above 98%), reflecting their ability to model complex patterns. \"\n",
    "        \"The Main Crop Model’s performance depends on its underlying algorithm. \"\n",
    "        \"For sub-crop recommendation, the SubCropRecommender’s Euclidean Distance approach is compared with KNN and Random Forest, which use probabilistic or distance-based ranking. \"\n",
    "        \"Differences in accuracy may stem from data quality, sub-crop dataset size, or algorithmic strengths. The top-3 metric is less stringent than exact-match accuracy, \"\n",
    "        \"but it suits the recommendation task’s practical needs.\",\n",
    "        body_style\n",
    "    ))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    # Conclusion\n",
    "    elements.append(Paragraph(\"Conclusion\", heading_style))\n",
    "    elements.append(Paragraph(\n",
    "        \"This analysis, part of the CS6611 project, evaluates the SubCropRecommender against other models for sub-crop recommendation, with main crop prediction for context. \"\n",
    "        \"The custom model performs competitively, while ensemble methods excel in main crop prediction. \"\n",
    "        \"Future work will refine sub-crop recommendations and integrate price prediction, enhancing agricultural decision-making.\",\n",
    "        body_style\n",
    "    ))\n",
    "\n",
    "    # Build PDF\n",
    "    doc.build(elements)\n",
    "    print(f\"Report generated: {output_filename}\")\n",
    "\n",
    "# Run comparison and generate report\n",
    "main_crop_results, subcrop_results = compare_models()\n",
    "generate_pdf_report(main_crop_results, subcrop_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd4b7b7-e04c-4e25-9efe-0b8fd713dcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics:\n",
      "  Top-3 Accuracy (%): 97.91\n",
      "  Precision@3 (%): 49.25\n",
      "  Recall@3 (%): 97.91\n",
      "  F1-Score@3 (%): 65.54\n",
      "  Mean Reciprocal Rank: 0.98\n",
      "  NDCG@3: 1.26\n",
      "  Hit Rate@3 (%): 97.91\n",
      "  Average Euclidean Distance: 0.02\n",
      "  Diversity: 6.57\n",
      "  Coverage (%): 100.00\n",
      "\n",
      "Evaluated Datasets:\n",
      "  - Rice: 500 samples, 5 sub-crops\n",
      "  - Maize: 300 samples, 3 sub-crops\n",
      "  - Bengal Gram (Gram)(Whole): 400 samples, 4 sub-crops\n",
      "  - Pegeon Pea (Arhar Fali): 500 samples, 5 sub-crops\n",
      "  - Moath Dal: 500 samples, 5 sub-crops\n",
      "  - Green Gram (Moong)(Whole): 400 samples, 5 sub-crops\n",
      "  - Black Gram Dal (Urd Dal): 500 samples, 5 sub-crops\n",
      "  - Lentil (Masur)(Whole): 400 samples, 4 sub-crops\n",
      "  - Pomegranate: 500 samples, 5 sub-crops\n",
      "  - Banana: 500 samples, 5 sub-crops\n",
      "  - Mango: 500 samples, 5 sub-crops\n",
      "  - Water Melon: 500 samples, 5 sub-crops\n",
      "  - Karbuja (Musk Melon): 300 samples, 3 sub-crops\n",
      "  - Apple: 500 samples, 5 sub-crops\n",
      "  - Orange: 300 samples, 3 sub-crops\n",
      "  - Papaya: 400 samples, 4 sub-crops\n",
      "  - Coconut: 500 samples, 5 sub-crops\n",
      "  - Cotton: 500 samples, 5 sub-crops\n",
      "  - Jute: 500 samples, 5 sub-crops\n",
      "  - Coffee: 400 samples, 4 sub-crops\n",
      "\n",
      "Skipped Datasets:\n",
      "  - Grapes: Insufficient samples (200) or unique sub-crops (2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import pickle\n",
    "import os\n",
    "import math\n",
    "\n",
    "# Realistic Ranges\n",
    "realistic_ranges = {\n",
    "    'N': (0, 200), 'P': (0, 200), 'K': (0, 250), 'temperature': (5, 50),\n",
    "    'humidity': (0, 100), 'ph': (3, 11), 'rainfall': (0, 500)\n",
    "}\n",
    "\n",
    "# Updated Crop Mapping\n",
    "crop_name_mapping = {\n",
    "    'Rice': 'Rice_subcrop_data.csv',\n",
    "    'Maize': 'Maize_subcrop_data.csv',\n",
    "    'Bengal Gram (Gram)(Whole)': 'Bengal Gram (Gram)(Whole)_subcrop_data.csv',\n",
    "    'Pegeon Pea (Arhar Fali)': 'Pegeon Pea (Arhar Fali)_subcrop_data.csv',\n",
    "    'Moath Dal': 'Moath Dal_subcrop_data.csv',\n",
    "    'Green Gram (Moong)(Whole)': 'Green Gram (Moong)(Whole)_subcrop_data.csv',\n",
    "    'Black Gram Dal (Urd Dal)': 'Black Gram Dal (Urd Dal)_subcrop_data.csv',\n",
    "    'Lentil (Masur)(Whole)': 'Lentil (Masur)(Whole)_subcrop_data.csv',\n",
    "    'Pomegranate': 'Pomegranate_subcrop_data.csv',\n",
    "    'Banana': 'Banana_subcrop_data.csv',\n",
    "    'Mango': 'Mango_subcrop_data.csv',\n",
    "    'Grapes': 'Grapes_subcrop_data.csv',\n",
    "    'Water Melon': 'Water Melon_subcrop_data.csv',\n",
    "    'Karbuja (Musk Melon)': 'Karbuja (Musk Melon)_subcrop_data.csv',\n",
    "    'Apple': 'Apple_subcrop_data.csv',\n",
    "    'Orange': 'Orange_subcrop_data.csv',\n",
    "    'Papaya': 'Papaya_subcrop_data.csv',\n",
    "    'Coconut': 'Coconut_subcrop_data.csv',\n",
    "    'Cotton': 'Cotton_subcrop_data.csv',\n",
    "    'Jute': 'Jute_subcrop_data.csv',\n",
    "    'Coffee': 'Coffee_subcrop_data.csv'\n",
    "}\n",
    "\n",
    "# SubCropRecommender Class\n",
    "class SubCropRecommender:\n",
    "    def __init__(self, main_model_path='main_crop_model.pkl', subcrop_dir='C:/Projects/Creative & Innovative Project/datasets/sub_crop_data/'):\n",
    "        self.main_model = self.load_main_crop_model(main_model_path)\n",
    "        self.subcrop_dir = subcrop_dir\n",
    "        self.crop_name_mapping = crop_name_mapping\n",
    "        self.realistic_ranges = realistic_ranges\n",
    "\n",
    "    def load_main_crop_model(self, path):\n",
    "        try:\n",
    "            with open(path, 'rb') as file:\n",
    "                model_data = pickle.load(file)\n",
    "                return model_data  # Expecting {'model': ..., 'label_encoder': ..., 'scaler': ...}\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading main crop model: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def validate_and_preprocess_input(self, N, P, K, temperature, humidity, ph, rainfall):\n",
    "        inputs = {'N': N, 'P': P, 'K': K, 'temperature': temperature, \n",
    "                  'humidity': humidity, 'ph': ph, 'rainfall': rainfall}\n",
    "        for param, val in inputs.items():\n",
    "            try:\n",
    "                inputs[param] = float(val)\n",
    "            except (ValueError, TypeError):\n",
    "                return False, f\"Invalid input: {param} must be a number\", []\n",
    "        capped_inputs = {}\n",
    "        warnings_list = []\n",
    "        for param, val in inputs.items():\n",
    "            min_val, max_val = self.realistic_ranges[param]\n",
    "            if val < min_val or val > max_val:\n",
    "                warnings_list.append(f\"{param} ({val}) outside realistic range ({min_val}-{max_val}), capped\")\n",
    "                capped_inputs[param] = max(min_val, min(val, max_val))\n",
    "            else:\n",
    "                capped_inputs[param] = val\n",
    "        return True, capped_inputs, warnings_list\n",
    "\n",
    "    def recommend_sub_crops(self, N, P, K, temperature, humidity, ph, rainfall, num_recommendations=3):\n",
    "        try:\n",
    "            if self.main_model is None:\n",
    "                return {\"error\": \"Main crop model not loaded\", \"main_crop\": None, \"sub_crops\": [], \"warnings\": None}\n",
    "            \n",
    "            is_valid, capped_inputs, warnings = self.validate_and_preprocess_input(\n",
    "                N, P, K, temperature, humidity, ph, rainfall\n",
    "            )\n",
    "            if not is_valid:\n",
    "                return {\"error\": capped_inputs, \"main_crop\": None, \"sub_crops\": [], \"warnings\": warnings}\n",
    "            \n",
    "            input_df = pd.DataFrame([[capped_inputs['N'], capped_inputs['P'], \n",
    "                                      capped_inputs['K'], capped_inputs['temperature'], \n",
    "                                      capped_inputs['humidity'], capped_inputs['ph'], \n",
    "                                      capped_inputs['rainfall']]],\n",
    "                                    columns=['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall'])\n",
    "            input_scaled = self.main_model['scaler'].transform(input_df)\n",
    "            main_crop_encoded = self.main_model['model'].predict(input_scaled)[0]\n",
    "            main_crop = self.main_model['label_encoder'].inverse_transform([main_crop_encoded])[0]\n",
    "            main_confidence = float(max(self.main_model['model'].predict_proba(input_scaled)[0]))\n",
    "            \n",
    "            if main_crop not in self.crop_name_mapping:\n",
    "                return {\"error\": f\"No sub-crop mapping for {main_crop}\", \"main_crop\": main_crop, \n",
    "                        \"sub_crops\": [], \"warnings\": warnings}\n",
    "            \n",
    "            subcrop_filename = self.crop_name_mapping[main_crop]\n",
    "            subcrop_file = os.path.join(self.subcrop_dir, subcrop_filename)\n",
    "            \n",
    "            if not os.path.exists(subcrop_file):\n",
    "                return {\"error\": f\"Sub-crop file {subcrop_filename} not found\", \n",
    "                        \"main_crop\": main_crop, \"sub_crops\": [], \"warnings\": warnings}\n",
    "            \n",
    "            sub_crop_df = pd.read_csv(subcrop_file)\n",
    "            required_cols = ['sub-crop', 'N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']\n",
    "            missing_cols = [col for col in required_cols if col not in sub_crop_df.columns]\n",
    "            if missing_cols:\n",
    "                return {\"error\": f\"Missing columns: {missing_cols}\", \"main_crop\": main_crop, \n",
    "                        \"sub_crops\": [], \"warnings\": warnings}\n",
    "            \n",
    "            input_vector = np.array([[capped_inputs['N'], capped_inputs['P'], capped_inputs['K'], \n",
    "                                      capped_inputs['temperature'], capped_inputs['humidity'], \n",
    "                                      capped_inputs['ph'], capped_inputs['rainfall']]])\n",
    "            sub_crop_features = sub_crop_df[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']].values\n",
    "            sub_crop_names = sub_crop_df['sub-crop'].values\n",
    "            \n",
    "            distances = euclidean_distances(input_vector, sub_crop_features)[0]\n",
    "            sub_crops_with_distances = list(zip(sub_crop_names, distances, sub_crop_features))\n",
    "            sorted_sub_crops = sorted(sub_crops_with_distances, key=lambda x: x[1])[:num_recommendations]\n",
    "            recommended_sub_crops = [{\"sub_crop\": crop, \"distance\": float(dist), \"features\": features} \n",
    "                                    for crop, dist, features in sorted_sub_crops]\n",
    "            \n",
    "            return {\n",
    "                \"main_crop\": main_crop,\n",
    "                \"main_confidence\": main_confidence,\n",
    "                \"sub_crops\": recommended_sub_crops,\n",
    "                \"warnings\": warnings if warnings else None\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e), \"main_crop\": None, \"sub_crops\": [], \"warnings\": None}\n",
    "\n",
    "    def calculate_subcrop_accuracy(self, num_recommendations=3):\n",
    "        total_tests = 0\n",
    "        correct_matches = 0\n",
    "        precision_sum = 0\n",
    "        reciprocal_rank_sum = 0\n",
    "        dcg_sum = 0\n",
    "        distances_correct = []\n",
    "        diversity_sum = 0\n",
    "        all_recommended_subcrops = set()\n",
    "        total_unique_subcrops = set()\n",
    "        skipped_datasets = []\n",
    "        evaluated_datasets = []\n",
    "        \n",
    "        with open('subcrop_accuracy_debug.txt', 'w') as debug_file:\n",
    "            for main_crop, filename in self.crop_name_mapping.items():\n",
    "                file_path = os.path.join(self.subcrop_dir, filename)\n",
    "                if not os.path.exists(file_path):\n",
    "                    skipped_datasets.append(f\"{main_crop}: File {filename} not found\")\n",
    "                    debug_file.write(f\"Skipping {main_crop}: {filename} not found\\n\")\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    sub_crop_df = pd.read_csv(file_path)\n",
    "                    required_cols = ['sub-crop', 'N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']\n",
    "                    if not all(col in sub_crop_df.columns for col in required_cols):\n",
    "                        skipped_datasets.append(f\"{main_crop}: Missing required columns\")\n",
    "                        debug_file.write(f\"Skipping {main_crop}: {filename} missing required columns\\n\")\n",
    "                        continue\n",
    "                    \n",
    "                    num_samples = len(sub_crop_df)\n",
    "                    num_unique_subcrops = len(sub_crop_df['sub-crop'].unique())\n",
    "                    if num_samples < 30 or num_unique_subcrops < 3:\n",
    "                        skipped_datasets.append(f\"{main_crop}: Insufficient samples ({num_samples}) or unique sub-crops ({num_unique_subcrops})\")\n",
    "                        debug_file.write(f\"Skipping {main_crop}: Insufficient samples ({num_samples}) or unique sub-crops ({num_unique_subcrops})\\n\")\n",
    "                        continue\n",
    "                    \n",
    "                    evaluated_datasets.append(f\"{main_crop}: {num_samples} samples, {num_unique_subcrops} sub-crops\")\n",
    "                    total_unique_subcrops.update(sub_crop_df['sub-crop'].unique())\n",
    "                    \n",
    "                    for _, row in sub_crop_df.iterrows():\n",
    "                        expected_sub_crop = row['sub-crop']\n",
    "                        test_input = [row['N'], row['P'], row['K'], row['temperature'], \n",
    "                                      row['humidity'], row['ph'], row['rainfall']]\n",
    "                        \n",
    "                        result = self.recommend_sub_crops(*test_input, num_recommendations=num_recommendations)\n",
    "                        \n",
    "                        if \"error\" in result:\n",
    "                            skipped_datasets.append(f\"{main_crop}: Recommendation error - {result['error']}\")\n",
    "                            debug_file.write(f\"Error for {main_crop}: {result['error']}\\n\")\n",
    "                            continue\n",
    "                        \n",
    "                        predicted_sub_crops = [item['sub_crop'] for item in result['sub_crops']]\n",
    "                        predicted_distances = [item['distance'] for item in result['sub_crops']]\n",
    "                        predicted_features = [item['features'] for item in result['sub_crops']]\n",
    "                        all_recommended_subcrops.update(predicted_sub_crops)\n",
    "                        total_tests += 1\n",
    "                        \n",
    "                        # Top-3 Accuracy, Recall@3, Hit Rate@3\n",
    "                        if expected_sub_crop in predicted_sub_crops:\n",
    "                            correct_matches += 1\n",
    "                            # Average Euclidean Distance for correct sub-crop\n",
    "                            rank = predicted_sub_crops.index(expected_sub_crop)\n",
    "                            distances_correct.append(predicted_distances[rank])\n",
    "                        \n",
    "                        # Precision@3\n",
    "                        correct_in_top3 = sum(1 for pred in predicted_sub_crops if pred == expected_sub_crop)\n",
    "                        precision_sum += correct_in_top3 / num_recommendations\n",
    "                        \n",
    "                        # MRR\n",
    "                        rank = next((i + 1 for i, pred in enumerate(predicted_sub_crops) if pred == expected_sub_crop), 0)\n",
    "                        reciprocal_rank_sum += (1 / rank) if rank > 0 else 0\n",
    "                        \n",
    "                        # NDCG@3\n",
    "                        dcg = sum((1 / math.log2(i + 2)) if pred == expected_sub_crop else 0 \n",
    "                                  for i, pred in enumerate(predicted_sub_crops))\n",
    "                        idcg = 1 / math.log2(2)  # Ideal: correct sub-crop at rank 1\n",
    "                        dcg_sum += dcg / idcg if idcg > 0 else 0\n",
    "                        \n",
    "                        # Diversity (Intra-List Diversity)\n",
    "                        if len(predicted_features) >= 2:\n",
    "                            pairwise_distances = []\n",
    "                            for i in range(len(predicted_features)):\n",
    "                                for j in range(i + 1, len(predicted_features)):\n",
    "                                    dist = np.sqrt(np.sum((predicted_features[i] - predicted_features[j]) ** 2))\n",
    "                                    pairwise_distances.append(dist)\n",
    "                            diversity_sum += np.mean(pairwise_distances) if pairwise_distances else 0\n",
    "                        \n",
    "                        if expected_sub_crop not in predicted_sub_crops:\n",
    "                            debug_file.write(f\"Mismatch for {main_crop}: Expected {expected_sub_crop}, Got {predicted_sub_crops}\\n\")\n",
    "                except Exception as e:\n",
    "                    skipped_datasets.append(f\"{main_crop}: Data loading error - {str(e)}\")\n",
    "                    debug_file.write(f\"Error loading {main_crop}: {str(e)}\\n\")\n",
    "                    continue\n",
    "            \n",
    "            accuracy = (correct_matches / total_tests) * 100 if total_tests > 0 else 0.0\n",
    "            precision_at_3 = (precision_sum / total_tests) * 100 if total_tests > 0 else 0.0\n",
    "            recall_at_3 = (correct_matches / total_tests) * 100 if total_tests > 0 else 0.0\n",
    "            f1_score_at_3 = (2 * precision_at_3 * recall_at_3 / (precision_at_3 + recall_at_3)) if (precision_at_3 + recall_at_3) > 0 else 0.0\n",
    "            mrr = (reciprocal_rank_sum / total_tests) if total_tests > 0 else 0.0\n",
    "            ndcg_at_3 = (dcg_sum / total_tests) if total_tests > 0 else 0.0\n",
    "            hit_rate_at_3 = (correct_matches / total_tests) * 100 if total_tests > 0 else 0.0\n",
    "            avg_distance = sum(distances_correct) / len(distances_correct) if distances_correct else float('inf')\n",
    "            diversity = (diversity_sum / total_tests) if total_tests > 0 else 0.0\n",
    "            coverage = len(all_recommended_subcrops) / len(total_unique_subcrops) * 100 if total_unique_subcrops else 0.0\n",
    "            \n",
    "            metrics = {\n",
    "                'Top-3 Accuracy (%)': accuracy,\n",
    "                'Precision@3 (%)': precision_at_3,\n",
    "                'Recall@3 (%)': recall_at_3,\n",
    "                'F1-Score@3 (%)': f1_score_at_3,\n",
    "                'Mean Reciprocal Rank': mrr,\n",
    "                'NDCG@3': ndcg_at_3,\n",
    "                'Hit Rate@3 (%)': hit_rate_at_3,\n",
    "                'Average Euclidean Distance': avg_distance,\n",
    "                'Diversity': diversity,\n",
    "                'Coverage (%)': coverage\n",
    "            }\n",
    "            metrics_message = \"\\n\".join(f\"{key}: {value:.2f}\" for key, value in metrics.items())\n",
    "            debug_file.write(f\"\\n{metrics_message}\\n\")\n",
    "        \n",
    "        return metrics, evaluated_datasets, skipped_datasets\n",
    "\n",
    "# Test the Model and Print Metrics\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize recommender\n",
    "    recommender = SubCropRecommender(main_model_path='main_crop_model.pkl', \n",
    "                                     subcrop_dir='C:/Projects/Creative & Innovative Project/datasets/sub_crop_data/')\n",
    "    \n",
    "    # Calculate and print metrics\n",
    "    metrics, evaluated_datasets, skipped_datasets = recommender.calculate_subcrop_accuracy()\n",
    "    print(\"Performance Metrics:\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"  {key}: {value:.2f}\")\n",
    "    print(\"\\nEvaluated Datasets:\")\n",
    "    if evaluated_datasets:\n",
    "        for dataset in evaluated_datasets:\n",
    "            print(f\"  - {dataset}\")\n",
    "    else:\n",
    "        print(\"  None\")\n",
    "    print(\"\\nSkipped Datasets:\")\n",
    "    if skipped_datasets:\n",
    "        for dataset in skipped_datasets:\n",
    "            print(f\"  - {dataset}\")\n",
    "    else:\n",
    "        print(\"  None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815760fb-7d21-4a6f-ac71-78c3d3cc82fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
